<?xml-stylesheet href="/rss.xsl" type="text/xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>悟剑阁</title>
    <link>https://sword865.github.io/</link>
    <description>Recent content on 悟剑阁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2015. All rights reserved.</copyright>
    <lastBuildDate>Sat, 03 May 2025 15:51:35 +0800</lastBuildDate>
    
        <atom:link href="https://sword865.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>Flash MLA Kernel分析</title>
        <link>https://sword865.github.io/posts/2025/2025-05-03-flashmla-kernel%E5%88%86%E6%9E%90/</link>
        <pubDate>Sat, 03 May 2025 15:51:35 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2025/2025-05-03-flashmla-kernel%E5%88%86%E6%9E%90/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2025/2025-05-03-flashmla-kernel%E5%88%86%E6%9E%90/ -&lt;p&gt;准备对DeepSeek的开源项目整理一些文档，也顺便强化一下记忆，先从FlashMLA开始。&lt;/p&gt;
&lt;p&gt;FlashMLA是DeepSeek开源的MLA算子实现，这个实现主要给inference decoding用的，Training和prefill应该是另外一个算子。&lt;/p&gt;
&lt;p&gt;先拿下面的图表示一下MLA算子是在计算一个什么东西，这篇文章就不讲具体的推导了，反正这个算子大概就是下面的2个GEMM算子的融合。需要注意的是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;这里矩阵K和矩阵V的共享一部分参数。&lt;/li&gt;
&lt;li&gt;图里只画显示了一个Query Head和一对KV Head的计算。在实际计算中还要num_kv_head和batch_size两个维度。&lt;/li&gt;
&lt;li&gt;两个GEMM中间其实还有一个sotfmax，不过这里可以通过online softmax算法把这块逻辑独立处理分块处理，所以不影响主流程。&lt;/li&gt;
&lt;/ol&gt;
&lt;img width=&#34;600&#34;  src=&#34;https://sword865.github.io/images/2025/20250503/mla.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;Kernel的调用主要分两部分&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调用&lt;code&gt;get_mla_metadata&lt;/code&gt;来计算一些metadata，用来优化kernel的执行&lt;/li&gt;
&lt;li&gt;调用&lt;code&gt;flash_mla_with_kvcache&lt;/code&gt;进行计算&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在进入调用前，先大概说一下FlashMLA计算的拆分逻辑。这块和FlashDecoding很像，并没有要求一个thread-block必须处理一个完整的sequence，而是通过一个负载均衡算法，把所有的sequence放到一起，然后拆分成一个个的sequence-block，然后每个thread-block就去处理分配给它的那些block的计算，最后再把这些thread-block的结果用合并，得到正确的输出。&lt;/p&gt;
&lt;p&gt;大概是下面这个图的样子：&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250503/computation-pattern.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;所以为了完成计算，第一步就是决定每个block需要处理哪些sub-sequence，也就是&lt;code&gt;get_mla_metadata&lt;/code&gt;要完成的事情。&lt;/p&gt;
&lt;h1 id=&#34;get_mla_metadata&#34;&gt;get_mla_metadata&lt;/h1&gt;
&lt;p&gt;先看&lt;code&gt;get_mla_metadata&lt;/code&gt;具体提供了哪些元数据，我们从repo提供的测试代码入手，考虑最简单的情况(batch_size=128, query_sequence_len=1, mean_key_sequence_len=4096, MTP=1, num_kv_head=1, num_q_head=16, TP=1, hidden_NoRoPE_dim=512, hidden_RoPE_dim=64, varlen=False)。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# cache_seqlens = tensor([4096, 4096, ..., 4096], dtype=torch.int32), size=batch_size, value=sequence_len
# s_q=1 (query_sequence_len=1且MTP=1), h_q(num_q_head)=128 (TP=1=128/128) h_kv(num_kv_head)=1
# 基于这些配置，计算mla kernel的metadata
tile_scheduler_metadata, num_splits = get_mla_metadata(cache_seqlens, s_q * h_q // h_kv, h_kv)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因为这里我们是在测试decoding步骤，所以有&lt;code&gt;query_sequence_len=1&lt;/code&gt;，可以看到三个入参：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;kv cache的大小&lt;/li&gt;
&lt;li&gt;类似GQA的Group数量，这个参数表示每个kv head对应多少个query head。&lt;/li&gt;
&lt;li&gt;kv head的数量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;get_mla_metadata&lt;/code&gt;会根据GPU中SM的数量和要处理的数据的大小，给每个SM分配任务。这个注意&lt;code&gt;get_mla_metadata_kernel&lt;/code&gt;的参数为&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;1, 32, 0, stream&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;，因此所有计算会在1个warp中完成。&lt;/p&gt;
&lt;p&gt;这里的关键就是具体怎么给每个(每组)SM分配工作的.&lt;/p&gt;
&lt;p&gt;首先，每几个SM会一起处理一个kv head和一组query head的计算：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;int num_sm_parts = sm_count / num_heads_k / cutlass::ceil_div(num_heads_per_head_k, block_size_m);
&lt;/code&gt;&lt;/pre&gt;&lt;img width=&#34;600&#34;  src=&#34;https://sword865.github.io/images/2025/20250503/flash_mla_sm_part.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;然后，我们计算每组SM需要处理多少个block，然后把block分配到每一个SM，具体任务的分配过程为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据batch size和&lt;code&gt;mean_key_sequence_len&lt;/code&gt;计算出一共有多少个block。&lt;/li&gt;
&lt;li&gt;给每个SM分配工作，包括每个SM要处理的tile的索引和位置。&lt;/li&gt;
&lt;li&gt;记录一下每个sequnce的切分点的位置，用于在计算时把结果正确的合起来才能得到完整的注意力输出。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;OK, 这样我们就完成了对任务的划分，接下来进入关键的计算kernel。&lt;/p&gt;
&lt;h1 id=&#34;flash_mla_with_kvcache&#34;&gt;flash_mla_with_kvcache&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;flash_mla_with_kvcache&lt;/code&gt;函数内部其实也是由2个子kernel组成的&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;flash_fwd_splitkv_mla_kernel&lt;/code&gt;: 通过for循环的方式，计算每个SM分配到的block的GEMM乘法。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;flash_fwd_splitkv_mla_combine_kernel&lt;/code&gt;: 负责把多个block的计算结果合起来，得到最终的结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;flash_fwd_splitkv_mla_kernel&#34;&gt;flash_fwd_splitkv_mla_kernel&lt;/h2&gt;
&lt;p&gt;先看&lt;code&gt;flash_fwd_splitkv_mla_kernel&lt;/code&gt;，这个kernel包括&lt;code&gt;num_m_block * num_query_head * num_sm_parts&lt;/code&gt; 个thread-block。其中&lt;code&gt;num_m_block=seqlen_q/block_size_m(64)&lt;/code&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kernel&amp;lt;&amp;lt;&amp;lt;dim3(num_m_block, params.h, params.num_sm_parts), Kernel_traits::kNThreads, smem_size, stream&amp;gt;&amp;gt;&amp;gt;(params);&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，这里的&lt;code&gt;seqlen_q&lt;/code&gt;并不是一开始的1了，实际上它等于&lt;code&gt;num_heads_per_head_k (seqlen_q = seqlen_q_ori * ngroups, 在MTP=1的情况下等于num_heads_per_head_k)&lt;/code&gt;
这样我们会发现：&lt;code&gt;num_m_block=cutlass::ceil_div(num_heads_per_head_k, block_size_m);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;回忆之前的SM分组公式，有&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;SM数量 = num_sm_parts * num_heads_k * ceil_div(num_heads_per_head_k, block_size_m)
       = num_sm_parts * ceil_div(num_heads_k * num_heads_per_head_k, block_size_m) 
       = num_sm_parts * ceil_div(num_query_head, block_size_m)
       = num_sm_parts * num_m_block
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;因此SM的数量对应了thread-block的第一维和最后一维。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dim3(num_m_block, params.h, params.num_sm_parts)&lt;/code&gt;的这三个维度分别表示：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;这个thread-block处理哪一个block。&lt;/li&gt;
&lt;li&gt;这个thread-block应该处理哪的一个query head。&lt;/li&gt;
&lt;li&gt;这个thread-block在对应的SM Group内的编号。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们来看每个thread-block会计算什么，我们知道多个thread-block会共同完成分配给一个SM的block的计算。
看代码发现这里其实有2重循环：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;外层循环会遍历所以分配给这个SM的query block。&lt;/li&gt;
&lt;li&gt;内层循环会遍历对应的KV cache block，计算出O的一个block。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;使用了Warp Specialization的策略，通过生产者&amp;ndash;&amp;gt;消费者的方式进行计算。
&lt;ul&gt;
&lt;li&gt;Warp Group 1：主要计算线程，负责大部分的注意力得分计算。&lt;/li&gt;
&lt;li&gt;Warp Group 2：使用double buffer的技术进行数据的加载，也参与一些计算。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这块代码比较复杂的，zhihu上有几篇文章写的挺清楚的，我就不一点点写分析了，画个图过来表示一下计算过程，对细节感兴趣的可以去看后面的几个参考的文章。&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250503/flashmla_wap_spec.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;这里可以看到，Warp Group 0会计算GEMM1，但是GEMM2是由两个Warp Group共同计算的，每个Wrap计算其中一半。&lt;/p&gt;
&lt;p&gt;这里比较重要的几块逻辑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Warp Specialization&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  int warp_group_idx = cutlass::canonical_warp_group_idx();
    if (warp_group_idx == 0) {
        // 主要计算逻辑，包括矩阵乘法、归一化、概率矩阵的计算和输出
        // thread 0 - 127
        ....
    } else {
       // 主要负责加载数据
       // thread 128 - 256
    }
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;上面else逻辑中的双缓冲&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// 双缓冲区数据结构定义
template&amp;lt;typename Kernel_traits&amp;gt;
struct SharedStorageMLA {
    union {
        struct {
               // 存储 Query、Key 和中间结果
              ...
              cute::array_aligned&amp;lt;typename Kernel_traits::Element, 
                  cute::cosize_v&amp;lt;typename Kernel_traits::SmemLayoutK&amp;gt; * 2&amp;gt; smem_k;  // Double buffer
              ...
        }
        ...
    }
}
...

 // 双缓冲策略(在warp group 1的代码里)：切换到第二个缓冲区
if (n_block % 2 == 1) {           
       // Double buffer for sK
       constexpr int sK_offset = size(sK);
       tSrK.data() = tSrK.data() + sK_offset / 8;
       tOrVt.data() = tOrVt.data() + sK_offset / 8;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;flash_fwd_splitkv_mla_combine_kernel&#34;&gt;flash_fwd_splitkv_mla_combine_kernel&lt;/h2&gt;
&lt;p&gt;最后的&lt;code&gt;flash_fwd_splitkv_mla_combine_kernel&lt;/code&gt;比较简单，就是负责数据的合并：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在Warp 0中计算各个block的Log-Sum-Exp最大值，获取全局归一化系数。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for (int i = 0; i &amp;lt; kNLsePerThread; ++i) max_lse = max(max_lse, local_lse[i]);
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;在Warp 0中计算缩放因子。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for (int i = 0; i &amp;lt; kNLsePerThread; ++i) {
       const int split = i * 32 + tidx;
       if (split &amp;lt; actual_num_splits) sLseScale[split] = expf(local_lse[i] - global_lse);
}
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;按照缩放因子，合并Output的输出，完成计算。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;for (int split = 0; split &amp;lt; actual_num_splits; ++split) {
       ...
       ElementAccum lse_scale = sLseScale[split];
       for (int i = 0; i &amp;lt; size(tOrO); ++i) {
              tOrO(i) += lse_scale * tOrOaccum(i);
        }
        ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;把结果写回全局内存。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;参考文章&#34;&gt;参考文章：&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2405.04434&#34;&gt;DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26269071923&#34;&gt;DeepSeek: FlashMLA代码解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/26080342823&#34;&gt;flashMLA 深度解析&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
- https://sword865.github.io/posts/2025/2025-05-03-flashmla-kernel%E5%88%86%E6%9E%90/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>vLLM Paged Attention代码分析</title>
        <link>https://sword865.github.io/posts/2025/2025-04-20-vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</link>
        <pubDate>Sun, 20 Apr 2025 15:51:35 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2025/2025-04-20-vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2025/2025-04-20-vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/ -&lt;p&gt;3月底整理了一个关于经典Paged Attention算法的ppt, 想起这个几年没写过的blog，把PPT改成一篇文章证明我还活着(-_-)。&lt;/p&gt;
&lt;img width=&#34;500&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/paged_attention.png&#34; class=&#34;center&#34; /&gt;
&lt;h2 id=&#34;vllm-的-paged-attention&#34;&gt;vLLM 的 Paged Attention&lt;/h2&gt;
&lt;p&gt;开始前先说明一下，vLLM里的Paged Attention Kernel是有好几个不同的版本的，大概是下面这样子：&lt;/p&gt;
&lt;p&gt;vLLM早期版本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prefilling -&amp;gt; Flash Attention的flash_attn_varlen_func&lt;/li&gt;
&lt;li&gt;Dedocding -&amp;gt; 自己实现的Paged Attention
&lt;ul&gt;
&lt;li&gt;paged_attention_v1 : 用于比较短的sequence&lt;/li&gt;
&lt;li&gt;paged_attention_v2 : 用于不想用v1的情况 :)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;源码大概是这样的：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    # NOTE(woosuk): We use a simple heuristic to decide whether to use
    # PagedAttention V1 or V2. If the number of partitions is 1, we use
    # V1 to avoid the overhead of reduction. Also, if the number of
    # sequences or heads is large, we use V1 since there is enough work
    # to parallelize.
    # TODO(woosuk): Tune this heuristic.
    # For context len &amp;gt; 8192, use V2 kernel to avoid shared memory
    # shortage.
    use_v1 = (max_seq_len &amp;lt;= 8192 and (max_num_partitions == 1 or num_seqs * num_heads &amp;gt; 512))
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;vLLM 最新版本就已经全部转向Flash Attention， 用cutlass实现了。&lt;/p&gt;
&lt;h2 id=&#34;nvidia-gpu-基础&#34;&gt;NVIDIA GPU 基础&lt;/h2&gt;
&lt;p&gt;在深入 Paged Attention 的实现之前，我们需要了解 NVIDIA GPU的基本架构。（这里我们主要讲A100）&lt;/p&gt;
&lt;p&gt;在做开发时，GPU 的 CUDA 程序包括 Grid -&amp;gt; Thread Block -&amp;gt; Threads三层架构。
这三层架构对应到GPU的硬件：GPU -&amp;gt; SM -&amp;gt; Cuda Core&lt;/p&gt;
&lt;p&gt;在实际执行的时候，Threads会以每32个为一组执行，因此这里还多了一层：Thread Wrap，因此结构变成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CUDA程序：Grid -&amp;gt; Thread Block -&amp;gt; Thread Wrap -&amp;gt; Threads四层架构。&lt;/li&gt;
&lt;li&gt;GPU硬件：GPU -&amp;gt; SM(多次执行) -&amp;gt; SM(一次执行) -&amp;gt; Cuda Core，也是四层。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 A100 GPU 上，我们有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;108个SM&lt;/li&gt;
&lt;li&gt;每个SM有4个Wrap scheduler
&lt;ul&gt;
&lt;li&gt;最多有4个Thread Wrap同时在一个SM上执行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;每个Wrap scheduler有一个长度为16的调度队列
&lt;ul&gt;
&lt;li&gt;一个SM上最多可以调度64个Thread Wrap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基本上这些数字在设计Kernel的时候都可以被考虑到，从而最大化一个Kernel的硬件利用率。&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/nvida_gpu.png&#34; class=&#34;center&#34; /&gt;
&lt;h2 id=&#34;vllm-kernel-映射&#34;&gt;vLLM Kernel 映射&lt;/h2&gt;
&lt;p&gt;现在我们看一下vLLM Kernel的设计：(处于简化的目的，我们认为没有TP)&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/vllm_kernel_map.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;设计Kernel的第一步是把程序拆分成不同的Thread Block来简化问题，vLLM中每个Thread Block会负责1个Query Token的一个Query Head的计算。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这个设计其实比较粗糙。不过没关系，Flash Attention里有更多优化。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;设计好计算粒度后，是内存布局的优化，vLLM的Kernel对Q，K, V使用了不同的内存布局，看代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    const scalar_t* __restrict__ q,       // [num_seqs, num_heads, head_size]
    const cache_t* __restrict__ k_cache,  // [num_blocks, num_kv_heads,
                                          // head_size/x, block_size, x]
    const cache_t* __restrict__ v_cache,  // [num_blocks, num_kv_heads,
                                          // head_size, block_size]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;内存设计的时候，我们一般要考虑的是如何能够更好的做到：1. 每次读取连续的内存块(向量读指令，最好能翻译成_ld.global.b128，以128bit也就是16Bytes为单位)；2. 降低不同thread的读冲突。QKV的内存布局基本上也是考虑这些来做的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Q的布局是最简单的，序列长度-&amp;gt;head数量-&amp;gt;head维度。&lt;/li&gt;
&lt;li&gt;K的布局比较复杂，最外层的num_block和num_kv_heads比较好理解，对应了一块KV Cache。但是在没有按照head_size连续存储，还引入了一个参数x。这个布局其实是为了优化K的读取效率，我们在后面再讲。&lt;/li&gt;
&lt;li&gt;最后是V的布局，比K要直接一些，没有额外的维度x。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于这个设计，在列一下相关的代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  // 我们希望能用一个thread wrap一次处理一个KV cache block，这里block_size一般是4/8/16这样子。 
  // 因为wrap_size=32，大于cache block size，我们就可以给一个token多分配几个thread来加速计算。
  // 用wrap size 处理 cache_block_size，这样就知道一个wrap thread可以用几个Thread来处理一个token。
  // 这里数字被记作thread group size
  [[maybe_unused]] int thread_group_size = MAX(WARP_SIZE / BLOCK_SIZE, 1);
  assert(head_size % thread_group_size == 0);
  ...
  # 这里的Num threads是128，最后算出来4个wrap，应该也是对应了A100个一个SM有4个wrap scheduler。
  constexpr int NUM_WARPS = NUM的_THREADS / WARP_SIZE;
  ...
  # 没啥好说的，就是一个thread block用128个thread，处理一个token的一个head
  dim3 grid(num_heads, num_seqs, 1);
  dim3 block(NUM_THREADS);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;随着Thread Group的提出，这个CUDA Kernel的架构变的更复杂了 :(&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CUDA程序：Grid -&amp;gt; Thread Block -&amp;gt; Thread Wrap -&amp;gt; Thread Group -&amp;gt; Threads五层架构。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query数据访问&#34;&gt;Query数据访问&lt;/h2&gt;
&lt;p&gt;讲了这么多终于开始计算了，先拿张图演示一下Query Token的访问：&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/query_io.png&#34; class=&#34;center&#34; /&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  constexpr int VEC_SIZE = MAX(16 / (THREAD_GROUP_SIZE * sizeof(scalar_t)), 1);

  constexpr int NUM_ELEMS_PER_THREAD = HEAD_SIZE / THREAD_GROUP_SIZE;
  constexpr int NUM_VECS_PER_THREAD = NUM_ELEMS_PER_THREAD / VEC_SIZE;

  const scalar_t* q_ptr = q + seq_idx * q_stride + head_idx * HEAD_SIZE;
  __shared__ Q_vec q_vecs[THREAD_GROUP_SIZE][NUM_VECS_PER_THREAD];
#pragma unroll
  for (int i = thread_group_idx; i &amp;lt; NUM_VECS_PER_THREAD;
       i += NUM_THREAD_GROUPS) {
    const int vec_idx = thread_group_offset + i * THREAD_GROUP_SIZE;
    q_vecs[thread_group_offset][i] =
        *reinterpret_cast&amp;lt;const Q_vec*&amp;gt;(q_ptr + vec_idx * VEC_SIZE);
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;对着这块代码讲一下：
可以看到这里因为一个block是专门处理一个token的一个head的，因此把这块数据存在了shared memory里，这样方便复用。&lt;/p&gt;
&lt;p&gt;然后这里又引入了一个叫VEC_SIZE的东西，这里其实就是说如果我想一次读16Bytes(_ld.global.b128), 那每个thead一次要读几个元素(因为一共有thread group个线程一起读)。&lt;/p&gt;
&lt;p&gt;然后就用各种size来算一下每个thread要读多少次vec，这多么元素又对应多少个VEC，我们就知道一个thread具体要读哪些数据了。&lt;/p&gt;
&lt;p&gt;这里thread每次读取的粒度是vec, 而每个thread group每次则读取16Bytes，最后就可以合并成一个向量读的指令来优化IO。&lt;/p&gt;
&lt;p&gt;按这个方式把数据都读进来吗，这里其实很多thread要读的数据是一样的，只要有一份数据完成读取，然后其他thread group就可以直接复用这个数据了&lt;/p&gt;
&lt;h2 id=&#34;key-cache数据访问&#34;&gt;Key Cache数据访问&lt;/h2&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/key_io.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;和Query一样，每个thread按VEC访问数据，也是希望一次访问16Bytes，这也是Query最内层有一个X维度的原因。&lt;/p&gt;
&lt;p&gt;我们每x个元素的大小是16Bytes，那么每个Thread就可以按16Bytes的方式对数据进行读取。&lt;/p&gt;
&lt;p&gt;因为我们需要处理Query Token和所有Key Token的乘积，因此这里要一个block一个block的把所有Key Token读进来。
整个读取过程大概是这样一个三层循环：&lt;/p&gt;
&lt;p&gt;每个Thread Wrap通过循环的方式处理多个Paged Block&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;循环的每次大迭代处理一个Paged Block（内部通过两个小循环处理）
&lt;ul&gt;
&lt;li&gt;内层外循环：遍历block内每个Token (block_size次）
&lt;ul&gt;
&lt;li&gt;内层内循环：遍历每个Token的每个vec  (head_size / (thread_group_size*vec_size))&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样，只要一个Thread Wrap完成读取，Thread Block里其他Thread Wrap会复用这个读取结果。&lt;/p&gt;
&lt;p&gt;看一个这个三重循环的代码：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  // 外层大循环：4个wrap一起遍历所有所有paged blocks
  // 每次循环：每个wrap处理一个paged block
      // 4 个wrap同时执行 （并行度）
  // wrap_idx = thread_is / wrap_size
  for (int block_idx = start_block_idx + warp_idx; block_idx &amp;lt; end_block_idx;
       block_idx += NUM_WARPS) {
    ...
    // Load a key to registers.
    // Each thread in a thread group has a different part of the key.
    // For example, if the the thread group size is 4, then the first thread in
    // the group has 0, 4, 8, ... th vectors of the key, and the second thread
    // has 1, 5, 9, ... th vectors of the key, and so on.
    // 内层外循环：遍历所有paged blocks
    // 每次循环：32个thread一起遍历当前paged block内所有token
        // NUM_TOKENS_PER_THREAD_GROUP =      DIVIDE_ROUND_UP(BLOCK_SIZE, WARP_SIZE);
        // 每个thread group负责一个token(token_idx)
    for (int i = 0; i &amp;lt; NUM_TOKENS_PER_THREAD_GROUP; i++) {
      const int physical_block_offset =
          (thread_group_idx + i * WARP_SIZE) % BLOCK_SIZE;
      const int token_idx = block_idx * BLOCK_SIZE + physical_block_offset;
      K_vec k_vecs[NUM_VECS_PER_THREAD];

#pragma unroll
        // 内层内循环：按 VEC_SIZE 遍历Token内的所有fp16
        // 每次循环：32个thread一起遍历paged block内每个token
            // NUM_ELEMS_PER_THREAD = HEAD_SIZE / THREAD_GROUP_SIZE;
            // NUM_VECS_PER_THREAD = NUM_ELEMS_PER_THREAD / VEC_SIZE;
            // 每个thread group 为一组,处理同一个token
            // 每个threa一次读取一个VEC
            // 每个thread group一共负责 NUM_VECS_PER_THREAD 个VEC
            // K_vec k_vecs[NUM_VECS_PER_THREAD];  (1 Paged Block)
      for (int j = 0; j &amp;lt; NUM_VECS_PER_THREAD; j++) {
        const cache_t* k_ptr =
            k_cache + physical_block_number * kv_block_stride +
            kv_head_idx * kv_head_stride + physical_block_offset * x;
        const int vec_idx = thread_group_offset + j * THREAD_GROUP_SIZE;
        const int offset1 = (vec_idx * VEC_SIZE) / x;
        const int offset2 = (vec_idx * VEC_SIZE) % x;

        if constexpr (KV_DTYPE == Fp8KVCacheDataType::kAuto) {
          k_vecs[j] = *reinterpret_cast&amp;lt;const K_vec*&amp;gt;(
              k_ptr + offset1 * BLOCK_SIZE * x + offset2);
        } else {
          // Vector conversion from Quant_vec to K_vec.
          Quant_vec k_vec_quant = *reinterpret_cast&amp;lt;const Quant_vec*&amp;gt;(
              k_ptr + offset1 * BLOCK_SIZE * x + offset2);
          k_vecs[j] = fp8::scaled_convert&amp;lt;K_vec, Quant_vec, KV_DTYPE&amp;gt;(
              k_vec_quant, *k_scale);
        }
      }

      // Compute dot product.
      ....
  }
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;qk-计算&#34;&gt;QK 计算&lt;/h2&gt;
&lt;p&gt;Query和Key都读进来了，下一步自然就是矩阵乘了，还是先上个图：&lt;/p&gt;
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/query_key_compute.png&#34; class=&#34;center&#34; /&gt;
&lt;p&gt;基础的计算的逻辑就是上面代码里省略的部分&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;      // Compute dot product.
      // This includes a reduction across the threads in the same thread group.
      float qk = scale * Qk_dot&amp;lt;scalar_t, THREAD_GROUP_SIZE&amp;gt;::dot(
                             q_vecs[thread_group_offset], k_vecs);
      // Add the ALiBi bias if slopes are given.
      qk += (alibi_slope != 0) ? alibi_slope * (token_idx - seq_len + 1) : 0;

      if (thread_group_offset == 0) {
        // Store the partial reductions to shared memory.
        // NOTE(woosuk): It is required to zero out the masked logits.
        const bool mask = token_idx &amp;gt;= seq_len;
        logits[token_idx - start_token_idx] = mask ? 0.f : qk;
        // Update the max value.
        qk_max = mask ? qk_max : fmaxf(qk_max, qk);
      }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后要做reduce，因为所有qk的乘积是分布在多个Thread里面的，我们要把Thread block里所有的数据都聚合起来，才好算最后的softmax，这里是经典的两层reduce算法，细节就不解释了。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  // Perform reduction across the threads in the same warp to get the
  // max qk value for each &amp;#34;warp&amp;#34; (not across the thread block yet).
  // The 0-th thread of each thread group already has its max qk value.
#pragma unroll
  // 经典的Thread Wrap内reduce算法
  for (int mask = WARP_SIZE / 2; mask &amp;gt;= THREAD_GROUP_SIZE; mask /= 2) {
    qk_max = fmaxf(qk_max, VLLM_SHFL_XOR_SYNC(qk_max, mask));
  }
  if (lane == 0) {
    red_smem[warp_idx] = qk_max;
  }
  __syncthreads();

  // 经典的Thread Block内reduce算法
  // TODO(woosuk): Refactor this part.
  // Get the max qk value for the sequence.
  qk_max = lane &amp;lt; NUM_WARPS ? red_smem[lane] : -FLT_MAX;
#pragma unroll
  for (int mask = NUM_WARPS / 2; mask &amp;gt;= 1; mask /= 2) {
    qk_max = fmaxf(qk_max, VLLM_SHFL_XOR_SYNC(qk_max, mask));
  }
  // Broadcast the max qk value to all threads.
  qk_max = VLLM_SHFL_SYNC(qk_max, 0);

  // 计算softmax
  // Get the sum of the exp values.
  float exp_sum = 0.f;
  for (int i = thread_idx; i &amp;lt; num_tokens; i += NUM_THREADS) {
    float val = __expf(logits[i] - qk_max);
    logits[i] = val;
    exp_sum += val;
  }
  exp_sum = block_sum&amp;lt;NUM_WARPS&amp;gt;(&amp;amp;red_smem[NUM_WARPS], exp_sum);

  // Compute softmax.
  const float inv_sum = __fdividef(1.f, exp_sum + 1e-6f);
  for (int i = thread_idx; i &amp;lt; num_tokens; i += NUM_THREADS) {
    logits[i] *= inv_sum;
  }
  __syncthreads();
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;跑到这里以后，softmax就算完了，剩下来的就是在乘一下V Cache，这块就比较简单了。&lt;/p&gt;
&lt;h2 id=&#34;value访问和attneion计算&#34;&gt;Value访问和Attneion计算&lt;/h2&gt;
&lt;p&gt;Value的访问比较直接，直接上图，就是大家一起把所有Value都读进来。
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/value_io.png&#34; class=&#34;center&#34; /&gt;&lt;/p&gt;
&lt;p&gt;同时边读边计算，都在这个图里了：
&lt;img width=&#34;800&#34;  src=&#34;https://sword865.github.io/images/2025/20250420/attention_compute.png&#34; class=&#34;center&#34; /&gt;&lt;/p&gt;
&lt;p&gt;就是先按block进行遍历，然后每次重block里读所有token的一部分维度进行计算，把所有维度都算出来，分散的存在各个thread里。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;  // 一样的外层大循环：4个wrap一起遍历所有paged blocks
  for (int block_idx = start_block_idx + warp_idx; block_idx &amp;lt; end_block_idx;
       block_idx += NUM_WARPS) {
    // NOTE(woosuk): The block number is stored in int32. However, we cast it to
    // int64 because int32 can lead to overflow when this variable is multiplied
    // by large numbers (e.g., kv_block_stride).

    const int64_t physical_block_number =
        static_cast&amp;lt;int64_t&amp;gt;(block_table[block_idx]);
    const int physical_block_offset = (lane % NUM_V_VECS_PER_ROW) * V_VEC_SIZE;
    const int token_idx = block_idx * BLOCK_SIZE + physical_block_offset;
    L_vec logits_vec;
    from_float(logits_vec, *reinterpret_cast&amp;lt;Float_L_vec*&amp;gt;(logits + token_idx -
                                                           start_token_idx));

    const cache_t* v_ptr = v_cache + physical_block_number * kv_block_stride +
                           kv_head_idx * kv_head_stride;
#pragma unroll

    // NUM_V_VECS_PER_ROW = BLOCK_SIZE / V_VEC_SIZE;
    // 一个Paged Block有几个VEC
    // NUM_ROWS_PER_ITER = WARP_SIZE / NUM_V_VECS_PER_ROW;
        // 一个WRAP可以同时处理几个 Paged Block 
    // NUM_ROWS_PER_THREAD = DIVIDE_ROUND_UP(HEAD_SIZE, NUM_ROWS_PER_ITER);
        // 遍历所有head纬度需要几个迭代
    for (int i = 0; i &amp;lt; NUM_ROWS_PER_THREAD; i++) {
      const int row_idx = lane / NUM_V_VECS_PER_ROW + i * NUM_ROWS_PER_ITER;
      if (row_idx &amp;lt; HEAD_SIZE) {
        const int offset = row_idx * BLOCK_SIZE + physical_block_offset;
        V_vec v_vec;

        if constexpr (KV_DTYPE == Fp8KVCacheDataType::kAuto) {
          v_vec = *reinterpret_cast&amp;lt;const V_vec*&amp;gt;(v_ptr + offset);
        } else {
          V_quant_vec v_quant_vec =
              *reinterpret_cast&amp;lt;const V_quant_vec*&amp;gt;(v_ptr + offset);
          // Vector conversion from V_quant_vec to V_vec.
          v_vec = fp8::scaled_convert&amp;lt;V_vec, V_quant_vec, KV_DTYPE&amp;gt;(v_quant_vec,
                                                                    *v_scale);
        }
        if (block_idx == num_seq_blocks - 1) {
          // num_seq_blocks = DIVIDE_ROUND_UP(seq_len, BLOCK_SIZE);
          // 对最后一个Paged Block特殊处理，防止越界
          // NOTE(woosuk): When v_vec contains the tokens that are out of the
          // context, we should explicitly zero out the values since they may
          // contain NaNs. See
          // https://github.com/vllm-project/vllm/issues/641#issuecomment-1682544472
          scalar_t* v_vec_ptr = reinterpret_cast&amp;lt;scalar_t*&amp;gt;(&amp;amp;v_vec);
#pragma unroll
          for (int j = 0; j &amp;lt; V_VEC_SIZE; j++) {
            v_vec_ptr[j] = token_idx + j &amp;lt; seq_len ? v_vec_ptr[j] : zero_value;
          }
        }

        // 按Vec分段计算和V的乘积：由多个thread计算，后续需要进一步聚合。
        accs[i] += dot(logits_vec, v_vec);
      }
    }
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;等算法以后再进行reduce把结果聚合，得到最后的结果。这个是经典的reduce算法：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// Perform reduction within each warp.
// 经典in wrap规约算法
#pragma unroll
  for (int i = 0; i &amp;lt; NUM_ROWS_PER_THREAD; i++) {
    float acc = accs[i];
#pragma unroll
    for (int mask = NUM_V_VECS_PER_ROW / 2; mask &amp;gt;= 1; mask /= 2) {
      acc += VLLM_SHFL_XOR_SYNC(acc, mask);
    }
    accs[i] = acc;
  }

  // NOTE(woosuk): A barrier is required because the shared memory space for
  // logits is reused for the output.
  __syncthreads();

  // Perform reduction across warps.
  // 经典树状cross wrap规约算法
  float* out_smem = reinterpret_cast&amp;lt;float*&amp;gt;(shared_mem);
#pragma unroll
  for (int i = NUM_WARPS; i &amp;gt; 1; i /= 2) {
    int mid = i / 2;
    // Upper warps write to shared memory.
    if (warp_idx &amp;gt;= mid &amp;amp;&amp;amp; warp_idx &amp;lt; i) {
      float* dst = &amp;amp;out_smem[(warp_idx - mid) * HEAD_SIZE];
#pragma unroll
      for (int i = 0; i &amp;lt; NUM_ROWS_PER_THREAD; i++) {
        const int row_idx = lane / NUM_V_VECS_PER_ROW + i * NUM_ROWS_PER_ITER;
        if (row_idx &amp;lt; HEAD_SIZE &amp;amp;&amp;amp; lane % NUM_V_VECS_PER_ROW == 0) {
          dst[row_idx] = accs[i];
        }
      }
    }
    __syncthreads();

    // Lower warps update the output.
    if (warp_idx &amp;lt; mid) {
      const float* src = &amp;amp;out_smem[warp_idx * HEAD_SIZE];
#pragma unroll
      for (int i = 0; i &amp;lt; NUM_ROWS_PER_THREAD; i++) {
        const int row_idx = lane / NUM_V_VECS_PER_ROW + i * NUM_ROWS_PER_ITER;
        if (row_idx &amp;lt; HEAD_SIZE &amp;amp;&amp;amp; lane % NUM_V_VECS_PER_ROW == 0) {
          accs[i] += src[row_idx];
        }
      }
    }
    __syncthreads();
  }
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;算完以后就是把结果写到output了，这块就不贴了。&lt;/p&gt;
&lt;h2 id=&#34;收尾&#34;&gt;收尾&lt;/h2&gt;
&lt;p&gt;大概流程就是这样，整个流程还是设计不少细节的，我也不知道写清楚没有，不过对着代码多看几遍总能看明白的。&lt;/p&gt;
- https://sword865.github.io/posts/2025/2025-04-20-vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>Google Small Towers中多目标优化的探索</title>
        <link>https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/</link>
        <pubDate>Mon, 08 Mar 2021 15:51:35 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/ -&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;多目标优化中有一个很常见的跷跷板问题，就是说在训练时，多个目标会相互影响，导致震荡&amp;mdash;你降我升，我升你降。有时间还会出现Nan的结果，需要很仔细的调参测试+清洗数据才能训练出一个理想的模型。&lt;/p&gt;
&lt;p&gt;针对这种问题，自然就有了一些尝试，比如从帕累托最优的角度寻找优化方向（阿里PEA），修改模型结构使Shared部分存储更泛化的信息（腾讯PLE）。不过这两个写的人都挺多了，就写一下Google Small Towers的这篇文章吧。&lt;/p&gt;
&lt;h2 id=&#34;主要问题讨论&#34;&gt;主要问题讨论&lt;/h2&gt;
&lt;p&gt;文章首先讨论了两个问题：&lt;/p&gt;
&lt;h3 id=&#34;1-over-parameterization对多任务模型的适用性&#34;&gt;1. Over-parameterization对多任务模型的适用性&lt;/h3&gt;
&lt;p&gt;我们都知道over-parameterization对单任务模型是有价值的，那边对多任务模型是否成立？&lt;/p&gt;
&lt;p&gt;这里以将多个目标的线性组合作为优化目标的例子，认为over-parameterization能够帮助处理各任务优化目标之间的冲突问题（既减少跷跷板问题的出现）。&lt;/p&gt;
&lt;h3 id=&#34;2-大型模型和小型模型的多目标学习表现对比&#34;&gt;2. 大型模型和小型模型的多目标学习表现对比&lt;/h3&gt;
&lt;p&gt;通过实验对比了大型模型和小型模型进行多目标学习中的不同表现。&lt;/p&gt;
&lt;p&gt;实验中，不论是增加任务相关结构的复杂度，还是增加任务共享结构的复杂度，Pareto frontier都会呈现先变好在变差的趋势。&lt;/p&gt;
&lt;p&gt;因此，文章认为over-parameterization并不利于多目标学习中的共享性，进而伤害了多目标学习中的泛化能力。因此，在多目标学习中，模型大小实质上是对模型有效性和泛化能力的一种平衡。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To summarize our insights, for a multi-task learning model, small models benefit from good multi-task generalization but hurts Pareto efficiency; big models theoretically have better Pareto efficiency but could suffer from loss of generalization.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;under-parameterized-self-auxiliaries模型结构&#34;&gt;Under-parameterized Self-auxiliaries模型结构&lt;/h2&gt;
&lt;p&gt;文章提出了under-parameterized self-auxiliaries的模型结构：&lt;/p&gt;
&lt;p&gt;首先假设模型的共享方式是所有任务共享最下面的表示层（Hard Sharded，MMOE这种，PLE就不行）,既对任务t，有：&lt;/p&gt;
&lt;p&gt;$$f_{t}(x; \theta_{sh}, \theta_{t})=f_{t}(h(x; \theta_{sh}); \theta_{t}), \forall t$$&lt;/p&gt;
&lt;p&gt;其中 $\theta_t$ 是任务相关的参数， $\theta_sh$ 为共享参数， $h(x;\theta_sh)$ 既为共享的表示层输出。&lt;/p&gt;
&lt;p&gt;文章在这个基础上对每个任务t增加了self-auxiliary tower的附属结构(既一个辅助任务的small tower)，该小塔输出和原来的任务相同，但参数 $\theta_t^{a}$ 很小（既小塔是一个很简单的结构）:&lt;/p&gt;
&lt;p&gt;$$f_t^a(x; \theta_{sh}, \theta_t^a))=f_t(h(x;\theta_{sh}); \theta_t^a), \forall t$$&lt;/p&gt;
&lt;h3 id=&#34;修改后的多目标模型结构&#34;&gt;修改后的多目标模型结构&lt;/h3&gt;
&lt;p&gt;修改后多目标模型的结构是这样的：&lt;/p&gt;
&lt;img width=&#34;500&#34;  src=&#34;https://sword865.github.io/images/2021/google_m_towner.png&#34; class=&#34;center&#34; /&gt;
&lt;h3 id=&#34;损失函数&#34;&gt;损失函数&lt;/h3&gt;
&lt;p&gt;最后的Loss则是在原来的基础上加上了小塔的Loss:&lt;/p&gt;
&lt;p&gt;$$\hat{L}(\theta)=\sum_{t=1}^Tw_t(\hat{L}(\theta_{sh},\theta_t)+\gamma \hat{L}(\theta_{sh},\theta_t^a))$$&lt;/p&gt;
&lt;p&gt;其中： $$\hat{L}(\theta_{sh},\theta_t^a))=\frac{1}{n}\sum_{i=1}^nL_t(f_t^a(x; \theta_{sh}, \theta_t^a)), y_i^t)$$&lt;/p&gt;
&lt;p&gt;这么改的原因自然就是前面的推理了：通过使用较小的模型来提高任务对不同的泛化能力。（任务量变成了原来的两倍，但是其中有一半任务是under-parameterized，因此也就降低了模型over-parameterized对共享性的破坏力）。&lt;/p&gt;
&lt;p&gt;文章认为，这种通过强迫模型学习共享层来提高复数任务的的结构也是一种正则化的手段。&lt;/p&gt;
&lt;h2 id=&#34;小塔结构示例&#34;&gt;小塔结构示例&lt;/h2&gt;
&lt;p&gt;这里对小塔的结构没有什么限制，唯一的要求就是要比模型简单，下面是文章里的一些例子：&lt;/p&gt;
&lt;img src=&#34;https://sword865.github.io/images/2021/google_m_tower_small_tower.png&#34; /&gt;
&lt;p&gt;最后主要就是附录中的证明与实验细节了，建议直接读原文了解。&lt;/p&gt;
&lt;h2 id=&#34;注释与思考&#34;&gt;注释与思考&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;注1&lt;/strong&gt;: Over-Parameterization的说明见&amp;quot;&lt;a href=&#34;https://arxiv.org/abs/1812.11118&#34;&gt;Reconciling modern machine-learning practice and the classical bias–variance trade-off&lt;/a&gt;&amp;ldquo;和&amp;rdquo;&lt;a href=&#34;https://arxiv.org/abs/1903.07571&#34;&gt;Two models of double descent for weak features&lt;/a&gt;&amp;ldquo;等文章，或者&lt;a href=&#34;https://www.zhihu.com/question/434311126&#34;&gt;知乎相关讨论&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注2&lt;/strong&gt;: 有意思的是Small Tower通过小塔来提升大塔多任务的效果，而阿里的Rocket Launching则是通过大塔来提高小塔的效果，这两个模型放在一起会怎么样呢。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注3&lt;/strong&gt;: 最近发现还有一篇修改优化算法的文章：Gradient Surgery for Multi-Task Learning，不过还没来得急细看，等有空了试试对我们的任务有没有帮助。&lt;/p&gt;
- https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>推荐系统周边设施--特征商店</title>
        <link>https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/</link>
        <pubDate>Sun, 07 Mar 2021 15:51:35 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/ -&lt;p&gt;好久没写博客了，今天写一点推荐系统周边设施的东西。&lt;/p&gt;
&lt;h2 id=&#34;特征管理&#34;&gt;特征管理&lt;/h2&gt;
&lt;p&gt;特征商店会存储特征元数据，比如特征的计算逻辑、血缘关系、数据类型。 一般来说，这些元数据用于管理特征的生命周期、计算任务和使用方式。&lt;/p&gt;
&lt;h2 id=&#34;离线训练数据生成&#34;&gt;离线训练数据生成&lt;/h2&gt;
&lt;p&gt;为了保证线上线下数据的一致性，推荐系统的训练数据通常有两个数据流Join得到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在Ranking中即实时打点：数据流以&lt;code&gt;traceId&lt;/code&gt;为Key，排序时特征为Value。&lt;/li&gt;
&lt;li&gt;客户端日志：记录了&lt;code&gt;traceId&lt;/code&gt;和事件类型(曝光、点击、分享等）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于客户端日志必然晚于服务端日志，因此两个数据流Join时需要一定的窗口。&lt;/p&gt;
&lt;h2 id=&#34;训练数据扩展&#34;&gt;训练数据扩展&lt;/h2&gt;
&lt;p&gt;但是作为调参工程师，我们必然会遇到需要的特征没有记录在实时打点中，导致训练时缺少相关数据的情况，这个时候，就需要想办法来处理这个问题。&lt;/p&gt;
&lt;p&gt;按照Uber的方法，我们可以把特征分为三类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;离线特征&lt;/li&gt;
&lt;li&gt;实时特征&lt;/li&gt;
&lt;li&gt;RPC特征&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;离线特征&#34;&gt;离线特征&lt;/h3&gt;
&lt;p&gt;对于离线特征：我们可以使用Spark读取数据仓库中的历史数据，以天为单位进行生成历史数据，然后放在一个分区的Hive表中。&lt;/p&gt;
&lt;h3 id=&#34;实时特征&#34;&gt;实时特征&lt;/h3&gt;
&lt;p&gt;对于实时特征：基于kappa的思想，我们可以在Flink中编写实时特征计算逻辑，然后启动重跑一段时间以前的历史数据，并记录这个过程中特征的每一次变化（有点类似数据库中的WAL日志流），将其输出到Kafka中去，这样我们也就有一个特征在历史时间段中的值。(这里我们最好有一个服务化的Flink平台，来进行任务的添加、删除、修改等工作)&lt;/p&gt;
&lt;p&gt;这里，特征的计算任务就可以通过特征元数据库进行管理。&lt;/p&gt;
&lt;p&gt;接下来，我们就可以通过带时间戳的Join来完成训练数据和特征数据的拼接，并将特征回写到训练数据中去了。 需要注意的是，为了保证线上线下数据的一致性，我们需要引入一定的延时机制来模拟客户端日志的延迟。&lt;/p&gt;
&lt;h3 id=&#34;rpc特征&#34;&gt;RPC特征&lt;/h3&gt;
&lt;p&gt;最后对于来自外部系统的RPC特征：就没有什么好办法了，我们只能在线上添加这个特征的打点，然后跑上一段时间来得到有这个特征的训练数据了。&lt;/p&gt;
&lt;p&gt;这里推荐一个比较新的开源项目可以完成类似的工作: &lt;a href=&#34;https://github.com/feast-dev/feast&#34;&gt;Feast&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;在线特征推送&#34;&gt;在线特征推送&lt;/h2&gt;
&lt;p&gt;特征的线上存储可以使用KV数据库比如Redis，数据的来源和上面训练数据的扩展可以使用同一套代码，只需要在计算时根据元数据配置来决定是否推送上线。&lt;/p&gt;
&lt;p&gt;另外，这里一般会做很多工程上的优化，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把多个特征作为一个特征组存在一个key里减少请求的次数&lt;/li&gt;
&lt;li&gt;使用一些算法（比如XXHash32）对过长的特征名(比如&lt;code&gt;spu$realtime$orders_last_2w$spu_id&lt;/code&gt;)进行压缩&lt;/li&gt;
&lt;/ul&gt;
- https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>NPE问题与一些语言中的解决方案</title>
        <link>https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
        <pubDate>Thu, 08 Nov 2018 23:51:35 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/ -&lt;p&gt;NPE(NullPointerException)是一个很烦人的问题，这里简单列举了一些语言中对NPE的处理。&lt;/p&gt;
&lt;h2 id=&#34;1-通过语法标记进行检查&#34;&gt;1. 通过语法标记进行检查&lt;/h2&gt;
&lt;h3 id=&#34;kotlin&#34;&gt;Kotlin&lt;/h3&gt;
&lt;p&gt;Kotlin要求可以为null的变量必需在定义时声明，同时在读取该类型变量属性时必须进行空值判断。例：String 和 String?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-kotlin&#34; data-lang=&#34;kotlin&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; a: String = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a = &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// compilation error, a can not be null
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; b: String? = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b = &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// ok
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; l = b.length &lt;span style=&#34;color:#75715e&#34;&gt;// compiler error: variable &amp;#39;b&amp;#39; can be null
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; l = &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (b &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) b.length &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; -&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// ok
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;jetbrains-annotations-for-java&#34;&gt;Jetbrains annotations for Java&lt;/h3&gt;
&lt;p&gt;IntelliJ IDEA提供了一些工具，比如可以对@NotNull的参数进行检查，当出现null赋值时在IDE中会给出提示。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.jetbrains.annotations.NotNull;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.ArrayList;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Test&lt;/span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foo&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;@NotNull&lt;/span&gt; Object param){
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; param.&lt;span style=&#34;color:#a6e22e&#34;&gt;hashCode&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;test&lt;/span&gt;(){
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        foo(&lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;// warn in IntelliJ IDEA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;（类似的，FindBugs也提供了@Nonnull注释，用于检查）&lt;/p&gt;
&lt;h3 id=&#34;lombok-for-java&#34;&gt;Lombok for Java&lt;/h3&gt;
&lt;p&gt;Lombok通过在编译时改写字节码对原始代码进行优化，其中的@NonNull，会自动插入运行时检查代码，发现错误抛出异常。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;NonNullExample&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;@NonNull&lt;/span&gt; Person person) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;super&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; person.&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等价于&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;NonNullExample&lt;/span&gt;(Person person) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (person &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;throw&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; NullPointerException(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;person is marked @NonNull but is null&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;super&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello&amp;#34;&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;name&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; person.&lt;span style=&#34;color:#a6e22e&#34;&gt;getName&lt;/span&gt;();
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2-用更好的错误处理代替null&#34;&gt;2. 用更好的错误处理代替null&lt;/h2&gt;
&lt;p&gt;空值通常都是由错误导致的无法赋值，因此更好的错误处理也是NPE的一种应对。&lt;/p&gt;
&lt;h3 id=&#34;rust基于result错误处理&#34;&gt;Rust：基于Result错误处理&lt;/h3&gt;
&lt;p&gt;Rust通过Result类型提供了强大的错误处理机制。&lt;/p&gt;
&lt;h3 id=&#34;基于monad处理错误&#34;&gt;基于Monad处理错误&lt;/h3&gt;
&lt;p&gt;Scala等FP语言基于Monad(Option, Either, Try&amp;hellip;)提供了错误处理，其中Optional是最基础的一种。在Option中，定义了专门的None来表示计算失败。这样，在得不到结果时，就会得到None，因此在后续的使用中可以使用isDefined先判断是否有值，再进行处理：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; name&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Option&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;String&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; request getParameter &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isDefined&lt;span style=&#34;color:#f92672&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;//do some stuff with name.get
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是这么写很不方便，还是更推荐使用flatMap乃至for推导式来进行计算。(for-yield推导式其实就是flatmap和map的语法糖)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; upper &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name &lt;span style=&#34;color:#66d9ef&#34;&gt;&amp;lt;-&lt;/span&gt; request getParameter &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  trimmed &lt;span style=&#34;color:#66d9ef&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Some&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trim&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  upper &lt;span style=&#34;color:#66d9ef&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Some&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;trimmed&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toUpperCase&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; trimmed&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;length &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;yield&lt;/span&gt; upper
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;println&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;upper getOrElse &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于Option只能用None表示失败，不能记录错误信息，所以scala中还提供了Either用来携带更多的信息。&lt;/p&gt;
&lt;h3 id=&#34;optional-in-java&#34;&gt;Optional in Java&lt;/h3&gt;
&lt;p&gt;Java中的Optional跟scala里的Option是很相似的，同样提供了flatMap操作。但是因为没有for推导式，用起来就感觉不太方便。另外，Java中也缺少可以携带错误信息的Either。&lt;/p&gt;
- https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>比较一下spark2的DataFrame和RDD</title>
        <link>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</link>
        <pubDate>Sun, 12 Mar 2017 15:49:45 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/ -&lt;p&gt;前段时间把spark集群升级到2.x，使用起来感觉相对1.x的版本最大的改动就是DataFrame正式开始替代RDD成为主流，包括我们最常用到的mllib的官方文档也提到：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.
After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.
The RDD-based API is expected to be removed in Spark 3.0.
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;rdd的结构&#34;&gt;RDD的结构&lt;/h4&gt;
&lt;p&gt;RDD可以看成是一个分布式的无序列表，这个列表内的元素是一个object，RDD并不关心每个object的内部结构。因此所有操作都必须对这个object进行，不利于算子的复用。&lt;/p&gt;
&lt;p&gt;比起DataFrame，RDD更方便我们对数据做一些底层的操作，也可以用于unstructured的数据。&lt;/p&gt;
&lt;h4 id=&#34;dataframe的结构&#34;&gt;DataFrame的结构&lt;/h4&gt;
&lt;p&gt;DataFrame不同于RDD，框架会去了解object中的数据是什么样的结构，这样每个算子就可以单独实现在某个列上，复用起来就更加简单。&lt;/p&gt;
&lt;p&gt;因为DataFrame比RDD多个更多的限制，对内部的元素也有了更多的了解，可以使用SQL语句进行操作，因此也就可以在对DataFrame进行操作时使用Spark SQL的Catalyst优化器进行优化。&lt;/p&gt;
&lt;p&gt;Catalyst一个易于扩展的查询优化器，同时支持基于规则(rule-based)和基于代价(cost-based)的优化方法，我们可以基于相关API自己定义优化规则。&lt;/p&gt;
&lt;p&gt;最后，Spark的Tungsten目前还只支持DataFrame API, 因此在使用RDD时不能享受到Tungsten带来的效率优化。（Tungsten做的优化概括起来说就是由Spark自己来管理内存而不是使用JVM，这样可以避免JVM GC带来的性能损失）&lt;/p&gt;
&lt;h4 id=&#34;dataset数据结构&#34;&gt;DataSet数据结构&lt;/h4&gt;
&lt;p&gt;前面提到DataFrame每一个record对应了一个Row。而Dataset的定义更加宽松，每一个record对应了一个任意的类型。实际上，从源码中可以看到，DataFrame就是Dataset的一种特例。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package object sql {
    ...
    type DataFrame = Dataset[Row]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DataSet和DataFrame可以通过df.as和ds.toDF方法方便的进行转化。&lt;/p&gt;
&lt;p&gt;不同于Row是一个泛化的无类型JVM object, Dataset是由一系列的强类型JVM object组成的，因此DataSet可以在编译时进行类型检查。&lt;/p&gt;
&lt;p&gt;比起RDD，DataSet的API也以Spark SQL引擎为基础，因此在对DataSet进行操作时，同样可以从Catalyst优化器中受益。&lt;/p&gt;
&lt;p&gt;基本上，我觉得DataSet集合了RDD和DataSet两者的优点。&lt;/p&gt;
&lt;h4 id=&#34;关于效率&#34;&gt;关于效率&lt;/h4&gt;
&lt;p&gt;最后，在效率上，在使用RDD的API时候，使用Python明显比Scala要慢上很多（据我们测试是慢了2倍以上）。但是在使用DataFame时，这个缺陷就不复存在了，换句话说，喜欢Python或者放不下各种Python扩展的同志们可以把Python写起来了，哈哈。这里放个国外网友测试的效率比较吧：&lt;/p&gt;
&lt;img src=&#34;https://sword865.github.io/images/2017/Spark_Dataframe_Official_Benchmark.png&#34; /&gt;
&lt;p&gt;可以看到，速度上大致是 Scala DF = Python DF &amp;gt; Scala RDD &amp;gt; Python RDD，并且DF优势很显著。&lt;/p&gt;
&lt;h4 id=&#34;其他参考资料&#34;&gt;其他参考资料&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hustnn/TungstenSecret&#34;&gt;探索Spark Tungsten的秘密&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.iteblog.com/archives/1706.html&#34;&gt;Spark 2.0介绍：在Spark SQL中定义查询优化规则&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.infoq.com/cn/articles/2015-Review-Spark&#34;&gt;http://www.infoq.com/cn/articles/2015-Review-Spark&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com/questions/37301226/difference-between-dataset-api-and-dataframe&#34;&gt;http://stackoverflow.com/questions/37301226/difference-between-dataset-api-and-dataframe&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html&#34;&gt;https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://0x0fff.com/spark-dataframes-are-faster-arent-they/&#34;&gt;https://0x0fff.com/spark-dataframes-are-faster-arent-they/&lt;/a&gt;&lt;/p&gt;
- https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>谈谈Factorization Machine</title>
        <link>https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/</link>
        <pubDate>Fri, 04 Nov 2016 22:47:21 +0800</pubDate>
        
        <guid>https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/ -&lt;p&gt;因子分解机(Factorization Machine, 简称FM)是一种不错的CTR预估模型，也是我们现在在使用的广告点击率预估模型，比起著名的Logistic Regression, FM能够把握一些组合的高阶特征，因此拥有更强的表现力。&lt;/p&gt;
&lt;p&gt;在做点击率预估时，我们的特征往往来自于用户(user)、广告(item)和上下文环境(context)，在线性模型中，这些特征不进行组合的话，就会发生一个很尴尬的情况，因为：&lt;/p&gt;
&lt;div&gt;$$score = f(w_{user} * x_{user} + w_{item} * x_{item} + w_{contex} * x_{contex})$$&lt;/div&gt;
&lt;p&gt;所以，对所有用户&amp;ndash;我们将得到相同的排序。&lt;/p&gt;
&lt;p&gt;因此我们需要引入一些组合特征作为输入模型，然而仅二阶特征组合的可能性就是原始特征的平方之多，但是由于很多特征其实是相互独立的，他们的组合并没有什么价值。FM就是一种能够自动把握一些高阶特征的点击率预估模型，可以自动帮助使用者选择合适的高阶输入。&lt;/p&gt;
&lt;p&gt;我们先写出带有所有二阶组合特征的目标函数，其中矩阵W中有n^2个参数，求解非常复杂：&lt;/p&gt;
&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{ij} x_i x_j$$&lt;/div&gt;
&lt;p&gt;我们都知道在矩阵分解的协同过滤中中，我们认为每个用户可以表示成一个K维的特征向量$u_k$,每个物品也能表示成一个高维向量$i_k$，这样用户与物品的相关性就可以用两个向量的点击表示，所有用户与所有物品的相关性就可以用两个矩阵相乘的形式表示出来了。&lt;/p&gt;
&lt;p&gt;FM的模型参考了矩阵分解的思想，认为每个特征 $x_i$都可以用一个K维的特征向量$v_i$表示，那么所有特征之前的相关性就也就可以用两个矩阵的相乘进行表示了，模型表示如下：&lt;/p&gt;
&lt;p&gt;其中矩阵W中代表了特征的特征向量的內积，既：$w_{ij}=v_i v_j$，所以，公式可以改写为:&lt;/p&gt;
&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} v_{i} v_{j} x_i x_j$$&lt;/div&gt;
&lt;p&gt;也就是：&lt;/p&gt;
&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \sum_{h=i}^{k} v_{i,h} v_{j,h} x_i x_j$$&lt;/div&gt;
&lt;p&gt;可以看出，W中的参数现在只有nk个了，因为一般有k&amp;laquo;n，所以FM大大降低的目标函数的复杂度。推导可得梯度公式：&lt;/p&gt;
&lt;div&gt;$δy/δw_{0}=1$&lt;/div&gt;
&lt;div&gt;$δy/δw_{i}=x_{i},i=1...n$&lt;/div&gt;
&lt;div&gt;$δy/δv_{i,k}=x_{i}\sum{j \neq i} v_{j,k}x_{j}$&lt;/div&gt;
&lt;p&gt;FM的优化可以用SGD来做，不过这里推荐带动量（momentum）的min-batch SGD算法，试验中比普通的SGD效果似乎更好。带momentum的SGD模拟了物品运动中的惯性。&lt;/p&gt;
&lt;p&gt;在传统的SGD中：&lt;span&gt;$x_{t+1}=x_t+Δx_t,Δx_t=-ŋg_t$&lt;/span&gt; ,其中 $g_t$代表了梯度。而在momentum的SGD中：$Δx_t=px_{t-1}-ŋg_t$。&lt;/p&gt;
&lt;p&gt;不过比起LR, FM有一个缺点&amp;ndash;目标函数是非凸的，虽然针对这个缺点也有一些研究比如一些凸函数形式的FM，不过在实践中似乎这并不是一个很严重的问题，合适的初始化方式和优化方法一般是能够给出一个可以接受的解的。&lt;/p&gt;
&lt;p&gt;FM的另外一个缺点是有点耗费内存，对于每个特征都要用一个K维的向量表示导致参数数量是LR的K倍，这方面也是有一些研究的，比如李沐针对这个问题提出的DiFacto就是一个很好的能够降低内存消耗的优化方案。&lt;/p&gt;
&lt;p&gt;最后，还有一种著名的策略是FFM模型，FFM模型被称为FM的升级版，把同一类的特征（比如一些用01向量编码的的离散特征）归到一个field里去，然后要求每个特征在每个field下都有一个不同的K维表示方式，这一下把参数的数量从K变成了FK(F是field的数量)，模型复杂度变的更高了。不过这样做的效果确实不错。&lt;/p&gt;
- https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>Elasticsearch-HttpServerModule</title>
        <link>https://sword865.github.io/posts/archives/2015-07-27-elasticsearch-httpservermodule/</link>
        <pubDate>Mon, 27 Jul 2015 00:00:00 +0000</pubDate>
        
        <guid>https://sword865.github.io/posts/archives/2015-07-27-elasticsearch-httpservermodule/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/archives/2015-07-27-elasticsearch-httpservermodule/ -&lt;p&gt;HttpServerModule的请求主要由HttpServer中的HttpServerTransport （默认为NettyHttpServerTransport）类处理。&lt;/p&gt;
&lt;p&gt;NettyHttpServerTransport基于netty框架，负责监听并建立连接，信息的处理由内部类HttpChannelPipelineFactory 完成。&lt;/p&gt;
&lt;p&gt;每当产生一个连接时，都会发出一个ChannelEvent，该Event由一系列的ChannelHandler进行处理。&lt;/p&gt;
&lt;p&gt;为了方便组织，这些ChannelHandler被放在一条“流(pipeline)”里，一个ChannelEvent并不会主动的”流”经所有的Handler，而是由上一个Handler显式的调用ChannelPipeline.sendUp(Down)stream产生，并交给下一个Handler处理。&lt;/p&gt;
&lt;p&gt;换句话说，每个Handler接收到一个ChannelEvent，并处理结束后，如果需要继续处理，那么它需要调用sendUp(Down)stream新发起一个事件。如果它不再发起事件，那么处理就到此结束，即使它后面仍然有Handler没有执行。这个机制可以保证最大的灵活性，当然对Handler的先后顺序也有了更严格的要求。&lt;/p&gt;
&lt;p&gt;在流Pipeline里有一个Map(name2ctx)和一个链表(记录head和tail)，pipeline里面会调度关联的多个channelhandler的运行。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://sword865.github.io/images/archives/0753391.png&#34;&gt;&lt;img src=&#34;https://sword865.github.io/images/archives/0753391.png&#34; alt=&#34;channel pipeline&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在NettyHttpServerTransport中，会流过的channelhandler就包括解码http请求(把多个HttpChunk拼起来并按http协议进行解析)和http请求处理。&lt;/p&gt;
&lt;p&gt;在处理http请求，数据流向为：HttpRequestHandler-&amp;gt;&lt;span class=&#34;s1&#34;&gt;NettyHttpServerTransport&lt;/span&gt;-&amp;gt;HttpServerAdapter(HttpServer的内部类Dispatche)-&amp;gt;RestController。&lt;/p&gt;
&lt;p&gt;RestController中的处理代码为：&lt;/p&gt;
&lt;pre class=&#34;lang:java decode:true &#34;&gt;
void executeHandler(RestRequest request, RestChannel channel) throws Exception {
        final RestHandler handler = getHandler(request);
        if (handler != null) {
            handler.handleRequest(request, channel);
        } else {
            if (request.method() == RestRequest.Method.OPTIONS) {
                // when we have OPTIONS request, simply send OK by default 
                // (with the Access Control Origin header which gets automatically added)
                channel.sendResponse(new BytesRestResponse(OK));
            } else {
                channel.sendResponse(new BytesRestResponse(
                    BAD_REQUEST, 
                    &#34;No handler found for uri [&#34; + request.uri() + &#34;] and method [&#34; + request.method() + &#34;]&#34;
                ));
            }
        }
    }

    private RestHandler getHandler(RestRequest request) {
        String path = getPath(request);
        RestRequest.Method method = request.method();
        if (method == RestRequest.Method.GET) {
            return getHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.POST) {
            return postHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.PUT) {
            return putHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.DELETE) {
            return deleteHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.HEAD) {
            return headHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.OPTIONS) {
            return optionsHandlers.retrieve(path, request.params());
        } else {
            return null;
        }
    }&lt;/pre&gt;
&lt;p&gt;void executeHandler(RestRequest request, RestChannel channel) throws Exception {
final RestHandler handler = getHandler(request);
if (handler != null) {
handler.handleRequest(request, channel);
} else {
if (request.method() == RestRequest.Method.OPTIONS) {
// when we have OPTIONS request, simply send OK by default (with the Access Control Origin header which gets automatically added)
channel.sendResponse(new BytesRestResponse(OK));
} else {
channel.sendResponse(new BytesRestResponse(BAD_REQUEST, &amp;ldquo;No handler found for uri [&amp;rdquo; + request.uri() + &amp;ldquo;] and method [&amp;rdquo; + request.method() + &amp;ldquo;]&amp;rdquo;));
}
}
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private RestHandler getHandler(RestRequest request) {
    String path = getPath(request);
    RestRequest.Method method = request.method();
    if (method == RestRequest.Method.GET) {
        return getHandlers.retrieve(path, request.params());
    } else if (method == RestRequest.Method.POST) {
        return postHandlers.retrieve(path, request.params());
    } else if (method == RestRequest.Method.PUT) {
        return putHandlers.retrieve(path, request.params());
    } else if (method == RestRequest.Method.DELETE) {
        return deleteHandlers.retrieve(path, request.params());
    } else if (method == RestRequest.Method.HEAD) {
        return headHandlers.retrieve(path, request.params());
    } else if (method == RestRequest.Method.OPTIONS) {
        return optionsHandlers.retrieve(path, request.params());
    } else {
        return null;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;可以看到，这里会根据注册的handler，选择合适的处理逻辑。&lt;/p&gt;
&lt;p&gt;这些handler由函数registerHandler进行注册，函数签名如下：&lt;/p&gt;
&lt;p class=&#34;p1&#34;&gt;
  &lt;span class=&#34;s1&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;void&lt;/span&gt; registerHandler(RestRequest.Method &lt;span class=&#34;s2&#34;&gt;method&lt;/span&gt;, String &lt;span class=&#34;s2&#34;&gt;path&lt;/span&gt;, RestHandler &lt;span class=&#34;s3&#34;&gt;handler&lt;/span&gt;)
&lt;/p&gt;
&lt;p class=&#34;p1&#34;&gt;
  比如对RestGetIndicesAction类，有如下构造函数：
&lt;/p&gt;
&lt;pre class=&#34;lang:java decode:true&#34;&gt;public RestGetIndicesAction(Settings settings, RestController controller, Client client) {
        super(settings, controller, client);
        controller.registerHandler(GET, &#34;/{index}&#34;, this);
        controller.registerHandler(GET, &#34;/{index}/{type}&#34;, this);
    }&lt;/pre&gt;
&lt;p&gt;netty参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/flashsword/blog/162936&#34;&gt;http://my.oschina.net/flashsword/blog/162936&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/flashsword/blog/164237&#34;&gt;http://my.oschina.net/flashsword/blog/164237&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/flashsword/blog/169361&#34;&gt;http://my.oschina.net/flashsword/blog/169361&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/flashsword/blog/178561&#34;&gt;http://my.oschina.net/flashsword/blog/178561&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://my.oschina.net/flashsword/blog/197963&#34;&gt;http://my.oschina.net/flashsword/blog/197963&lt;/a&gt;&lt;/p&gt;
- https://sword865.github.io/posts/archives/2015-07-27-elasticsearch-httpservermodule/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
    
        <item>
        <title>Tornado框架简析</title>
        <link>https://sword865.github.io/posts/archives/2015-02-05-tornado%E6%A1%86%E6%9E%B6%E7%AE%80%E6%9E%90/</link>
        <pubDate>Thu, 05 Feb 2015 00:00:00 +0000</pubDate>
        
        <guid>https://sword865.github.io/posts/archives/2015-02-05-tornado%E6%A1%86%E6%9E%B6%E7%AE%80%E6%9E%90/</guid>
        <description>悟剑阁 https://sword865.github.io/posts/archives/2015-02-05-tornado%E6%A1%86%E6%9E%B6%E7%AE%80%E6%9E%90/ -&lt;p&gt;Tornado是一款轻量级的Web服务器，同时又是一个开发框架。采用单线程非阻塞I/O模型(epoll)，主要是为了应对高并发 访问量而被开发出来，尤其适用于comet应用。&lt;/p&gt;
&lt;p&gt;Tornado服务器3大核心模块:&lt;/p&gt;
&lt;p&gt;(1) IOLoop&lt;/p&gt;
&lt;p&gt;Tornado为了实现高并发和高性能，使用了一个IOLoop来处理socket的读写事件，IOLoop基于epoll，可以高效的响应网络事件。这是Tornado高效的保证。&lt;/p&gt;
&lt;p&gt;tornado.ioloop.IOLoop.instance().start()&lt;/p&gt;
&lt;p&gt;IOLoop使用了单例模式，处理所有IO事件，&lt;/p&gt;
&lt;p&gt;实现为EPollIOLoop-&amp;gt;PollIOLoop-&amp;gt;IOLoop-&amp;gt;Configurable&lt;/p&gt;
&lt;p&gt;IOLoop中有四个重要的数据集： _events 和 _handlers 保存I/O事件和对应的处理器， _callbacks 和 _timeouts 保存（超时）回调。&lt;/p&gt;
&lt;p&gt;关键函数：&lt;/p&gt;
&lt;pre class=&#34;lang:python decode:true &#34;&gt;def initialize(self, impl, time_func=None):
    super(PollIOLoop, self).initialize()
    self._impl = impl
    if hasattr(self._impl, &#39;fileno&#39;):
        set_close_exec(self._impl.fileno())
    self.time_func = time_func or time.time
    #handlers 是一个函数集字典
    self._handlers = {}
    self._events = {}
    #回调函数集合
    self._callbacks = []
    self._callback_lock = threading.Lock()
    self._timeouts = []
    self._cancellations = 0
    self._running = False
    self._stopped = False
    self._closing = False
    self._thread_ident = None
    self._blocking_signal_threshold = None
    self._timeout_counter = itertools.count()

    # Create a pipe that we send bogus data to when we want to wake
    # the I/O loop when it is idle
    self._waker = Waker()
    self.add_handler(self._waker.fileno(),
                     lambda fd, events: self._waker.consume(),
                     self.READ)&lt;/pre&gt;
&lt;p&gt;其中，waker是一个发伪数据用的类，在需要时，我们可以用它唤醒空闲的I/O Loop。当我们调用add_callback时，为了让回调函数运行，可能会需要使用它发送一个伪数据。&lt;/p&gt;
&lt;pre class=&#34;lang:python decode:true&#34;&gt;#将文件描述符发生相应的事件时的回调函数对应
def add_handler(self, fd, handler, events):
    &#34;&#34;&#34;Registers the given handler to receive the given events for fd.&#34;&#34;&#34;
    self._handlers[fd] = stack_context.wrap(handler)
    #在 epoll 中注册对应事件
    #epoll_ctl
    self._impl.register(fd, events | self.ERROR)
&lt;/pre&gt;
&lt;p&gt;其中stack_context.wrap()对handler进行封装，封装后记录了上下文信息。而_impl是对epoll的封装。&lt;/p&gt;
&lt;p&gt;所以，只要把所有事件在IOLoop中进行注册，运行start函数后，就会进入进程的监听循环，循环监听所有的fd，并调用fd对应的handler。循环过程参考start()函数。&lt;/p&gt;
&lt;pre class=&#34;lang:python decode:true&#34;&gt;def start(self):
    while True:
        with self._callback_lock:
            callbacks = self._callbacks
            self._callbacks = []
        #运行所有callback
        for callback in callbacks:
            self._run_callback(callback)
        #取事件
        event_pairs = self._impl.poll(poll_timeout)
        self._events.update(event_pairs)
        while self._events:
            fd, events = self._events.popitem()
            try:
                #调用事件handler
                fd_obj, handler_func = self._handlers[fd]
                handler_func(fd_obj, events)
            except (OSError, IOError) as e:
                if errno_from_exception(e) == errno.EPIPE:
                    # Happens when the client closes the connection
                    pass
                else:
                    self.handle_callback_exception(self._handlers.get(fd))
            except Exception:
                self.handle_callback_exception(self._handlers.get(fd))
&lt;/pre&gt;
&lt;p&gt;当poll中发现fp有read事件时，会调用对应的callback方法。如果fd是监听的fd，那么这个回调handler就是accept_handler函数(见下面HttpConnection的bind和add_scokets函数)。该方法会Accept连接并且紧跟着创建IOStream对象，read_until方法读完数据后，则调用_run_callback把处理函数（self._header_callback）加到IOLoop中，等到下次轮询时在最前面处理。&lt;/p&gt;
&lt;p&gt;(2) IOStream&lt;/p&gt;
&lt;p&gt;为了在处理请求的时候，实现对socket的异步读写， Tornado实现了IOStream类，用来处理socket的异步读写，负责异步通讯。&lt;/p&gt;
&lt;p&gt;主要包括3个函数，&lt;/p&gt;
&lt;p&gt;1.read_bytes(bytes,callback)在有固定的字节的数据到来的时候调用回调函数&lt;/p&gt;
&lt;p&gt;2.read_until(delimiter,callback)在读取到固定的字符序列结尾后调用回调函数&lt;/p&gt;
&lt;p&gt;3.write(data)：异步写&lt;/p&gt;
&lt;p&gt;(3) HTTPConnection&lt;/p&gt;
&lt;p&gt;这个类用来处理http的请求， 包括读取http请求头， 读取post过来的数据，调用用户自定义的处理方法。以及把响应数据写给客户端socket。&lt;/p&gt;
&lt;pre class=&#34;lang:python decode:true&#34;&gt;def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128): 
    sockets = bind_sockets(port, address=address, family=family,backlog=backlog)
        if self._started:
            self.add_sockets(sockets)
        else:
            self._pending_sockets.extend(sockets)
def add_sockets(self, sockets):
    if self.io_loop is None:
        self.io_loop = IOLoop.current()
    for sock in sockets:
        self._sockets[sock.fileno()] = sock
        add_accept_handler(sock, self._handle_connection,io_loop=self.io_loop)
&lt;/pre&gt;
&lt;p&gt;socket启动后，监听各个sockets，事件到来时，调用_handle_connection。&lt;/p&gt;
&lt;pre class=&#34;lang:python decode:true &#34;&gt;def _handle_connection(self, connection, address):
    if self.ssl_options is not None:
        connection = ssl_wrap_socket(connection,self.ssl_options,
                                     server_side=True,
                                     do_handshake_on_connect=False)
        if self.ssl_options is not None:
            stream = SSLIOStream(connection, io_loop=self.io_loop,
                                 max_buffer_size=self.max_buffer_size,
                                 read_chunk_size=self.read_chunk_size)
        else:
            stream = IOStream(connection, io_loop=self.io_loop,
                              max_buffer_size=self.max_buffer_size,
                              read_chunk_size=self.read_chunk_size)
        self.handle_stream(stream, address)
def handle_stream(self, stream, address):
    context = _HTTPRequestContext(stream, address,
                                  self.protocol)
    conn = HTTP1ServerConnection(
        stream, self.conn_params, context)
    self._connections.add(conn)
    conn.start_serving(self)
def start_serving(self, delegate):
    assert isinstance(delegate, httputil.HTTPServerConnectionDelegate)
    self._serving_future = self._server_request_loop(delegate)
    # Register the future on the IOLoop so its errors get logged.
    self.stream.io_loop.add_future(self._serving_future,
                                   lambda f: f.result())
&lt;/pre&gt;
&lt;p&gt;如前面所述，这里Accept连接并且紧跟着创建IOStream对象(不考虑https)，调用handle_stream-&amp;gt;start_serving-&amp;gt;_server_request_loop处理请求。最后会调用_read_message读取数据，并注册回调函数。&lt;/p&gt;
&lt;p&gt;最后抄一张图过来：&lt;/p&gt;
&lt;img class=&#34;alignnone wp-image-108 size-large&#34; src=&#34;https://sword865.github.io/wp-content/uploads/2015/02/QQ20150205-1@2x-1024x593.png&#34; alt=&#34;QQ20150205-1@2x&#34; width=&#34;615&#34; height=&#34;356&#34; /&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html&#34;&gt;http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://kenby.iteye.com/blog/1159621&#34;&gt;http://kenby.iteye.com/blog/1159621&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nowamagic.net/academy/detail/13321030&#34;&gt;http://www.nowamagic.net/academy/detail/13321030&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.yeolar.com/note/2013/02/09/tornado-async-networking/&#34;&gt;http://www.yeolar.com/note/2013/02/09/tornado-async-networking/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;源码：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/tornadoweb/tornado&#34;&gt;https://github.com/tornadoweb/tornado&lt;/a&gt;&lt;/p&gt;
&lt;p style=&#34;margin:0;padding:0;height:1px;overflow:hidden;&#34;&gt;
  &lt;a href=&#34;http://www.wumii.com/widget/relatedItems&#34; style=&#34;border:0;&#34;&gt;&lt;img src=&#34;http://static.wumii.cn/images/pixel.png&#34; alt=&#34;无觅相关文章插件，快速提升流量&#34; style=&#34;border:0;padding:0;margin:0;&#34; /&gt;&lt;/a&gt;
&lt;/p&gt;
- https://sword865.github.io/posts/archives/2015-02-05-tornado%E6%A1%86%E6%9E%B6%E7%AE%80%E6%9E%90/ - Copyright (c) 2015. All rights reserved.</description>
        </item>
    
    
  </channel>
</rss> 