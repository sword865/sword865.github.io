<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 悟剑阁</title>
    <link>https://sword865.github.io/posts/</link>
    <description>Recent content in Posts on 悟剑阁</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2015. All rights reserved.</copyright>
    <lastBuildDate>Sun, 20 Apr 2025 15:51:35 +0800</lastBuildDate>
    <atom:link href="https://sword865.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>vLLM Paged Attention代码分析</title>
      <link>https://sword865.github.io/posts/2025/vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 20 Apr 2025 15:51:35 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2025/vllm-paged-attention%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;3月底整理了一个关于经典Paged Attention算法的ppt, 想起这个几年没写过的blog，把PPT改成一篇文章证明我还活着(-_-)。&lt;/p&gt;&#xA;&lt;img width=&#34;500&#34;  src=&#34;https://sword865.github.io/images/2025/paged_attention.png&#34; class=&#34;center&#34; /&gt;&#xD;&#xA;&lt;h2 id=&#34;vllm-的-paged-attention&#34;&gt;vLLM 的 Paged Attention&lt;/h2&gt;&#xA;&lt;p&gt;开始前先说明一下，vLLM里的Paged Attention Kernel是有好几个不同的版本的，大概是下面这样子：&lt;/p&gt;&#xA;&lt;p&gt;vLLM早期版本：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Prefilling -&amp;gt; Flash Attention的flash_attn_varlen_func&lt;/li&gt;&#xA;&lt;li&gt;Dedocding -&amp;gt; 自己实现的Paged Attention&#xA;&lt;ul&gt;&#xA;&lt;li&gt;paged_attention_v1 : 用于比较短的sequence&lt;/li&gt;&#xA;&lt;li&gt;paged_attention_v2 : 用于不想用v1的情况 :)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;源码大概是这样的：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    # NOTE(woosuk): We use a simple heuristic to decide whether to use&#xD;&#xA;    # PagedAttention V1 or V2. If the number of partitions is 1, we use&#xD;&#xA;    # V1 to avoid the overhead of reduction. Also, if the number of&#xD;&#xA;    # sequences or heads is large, we use V1 since there is enough work&#xD;&#xA;    # to parallelize.&#xD;&#xA;    # TODO(woosuk): Tune this heuristic.&#xD;&#xA;    # For context len &amp;gt; 8192, use V2 kernel to avoid shared memory&#xD;&#xA;    # shortage.&#xD;&#xA;    use_v1 = (max_seq_len &amp;lt;= 8192 and (max_num_partitions == 1 or num_seqs * num_heads &amp;gt; 512))&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;vLLM 最新版本就已经全部转向Flash Attention， 用cutlass实现了。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Small Towers中多目标优化的探索</title>
      <link>https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Mon, 08 Mar 2021 15:51:35 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2021/2021-03-08-google-small-towers%E4%B8%AD%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;&#xA;&lt;p&gt;多目标优化中有一个很常见的跷跷板问题，就是说在训练时，多个目标会相互影响，导致震荡&amp;mdash;你降我升，我升你降。有时间还会出现Nan的结果，需要很仔细的调参测试+清洗数据才能训练出一个理想的模型。&lt;/p&gt;&#xA;&lt;p&gt;针对这种问题，自然就有了一些尝试，比如从帕累托最优的角度寻找优化方向（阿里PEA），修改模型结构使Shared部分存储更泛化的信息（腾讯PLE）。不过这两个写的人都挺多了，就写一下Google Small Towers的这篇文章吧。&lt;/p&gt;&#xA;&lt;h2 id=&#34;主要问题讨论&#34;&gt;主要问题讨论&lt;/h2&gt;&#xA;&lt;p&gt;文章首先讨论了两个问题：&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-over-parameterization对多任务模型的适用性&#34;&gt;1. Over-parameterization对多任务模型的适用性&lt;/h3&gt;&#xA;&lt;p&gt;我们都知道over-parameterization对单任务模型是有价值的，那边对多任务模型是否成立？&lt;/p&gt;&#xA;&lt;p&gt;这里以将多个目标的线性组合作为优化目标的例子，认为over-parameterization能够帮助处理各任务优化目标之间的冲突问题（既减少跷跷板问题的出现）。&lt;/p&gt;&#xA;&lt;h3 id=&#34;2-大型模型和小型模型的多目标学习表现对比&#34;&gt;2. 大型模型和小型模型的多目标学习表现对比&lt;/h3&gt;&#xA;&lt;p&gt;通过实验对比了大型模型和小型模型进行多目标学习中的不同表现。&lt;/p&gt;&#xA;&lt;p&gt;实验中，不论是增加任务相关结构的复杂度，还是增加任务共享结构的复杂度，Pareto frontier都会呈现先变好在变差的趋势。&lt;/p&gt;&#xA;&lt;p&gt;因此，文章认为over-parameterization并不利于多目标学习中的共享性，进而伤害了多目标学习中的泛化能力。因此，在多目标学习中，模型大小实质上是对模型有效性和泛化能力的一种平衡。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;To summarize our insights, for a multi-task learning model, small models benefit from good multi-task generalization but hurts Pareto efficiency; big models theoretically have better Pareto efficiency but could suffer from loss of generalization.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;under-parameterized-self-auxiliaries模型结构&#34;&gt;Under-parameterized Self-auxiliaries模型结构&lt;/h2&gt;&#xA;&lt;p&gt;文章提出了under-parameterized self-auxiliaries的模型结构：&lt;/p&gt;&#xA;&lt;p&gt;首先假设模型的共享方式是所有任务共享最下面的表示层（Hard Sharded，MMOE这种，PLE就不行）,既对任务t，有：&lt;/p&gt;&#xA;&lt;p&gt;$$f_{t}(x; \theta_{sh}, \theta_{t})=f_{t}(h(x; \theta_{sh}); \theta_{t}), \forall t$$&lt;/p&gt;&#xA;&lt;p&gt;其中 $\theta_t$ 是任务相关的参数， $\theta_sh$ 为共享参数， $h(x;\theta_sh)$ 既为共享的表示层输出。&lt;/p&gt;</description>
    </item>
    <item>
      <title>推荐系统周边设施--特征商店</title>
      <link>https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/</link>
      <pubDate>Sun, 07 Mar 2021 15:51:35 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2021/2021-03-07-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%91%A8%E8%BE%B9%E8%AE%BE%E6%96%BD--%E7%89%B9%E5%BE%81%E5%95%86%E5%BA%97/</guid>
      <description>&lt;p&gt;好久没写博客了，今天写一点推荐系统周边设施的东西。&lt;/p&gt;&#xA;&lt;h2 id=&#34;特征管理&#34;&gt;特征管理&lt;/h2&gt;&#xA;&lt;p&gt;特征商店会存储特征元数据，比如特征的计算逻辑、血缘关系、数据类型。 一般来说，这些元数据用于管理特征的生命周期、计算任务和使用方式。&lt;/p&gt;&#xA;&lt;h2 id=&#34;离线训练数据生成&#34;&gt;离线训练数据生成&lt;/h2&gt;&#xA;&lt;p&gt;为了保证线上线下数据的一致性，推荐系统的训练数据通常有两个数据流Join得到：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;在Ranking中即实时打点：数据流以&lt;code&gt;traceId&lt;/code&gt;为Key，排序时特征为Value。&lt;/li&gt;&#xA;&lt;li&gt;客户端日志：记录了&lt;code&gt;traceId&lt;/code&gt;和事件类型(曝光、点击、分享等）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;由于客户端日志必然晚于服务端日志，因此两个数据流Join时需要一定的窗口。&lt;/p&gt;&#xA;&lt;h2 id=&#34;训练数据扩展&#34;&gt;训练数据扩展&lt;/h2&gt;&#xA;&lt;p&gt;但是作为调参工程师，我们必然会遇到需要的特征没有记录在实时打点中，导致训练时缺少相关数据的情况，这个时候，就需要想办法来处理这个问题。&lt;/p&gt;&#xA;&lt;p&gt;按照Uber的方法，我们可以把特征分为三类：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;离线特征&lt;/li&gt;&#xA;&lt;li&gt;实时特征&lt;/li&gt;&#xA;&lt;li&gt;RPC特征&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;离线特征&#34;&gt;离线特征&lt;/h3&gt;&#xA;&lt;p&gt;对于离线特征：我们可以使用Spark读取数据仓库中的历史数据，以天为单位进行生成历史数据，然后放在一个分区的Hive表中。&lt;/p&gt;&#xA;&lt;h3 id=&#34;实时特征&#34;&gt;实时特征&lt;/h3&gt;&#xA;&lt;p&gt;对于实时特征：基于kappa的思想，我们可以在Flink中编写实时特征计算逻辑，然后启动重跑一段时间以前的历史数据，并记录这个过程中特征的每一次变化（有点类似数据库中的WAL日志流），将其输出到Kafka中去，这样我们也就有一个特征在历史时间段中的值。(这里我们最好有一个服务化的Flink平台，来进行任务的添加、删除、修改等工作)&lt;/p&gt;&#xA;&lt;p&gt;这里，特征的计算任务就可以通过特征元数据库进行管理。&lt;/p&gt;&#xA;&lt;p&gt;接下来，我们就可以通过带时间戳的Join来完成训练数据和特征数据的拼接，并将特征回写到训练数据中去了。 需要注意的是，为了保证线上线下数据的一致性，我们需要引入一定的延时机制来模拟客户端日志的延迟。&lt;/p&gt;&#xA;&lt;h3 id=&#34;rpc特征&#34;&gt;RPC特征&lt;/h3&gt;&#xA;&lt;p&gt;最后对于来自外部系统的RPC特征：就没有什么好办法了，我们只能在线上添加这个特征的打点，然后跑上一段时间来得到有这个特征的训练数据了。&lt;/p&gt;&#xA;&lt;p&gt;这里推荐一个比较新的开源项目可以完成类似的工作: &lt;a href=&#34;https://github.com/feast-dev/feast&#34;&gt;Feast&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;在线特征推送&#34;&gt;在线特征推送&lt;/h2&gt;&#xA;&lt;p&gt;特征的线上存储可以使用KV数据库比如Redis，数据的来源和上面训练数据的扩展可以使用同一套代码，只需要在计算时根据元数据配置来决定是否推送上线。&lt;/p&gt;&#xA;&lt;p&gt;另外，这里一般会做很多工程上的优化，比如：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;把多个特征作为一个特征组存在一个key里减少请求的次数&lt;/li&gt;&#xA;&lt;li&gt;使用一些算法（比如XXHash32）对过长的特征名(比如&lt;code&gt;spu$realtime$orders_last_2w$spu_id&lt;/code&gt;)进行压缩&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>NPE问题与一些语言中的解决方案</title>
      <link>https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Thu, 08 Nov 2018 23:51:35 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2018/2018-11-08-npe%E9%97%AE%E9%A2%98%E4%B8%8E%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;p&gt;NPE(NullPointerException)是一个很烦人的问题，这里简单列举了一些语言中对NPE的处理。&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-通过语法标记进行检查&#34;&gt;1. 通过语法标记进行检查&lt;/h2&gt;&#xA;&lt;h3 id=&#34;kotlin&#34;&gt;Kotlin&lt;/h3&gt;&#xA;&lt;p&gt;Kotlin要求可以为null的变量必需在定义时声明，同时在读取该类型变量属性时必须进行空值判断。例：String 和 String?&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-kotlin&#34; data-lang=&#34;kotlin&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; a: String = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a = &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// compilation error, a can not be null&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; b: String? = &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;abc&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;b = &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// ok&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; l = b.length &lt;span style=&#34;color:#75715e&#34;&gt;// compiler error: variable &amp;#39;b&amp;#39; can be null&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; l = &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (b &lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;) b.length &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; -&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// ok&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;jetbrains-annotations-for-java&#34;&gt;Jetbrains annotations for Java&lt;/h3&gt;&#xA;&lt;p&gt;IntelliJ IDEA提供了一些工具，比如可以对@NotNull的参数进行检查，当出现null赋值时在IDE中会给出提示。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; org.jetbrains.annotations.NotNull;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; java.util.ArrayList;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Test&lt;/span&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foo&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;@NotNull&lt;/span&gt; Object param){&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; param.&lt;span style=&#34;color:#a6e22e&#34;&gt;hashCode&lt;/span&gt;();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;test&lt;/span&gt;(){&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        foo(&lt;span style=&#34;color:#66d9ef&#34;&gt;null&lt;/span&gt;); &lt;span style=&#34;color:#75715e&#34;&gt;// warn in IntelliJ IDEA&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;（类似的，FindBugs也提供了@Nonnull注释，用于检查）&lt;/p&gt;</description>
    </item>
    <item>
      <title>比较一下spark2的DataFrame和RDD</title>
      <link>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</link>
      <pubDate>Sun, 12 Mar 2017 15:49:45 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</guid>
      <description>&lt;p&gt;前段时间把spark集群升级到2.x，使用起来感觉相对1.x的版本最大的改动就是DataFrame正式开始替代RDD成为主流，包括我们最常用到的mllib的官方文档也提到：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.&#xD;&#xA;After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.&#xD;&#xA;The RDD-based API is expected to be removed in Spark 3.0.&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;rdd的结构&#34;&gt;RDD的结构&lt;/h4&gt;&#xA;&lt;p&gt;RDD可以看成是一个分布式的无序列表，这个列表内的元素是一个object，RDD并不关心每个object的内部结构。因此所有操作都必须对这个object进行，不利于算子的复用。&lt;/p&gt;&#xA;&lt;p&gt;比起DataFrame，RDD更方便我们对数据做一些底层的操作，也可以用于unstructured的数据。&lt;/p&gt;&#xA;&lt;h4 id=&#34;dataframe的结构&#34;&gt;DataFrame的结构&lt;/h4&gt;&#xA;&lt;p&gt;DataFrame不同于RDD，框架会去了解object中的数据是什么样的结构，这样每个算子就可以单独实现在某个列上，复用起来就更加简单。&lt;/p&gt;&#xA;&lt;p&gt;因为DataFrame比RDD多个更多的限制，对内部的元素也有了更多的了解，可以使用SQL语句进行操作，因此也就可以在对DataFrame进行操作时使用Spark SQL的Catalyst优化器进行优化。&lt;/p&gt;&#xA;&lt;p&gt;Catalyst一个易于扩展的查询优化器，同时支持基于规则(rule-based)和基于代价(cost-based)的优化方法，我们可以基于相关API自己定义优化规则。&lt;/p&gt;&#xA;&lt;p&gt;最后，Spark的Tungsten目前还只支持DataFrame API, 因此在使用RDD时不能享受到Tungsten带来的效率优化。（Tungsten做的优化概括起来说就是由Spark自己来管理内存而不是使用JVM，这样可以避免JVM GC带来的性能损失）&lt;/p&gt;&#xA;&lt;h4 id=&#34;dataset数据结构&#34;&gt;DataSet数据结构&lt;/h4&gt;&#xA;&lt;p&gt;前面提到DataFrame每一个record对应了一个Row。而Dataset的定义更加宽松，每一个record对应了一个任意的类型。实际上，从源码中可以看到，DataFrame就是Dataset的一种特例。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;package object sql {&#xD;&#xA;    ...&#xD;&#xA;    type DataFrame = Dataset[Row]&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;DataSet和DataFrame可以通过df.as和ds.toDF方法方便的进行转化。&lt;/p&gt;</description>
    </item>
    <item>
      <title>谈谈Factorization Machine</title>
      <link>https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/</link>
      <pubDate>Fri, 04 Nov 2016 22:47:21 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2016/2016-11-04-%E8%B0%88%E8%B0%88factorization-machine/</guid>
      <description>&lt;p&gt;因子分解机(Factorization Machine, 简称FM)是一种不错的CTR预估模型，也是我们现在在使用的广告点击率预估模型，比起著名的Logistic Regression, FM能够把握一些组合的高阶特征，因此拥有更强的表现力。&lt;/p&gt;&#xA;&lt;p&gt;在做点击率预估时，我们的特征往往来自于用户(user)、广告(item)和上下文环境(context)，在线性模型中，这些特征不进行组合的话，就会发生一个很尴尬的情况，因为：&lt;/p&gt;&#xA;&lt;div&gt;$$score = f(w_{user} * x_{user} + w_{item} * x_{item} + w_{contex} * x_{contex})$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;所以，对所有用户&amp;ndash;我们将得到相同的排序。&lt;/p&gt;&#xA;&lt;p&gt;因此我们需要引入一些组合特征作为输入模型，然而仅二阶特征组合的可能性就是原始特征的平方之多，但是由于很多特征其实是相互独立的，他们的组合并没有什么价值。FM就是一种能够自动把握一些高阶特征的点击率预估模型，可以自动帮助使用者选择合适的高阶输入。&lt;/p&gt;&#xA;&lt;p&gt;我们先写出带有所有二阶组合特征的目标函数，其中矩阵W中有n^2个参数，求解非常复杂：&lt;/p&gt;&#xA;&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{ij} x_i x_j$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;我们都知道在矩阵分解的协同过滤中中，我们认为每个用户可以表示成一个K维的特征向量$u_k$,每个物品也能表示成一个高维向量$i_k$，这样用户与物品的相关性就可以用两个向量的点击表示，所有用户与所有物品的相关性就可以用两个矩阵相乘的形式表示出来了。&lt;/p&gt;&#xA;&lt;p&gt;FM的模型参考了矩阵分解的思想，认为每个特征 $x_i$都可以用一个K维的特征向量$v_i$表示，那么所有特征之前的相关性就也就可以用两个矩阵的相乘进行表示了，模型表示如下：&lt;/p&gt;&#xA;&lt;p&gt;其中矩阵W中代表了特征的特征向量的內积，既：$w_{ij}=v_i v_j$，所以，公式可以改写为:&lt;/p&gt;&#xA;&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} v_{i} v_{j} x_i x_j$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;也就是：&lt;/p&gt;&#xA;&lt;div&gt;$$y(x) = w_0 + \sum_{i=1}^{n} w_i x_i + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \sum_{h=i}^{k} v_{i,h} v_{j,h} x_i x_j$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;可以看出，W中的参数现在只有nk个了，因为一般有k&amp;laquo;n，所以FM大大降低的目标函数的复杂度。推导可得梯度公式：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Elasticsearch-HttpServerModule</title>
      <link>https://sword865.github.io/archives/150/</link>
      <pubDate>Mon, 27 Jul 2015 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/150/</guid>
      <description>&lt;p&gt;HttpServerModule的请求主要由HttpServer中的HttpServerTransport （默认为NettyHttpServerTransport）类处理。&lt;/p&gt;&#xA;&lt;p&gt;NettyHttpServerTransport基于netty框架，负责监听并建立连接，信息的处理由内部类HttpChannelPipelineFactory 完成。&lt;/p&gt;&#xA;&lt;p&gt;每当产生一个连接时，都会发出一个ChannelEvent，该Event由一系列的ChannelHandler进行处理。&lt;/p&gt;&#xA;&lt;p&gt;为了方便组织，这些ChannelHandler被放在一条“流(pipeline)”里，一个ChannelEvent并不会主动的”流”经所有的Handler，而是由上一个Handler显式的调用ChannelPipeline.sendUp(Down)stream产生，并交给下一个Handler处理。&lt;/p&gt;&#xA;&lt;p&gt;换句话说，每个Handler接收到一个ChannelEvent，并处理结束后，如果需要继续处理，那么它需要调用sendUp(Down)stream新发起一个事件。如果它不再发起事件，那么处理就到此结束，即使它后面仍然有Handler没有执行。这个机制可以保证最大的灵活性，当然对Handler的先后顺序也有了更严格的要求。&lt;/p&gt;&#xA;&lt;p&gt;在流Pipeline里有一个Map(name2ctx)和一个链表(记录head和tail)，pipeline里面会调度关联的多个channelhandler的运行。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://sword865.github.io/images/_posts/0753391.png&#34;&gt;&lt;img src=&#34;https://sword865.github.io/images/_posts/0753391.png&#34; alt=&#34;channel pipeline&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;在NettyHttpServerTransport中，会流过的channelhandler就包括解码http请求(把多个HttpChunk拼起来并按http协议进行解析)和http请求处理。&lt;/p&gt;&#xA;&lt;p&gt;在处理http请求，数据流向为：HttpRequestHandler-&amp;gt;&lt;span class=&#34;s1&#34;&gt;NettyHttpServerTransport&lt;/span&gt;-&amp;gt;HttpServerAdapter(HttpServer的内部类Dispatche)-&amp;gt;RestController。&lt;/p&gt;&#xA;&lt;p&gt;RestController中的处理代码为：&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:java decode:true &#34;&gt;&#xD;&#xA;void executeHandler(RestRequest request, RestChannel channel) throws Exception {&#xD;&#xA;        final RestHandler handler = getHandler(request);&#xD;&#xA;        if (handler != null) {&#xD;&#xA;            handler.handleRequest(request, channel);&#xD;&#xA;        } else {&#xD;&#xA;            if (request.method() == RestRequest.Method.OPTIONS) {&#xD;&#xA;                // when we have OPTIONS request, simply send OK by default &#xD;&#xA;                // (with the Access Control Origin header which gets automatically added)&#xD;&#xA;                channel.sendResponse(new BytesRestResponse(OK));&#xD;&#xA;            } else {&#xD;&#xA;                channel.sendResponse(new BytesRestResponse(&#xD;&#xA;                    BAD_REQUEST, &#xD;&#xA;                    &#34;No handler found for uri [&#34; + request.uri() + &#34;] and method [&#34; + request.method() + &#34;]&#34;&#xD;&#xA;                ));&#xD;&#xA;            }&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;&#xD;&#xA;    private RestHandler getHandler(RestRequest request) {&#xD;&#xA;        String path = getPath(request);&#xD;&#xA;        RestRequest.Method method = request.method();&#xD;&#xA;        if (method == RestRequest.Method.GET) {&#xD;&#xA;            return getHandlers.retrieve(path, request.params());&#xD;&#xA;        } else if (method == RestRequest.Method.POST) {&#xD;&#xA;            return postHandlers.retrieve(path, request.params());&#xD;&#xA;        } else if (method == RestRequest.Method.PUT) {&#xD;&#xA;            return putHandlers.retrieve(path, request.params());&#xD;&#xA;        } else if (method == RestRequest.Method.DELETE) {&#xD;&#xA;            return deleteHandlers.retrieve(path, request.params());&#xD;&#xA;        } else if (method == RestRequest.Method.HEAD) {&#xD;&#xA;            return headHandlers.retrieve(path, request.params());&#xD;&#xA;        } else if (method == RestRequest.Method.OPTIONS) {&#xD;&#xA;            return optionsHandlers.retrieve(path, request.params());&#xD;&#xA;        } else {&#xD;&#xA;            return null;&#xD;&#xA;        }&#xD;&#xA;    }&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;void executeHandler(RestRequest request, RestChannel channel) throws Exception {&#xA;final RestHandler handler = getHandler(request);&#xA;if (handler != null) {&#xA;handler.handleRequest(request, channel);&#xA;} else {&#xA;if (request.method() == RestRequest.Method.OPTIONS) {&#xA;// when we have OPTIONS request, simply send OK by default (with the Access Control Origin header which gets automatically added)&#xA;channel.sendResponse(new BytesRestResponse(OK));&#xA;} else {&#xA;channel.sendResponse(new BytesRestResponse(BAD_REQUEST, &amp;ldquo;No handler found for uri [&amp;rdquo; + request.uri() + &amp;ldquo;] and method [&amp;rdquo; + request.method() + &amp;ldquo;]&amp;rdquo;));&#xA;}&#xA;}&#xA;}&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tornado框架简析</title>
      <link>https://sword865.github.io/archives/100/</link>
      <pubDate>Thu, 05 Feb 2015 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/100/</guid>
      <description>&lt;p&gt;Tornado是一款轻量级的Web服务器，同时又是一个开发框架。采用单线程非阻塞I/O模型(epoll)，主要是为了应对高并发 访问量而被开发出来，尤其适用于comet应用。&lt;/p&gt;&#xA;&lt;p&gt;Tornado服务器3大核心模块:&lt;/p&gt;&#xA;&lt;p&gt;(1) IOLoop&lt;/p&gt;&#xA;&lt;p&gt;Tornado为了实现高并发和高性能，使用了一个IOLoop来处理socket的读写事件，IOLoop基于epoll，可以高效的响应网络事件。这是Tornado高效的保证。&lt;/p&gt;&#xA;&lt;p&gt;tornado.ioloop.IOLoop.instance().start()&lt;/p&gt;&#xA;&lt;p&gt;IOLoop使用了单例模式，处理所有IO事件，&lt;/p&gt;&#xA;&lt;p&gt;实现为EPollIOLoop-&amp;gt;PollIOLoop-&amp;gt;IOLoop-&amp;gt;Configurable&lt;/p&gt;&#xA;&lt;p&gt;IOLoop中有四个重要的数据集： _events 和 _handlers 保存I/O事件和对应的处理器， _callbacks 和 _timeouts 保存（超时）回调。&lt;/p&gt;&#xA;&lt;p&gt;关键函数：&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:python decode:true &#34;&gt;def initialize(self, impl, time_func=None):&#xD;&#xA;    super(PollIOLoop, self).initialize()&#xD;&#xA;    self._impl = impl&#xD;&#xA;    if hasattr(self._impl, &#39;fileno&#39;):&#xD;&#xA;        set_close_exec(self._impl.fileno())&#xD;&#xA;    self.time_func = time_func or time.time&#xD;&#xA;    #handlers 是一个函数集字典&#xD;&#xA;    self._handlers = {}&#xD;&#xA;    self._events = {}&#xD;&#xA;    #回调函数集合&#xD;&#xA;    self._callbacks = []&#xD;&#xA;    self._callback_lock = threading.Lock()&#xD;&#xA;    self._timeouts = []&#xD;&#xA;    self._cancellations = 0&#xD;&#xA;    self._running = False&#xD;&#xA;    self._stopped = False&#xD;&#xA;    self._closing = False&#xD;&#xA;    self._thread_ident = None&#xD;&#xA;    self._blocking_signal_threshold = None&#xD;&#xA;    self._timeout_counter = itertools.count()&#xD;&#xA;&#xD;&#xA;    # Create a pipe that we send bogus data to when we want to wake&#xD;&#xA;    # the I/O loop when it is idle&#xD;&#xA;    self._waker = Waker()&#xD;&#xA;    self.add_handler(self._waker.fileno(),&#xD;&#xA;                     lambda fd, events: self._waker.consume(),&#xD;&#xA;                     self.READ)&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;其中，waker是一个发伪数据用的类，在需要时，我们可以用它唤醒空闲的I/O Loop。当我们调用add_callback时，为了让回调函数运行，可能会需要使用它发送一个伪数据。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lucene索引文件学习</title>
      <link>https://sword865.github.io/archives/86/</link>
      <pubDate>Wed, 04 Feb 2015 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/86/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt; 最近在做搜索，抽空看一下lucene，资料挺多的，不过大部分都是3.x了……在对着官方文档大概看一下。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;优化后的lucene索引文件(4.9.0)&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;&lt;img title=&#34;NewImage.png&#34; src=&#34;https://sword865.github.io/wp-content/uploads/2015/02/NewImage.png&#34; alt=&#34;NewImage&#34; width=&#34;200&#34; height=&#34;146&#34; border=&#34;0&#34; /&gt;&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;一、段文件&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;1.段文件：segments_5p和segments.gen。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;segments.gen保存当前段文件版本信息。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;&#34;&gt;&#xD;&#xA;  &lt;li&gt;&#xD;&#xA;    &lt;span style=&#34;font-size: 12px;&#34;&gt;&lt;tt style=&#34;font-size: 1.2em;&#34;&gt;segments.gen&lt;/tt&gt;: GenHeader, Generation, Generation, Footer&lt;/span&gt;&#xD;&#xA;  &lt;/li&gt;&#xD;&#xA;&lt;/ul&gt;&#xD;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;segments_N（segments_5p）保存最新的段的信息，包括段的个数，每个段的段名、文档数等信息。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;font-size: 12px; color: #353833; font-family: Arial, Helvetica, sans-serif;&#34;&gt;&#xD;&#xA;  &lt;li&gt;&#xD;&#xA;    &lt;span style=&#34;font-size: 12px;&#34;&gt;&lt;tt style=&#34;font-size: 1.2em;&#34;&gt;segments_N&lt;/tt&gt;: Header, Version, NameCounter, SegCount, &lt;SegName, SegCodec, DelGen, DeletionCount, FieldInfosGen, DocValuesGen, UpdatesFiles&gt;&lt;sup style=&#34;font-size: 0.6em;&#34;&gt;SegCount&lt;/sup&gt;, CommitUserData, Footer&lt;/span&gt;&#xD;&#xA;  &lt;/li&gt;&#xD;&#xA;&lt;/ul&gt;&#xD;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;  源码参考：SegmentInfos.read(Directory directory, String segmentFileName):&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;2.段信息：*.si，存储段的基本信息。&lt;/span&gt;&lt;/p&gt;&#xA;&lt;ul style=&#34;color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;&#34;&gt;&#xD;&#xA;  &lt;li&gt;&#xD;&#xA;    &lt;span style=&#34;font-size: 12px;&#34;&gt;&lt;tt style=&#34;font-size: 1.2em;&#34;&gt;.si&lt;/tt&gt;: Header, SegVersion, SegSize, IsCompoundFile, Diagnostics, Attributes, Files&lt;/span&gt;&#xD;&#xA;  &lt;/li&gt;&#xD;&#xA;&lt;/ul&gt;&#xD;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 12px;&#34;&gt;       只对4.0-4.5使用，新版已经抛弃了，可以无视。  &lt;/span&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>基于标签的推荐系统</title>
      <link>https://sword865.github.io/archives/5/</link>
      <pubDate>Mon, 17 Nov 2014 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/5/</guid>
      <description>&lt;p&gt;一、基于图模型的推荐&lt;/p&gt;&#xA;&lt;p&gt;在不考虑标签时，基于二项图有两种随机游走的图推荐算法：&lt;/p&gt;&#xA;&lt;p&gt;1.probability spreading&lt;/p&gt;&#xA;&lt;p&gt;随机游走算法，在游走中，每个目标得到权重是基于归属者的边计算出来的。&lt;/p&gt;&#xA;&lt;p&gt;每次传播(item-&amp;gt;user-&amp;gt;item)后用户Ui的兴趣向量：&lt;/p&gt;&#xA;&lt;div&gt;$$f_j^p=\sum_{l=1}^{n}\sum_{s=1}^{m}\frac{a_{lj}a_{ls}a_{is}}{K(U_l)K(I_s)},j=1…m$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;2.heat spreading&lt;/p&gt;&#xA;&lt;p&gt;规则与ProbS相反，在游走中，每个目标得到权重是基于自己的边计算出来的。&lt;/p&gt;&#xA;&lt;p&gt;每次传播后用户Ui的兴趣向量：&lt;/p&gt;&#xA;&lt;div&gt;$$f_h^p=\frac{1}{K(I_j)}\sum_{l=1}^{n}\sum_{s=1}^{m}\frac{a_{lj}a_{ls}a_{is}}{K(U_l)},j=1…m$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;其中：&lt;/p&gt;&#xA;&lt;div&gt;$$K(I_j)=\sum_{l=1}^{m}a_{lj}$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;是节目j的邻域大小，&lt;/p&gt;&#xA;&lt;div&gt;$$K(U_l)=\sum_{l=1}^{n}a_{ls}$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;是用户l的邻域大小。&lt;/p&gt;&#xA;&lt;p&gt;$a_{ij}$是表示用户i和物品j之间是否有边存在的二元向量。&lt;/p&gt;&#xA;&lt;p&gt;相比之下，Heats算法倾向于降低热门item的权重，而Probs中与增强对热门item的推荐。&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;在随机游走算法的基础上，有基于&lt;span style=&#34;color: #333333; font-family: arial; font-size: 13px; line-height: 20.0200004577637px;&#34;&gt;三分图的标签推荐算法：&lt;/span&gt;&lt;/p&gt;&#xA;&lt;img title=&#34;NewImage.png&#34; src=&#34;https://sword865.github.io/images/_posts/171255254884996.png&#34; alt=&#34;NewImage&#34; width=&#34;600&#34; height=&#34;305&#34; border=&#34;0&#34; /&gt;&#xD;&#xA;&lt;p&gt;图中，用户i的每个item的权重（1 or 0）会同时像用户和标签进行传播，这样每次传播后的兴趣向量：&lt;/p&gt;&#xA;&lt;p&gt;$f_j^t=\lambda f_j^p + (1-\lambda) f_j^{pt}$，其中$f_j^p$和$f_j^{pt}$分别是从(item-&amp;gt;user-&amp;gt;item)和(item-&amp;gt;tag-&amp;gt;item)传播后得到的权重。&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 14px;&#34;&gt;二、矩阵分解的张量模型&lt;/span&gt;&lt;/p&gt;&#xA;&lt;p&gt;对三元阵$Y_{(n\times m\times t)}$进行矩阵分解，C为核张量，U,I,T为用户特征，物品特征和标签特征矩阵。&lt;/p&gt;&#xA;&lt;p&gt;根据分解结果对Y进行填充。&lt;/p&gt;&#xA;&lt;img title=&#34;NewImage.png&#34; src=&#34;https://sword865.github.io/images/_posts/171508548949009.png&#34; alt=&#34;NewImage&#34; width=&#34;600&#34; height=&#34;260&#34; border=&#34;0&#34; /&gt;&#xD;&#xA;&lt;p&gt;填充后即得到评分矩阵&lt;/p&gt;&#xA;&lt;p&gt;&lt;span style=&#34;font-size: 14px;&#34;&gt; &lt;/span&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google在KDD2013上关于CTR的一篇论文</title>
      <link>https://sword865.github.io/archives/6/</link>
      <pubDate>Sat, 03 Aug 2013 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/6/</guid>
      <description>&lt;p&gt;最近在做CTR，刚好Google在KDD发了一篇文章，讲了他们的一些尝试，总结一下：&lt;/p&gt;&#xA;&lt;p&gt;先是一些公式的符号说明：&lt;/p&gt;&#xA;&lt;p&gt;[&lt;img style=&#34;background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;&#34; title=&#34;image&#34; src=&#34;https://sword865.github.io/images/_posts/04011358-949b9f116ca94563ab5a0efa047697db.png&#34; alt=&#34;image&#34; width=&#34;447&#34; height=&#34;98&#34; border=&#34;0&#34; /&gt;][1]&lt;/p&gt;&#xA;&lt;p&gt;一、优化算法&lt;/p&gt;&#xA;&lt;p&gt;CTR中经常用Logistic regression进行训练，一个常用的Loss Function为&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://sword865.github.io/images/_posts/04011358-9e64ee86e7f14dbd8a3da9f8a2bb7c13.png&#34;&gt;&lt;img style=&#34;background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;&#34; title=&#34;image&#34; src=&#34;https://sword865.github.io/images/_posts/04011358-03407ff016d04735b28103abc573d428.png&#34; alt=&#34;image&#34; width=&#34;329&#34; height=&#34;34&#34; border=&#34;0&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Online gradient descent(OGD)是一个常用的优化方法，但是在加上L1正则化后，这种方法不能产生有效的稀疏模型。相比之下 Regularized Dual Averaging (RDA)拥有更好的稀疏性，但是精度不如OGD好。&lt;/p&gt;&#xA;&lt;p&gt;FTRL-Proximal 方法可以同时得到稀疏性与精确性，不同于OGD的迭代步骤：&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://sword865.github.io/images/_posts/04011358-2e856d4483c64ef0a668ee8c8df2a548.png&#34;&gt;&lt;img style=&#34;background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;&#34; title=&#34;image&#34; src=&#34;https://sword865.github.io/images/_posts/04011359-6f55d3e1f55f4389979bec14102120b5.png&#34; alt=&#34;image&#34; width=&#34;187&#34; height=&#34;39&#34; border=&#34;0&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;其中$\eta_t$是一个非增的学习率&lt;/p&gt;&#xA;&lt;p&gt;FTRL-Proximal通过下式迭代：&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://sword865.github.io/images/_posts/04011359-900ea01f64a547bd99cefe8e375a3a9d.png&#34;&gt;&lt;img style=&#34;background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;&#34; title=&#34;image&#34; src=&#34;https://sword865.github.io/images/_posts/04011359-37b635900b57402a9efc1d0fbf12e7d2.png&#34; alt=&#34;image&#34; width=&#34;482&#34; height=&#34;60&#34; border=&#34;0&#34; /&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt; &lt;/p&gt;&#xA;&lt;p&gt;参数$\sigma$是学习率，一般我们有 ${\sum_{s=1}^t\sigma_s=\frac{1}{\eta_t}}$。&lt;/p&gt;</description>
    </item>
    <item>
      <title>[转] Deep Learning（深度学习）学习笔记整理系列</title>
      <link>https://sword865.github.io/archives/7/</link>
      <pubDate>Fri, 26 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/7/</guid>
      <description>&lt;p&gt;转一套Deep Learning的文章&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/zouxy09/article/details/8775360&#34;&gt;http://blog.csdn.net/zouxy09/article/details/8775360&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;顺便附上翻译的UFLDL&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B&#34;&gt;http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>决策粗糙集</title>
      <link>https://sword865.github.io/archives/8/</link>
      <pubDate>Thu, 25 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/8/</guid>
      <description>&lt;p&gt;今天收拾资料，发现了以前刚接触粗糙集时写的一个综述，好久没写博客，发上来充数好了&lt;/p&gt;&#xA;&lt;p&gt;一、粗糙集模型&lt;a href=&#34;data:image/png;base64,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&#34;&gt;1&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;粗糙集是Pawlak于上世纪八十年代提出的一种不确定数学模型。该模型以有限集合上的等价关系为基础，定义了上下近似两个基本操作。该模型与它的其他一般化或变种形式有着较为广泛的应用。&lt;/p&gt;&#xA;&lt;p&gt;1.1&lt;a name=&#34;OLE_LINK19&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK18&#34;&gt;&lt;/a&gt;Pawlak粗糙集模型&lt;/p&gt;&#xA;&lt;p&gt;Pawlak粗糙集模型是以一个有限集合与集合上的一个等价关系为基础的。所谓的二元等价关系是一种满足自反性，对称性和传递性的关系的二元关系。因为这些性质，一个二元等价关系将一个集合分割成一到多个互不相较子集，形成了集合的一个分割，记为U/R，其中的元素与他们的并被称为精确集。&lt;/p&gt;&#xA;&lt;p&gt;在这一基础上，Pawlak提出了近似的概念，所谓近似，是通过一个已有集合U的一个分割中的集合的并集对一个U的任意子集X进行逼近，作为X的近似。包括上近似于下近似两种。如，设R是U上一个等价关系，则，X的上下近似分别为:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgYAAAAvCAIAAAAXYZUgAAAHHUlEQVR4nO2d2aHcIAxFXRcFUceUQDVuxsWQD2MPiwQS4GVe7vlI8mYwxvKFK5YkiwcAAAC8994vTzcAAADAW4AlAAAACMASAAAABGAJAAAAArAEAAAAAVgCAACAACwBAABAAJYAAAAgAEsAAAAQgCUAAAAIwBIAAAAEYAkAAAACsAQAAAABWAIAj7HM4+lHAX8EKAkAAEAAlgAAACBwhyVws9rKnFf+4QOs1rhNe9HmjF1nt2NZFmmlm7NJozdnzvi3H2e13xWK2Y/RjyoAPHVd/TX1goJY3S+S90P0yLRjcfP8Ubj6GX8bX9vR2rlszhCioTRVjKKbM4LBV9EOlXpJS9DKv+uiPkQh9VNsoamrn1PvartC0nkZx+aMJN2Ibp/fPcpbWvV8i6r6WNHGGyXOk4j/27zNmf3P2siqmCBTida1HWMvll31uCXQfhAox6bV5u+tWoGyIcqKfs0SvJeFlP5MhcoS5BU+pF468yjdNJ4mnjGel7Z0SIW2BPUIr7iA6Y+rrVQijGQvqy1cbe8GNmvUZX3xJktQFS574DssoaqU/B0xC0VzTKEjNf5FS5CHdKhRcl29X701jebeSXvpPIVqa7ndEthgtWIgi6Qe9r5kh5911wxYgpR2V/mOTecMj6BhLOK2KGv5SUuQhHR8Ev13LEGQtBzfV/a2ZphCz3B1tyVUemmtA+f3mbZLyN00rOcVy3o/YAmk6LO114UhK09W2N+pjqmdcS6E8fvJFs0F7Xp8vgc/MmeJ2Pbiri6nKXPzPGs4niB8tD9FNs9sWoKkkg5LSBdGM8ZDOm5TTTXeod5IkCuh0XNxwq5HQI3b0qdvKyuq+WKJlm8ltDrZA0rvIrOEaj13WYI0kpobk9YS23NWQLFU8Pl85K2bPEvgdC/sJwu1CNusvE6cRaYLdavdR5t8/A+51mqjBTzZwEMsBNKFGJ2LB01yXh4q5gQnmyU0KlEOv+OJTDukPWsUCU1dXa3eWKKZEa92z2P2D06J7iPF5oyx9nxRgkDEbtIoNvbaGKXsXYtdwhfPErh6brMEaSQVdZcHGfOSaR9WPOuTllD+mH04vXCDVNyJUPM85fhytYtxa2bZok5C5NVcqaExjFsfIDKv6K7ChaN6JaqmT5hSi0I6aAqzLKGjsPeFtJKevr+M77OFJ92cWawj3mhTorJQUe+ZzVoYEemX+TQLR0w991mCXHR8upfvImdzJiJxVJxWiW0AlnBS2wYq1BO+XO1irLXF22gNTJszxq2Che0xS6gqsfKlfC+hWomm6cOOIA6pH7KFRy2BlGGcteRrBSE7NkYv0TDvbcdpSKL1rYjKQVfVXgJdz12WII6kot64u5BPR/YnWvefz+dFllAv09Gpyl+lMD3Ke887ApN+NPrbpjgxrErByMrY4a+yvKizBLaS+yxBEdLB/dBLLaGh3vxVFvNYSr/8UaFKmMIoI3qFwxNZ3qAr1q21BHrUvN4SNJEkr+S/PrY2mZlX9jGj+0+Bpo2vtwSygwkhZuRsd0u29Jj0o5I7M2tTkmZ1wewlWFeZaUv3EqqVRBedO56VlYDeB9WE9DV7CWXhpnqzISyVaNbjT91wD1wdbZNap253kbdk9xKizTviS/leAl3P9ZagjKSXLxydZblELSteu32HE5zcagllSeHUOy4md4U4vqtdjDH7mSK3ZqKPCrLdinkBZedpJbWXnDjyR4c6ai+6l8wSmpUkFx0dh09++s4iqkI65cSRpMAV6o0bv69YmsW4bXUhO4lXEkYkyk5ESC45ceRjde2/u3yqLLQEvh7SYrmsRW0J+kimFwsmZ98zkdltNPbhvVcuFsXcYQnaBL+eiykmCpEiwp7coY3omyTRaayjF3rI9JZWS+utP3XO7p3dNLQt/Sm+pGoJ0kqSi0IfbjyR/BBqV0gFS3UN6oq6WL3f6Nj1/OlclyAkWlsly94EMSImL0Oo9B6IYx25uop31raEZj2Fh9SyFoUldEYyfjbBFuNZgnv3RZ3jQ0nJ5ZawpCkSR+US1e1k9KVBswbz0e7WTBDoG0//q2pHp7hAlv2NalIRYSnI59TbmalP0KggnRVVoq7lir+qVstaBraXX8F7LeEH6V1+Hu5wM1zFd43n8y1htct+NP7hvjNlJe5t9D/UUDjmxbJr83W6JVSzlt+2hPEFU4b/0hIGNiRH+swkPzjboaptuiV8z13UjtW1kvEpuypv7716BofmzrNeU+YHSSse/pdQ35K1zGZ8sbTC/2YJySjVqf+f/P8SiPYoxuV44fS7LfM9o/XMqDwUgNeiezOAR5C1gIL/zRIAAP8BL8lafhBYAgAAgMBftoTWOraCpx8FAADuAIMdAACAACwBAABAAJYAAAAgAEsAAAAQgCUAAAAIwBIAAAAEYAkAAAACsAQAAAABWAIAAIAALAEAAEDgH3r0MGGqgOSdAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过2中近似，我们可以把U分为三个部分，分别称为&lt;a name=&#34;OLE_LINK4&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK3&#34;&gt;&lt;/a&gt;正域POS(X)，边界域BND(X)，和负域NEG(X),这三个域都是U/R上一些集合的并，也就是可以用R精确表示的精确集：分别表示一定属于X，可能属于X，和一定不属于X三种定义。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;进一步的，对于任意两个等价关系R，D定义：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以证明的是，在Pawlak粗糙集模型中&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHEAAAAaCAIAAAAPLyQeAAACbUlEQVRoge1Y27XEIAi0LguiHqqhGYvJ/VCjvLLGNZu9ezJ/+xBhGEAN24PVCHc78IN4OF2Ph9P1+FecEkRM7xhIGIFWeeNCcZowhhBCCNz9/etjKI8J5M8JYYaYhFFbnzMzmxgeS2eGgNl0dEpgENQvJZCsS8slC8wIgUrWEBYROm/McjxhDAGIQFqzOSWIMRpS3RcXe9JZpN2Aqdpt0x4MQGTrbZxk1d8+oWJpczhNiKSUyHoRQceYrOasUNuNjvdRLBVpwYksuSooNhJGYcritHAk6r8fEIxSOTlmC9yB1wFFd3M7+rFRx0ozZc9Flmc5+SxOCbMVVuCSUjeOCyjVRJUwCPIvWiuvYMwDb3tr7koVsc8Gp9VRtnNf3yxMuWkufOGHSMKZSraCrzHMU+qkyvyfCs8g+QWnrDvW+j+YT1XV/QrT2zkBG5ymVMsobzMz92oQp2rf6cJyf+N8ygbOfmDg88mnxtRpXTY38+3d9mCnjhKjOm2p87bRylWc9uztm4sDrhVky4Wtx/Eghta1CK1Y+Q3FK5rRmnFlsolpXSA4dVpy2948kckvc0FFQ+9DMSiXrNN2bBksA1z2vdgmrZnhM4cpNMJ2qQ7iL0Gx0SR41HuMC4C8zGqOx6aWKC6RwGpIVddhGxw+n/ZVIEPynL7pDSURJQKgsTvA6XsUPwio7nDFLaLDbe9SucvI7u3hHKuKUnUpWXrVlbhLpzlqAqCqVDUM1YpRJnpK1Sy6mtDtJk5r0Lw1Zs0eKXfk/dR9kCsb3/F+ehsSIn0m5qvxNZwmRDDOev8RX8JpbXsf6HbX40s4/Sk8nK7HH1sU7gL5/NBzAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;。&lt;/p&gt;&#xA;&lt;p&gt;1.2变精度粗糙集模型(VPRT)&lt;a href=&#34;data:image/png;base64,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&#34;&gt;2&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;在原有粗糙集模型的基础上，又可以引入变精度粗糙集的概念，变精度粗糙集通过引入一个精度参数&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;，定义&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAAAhCAIAAABP+zCnAAADOklEQVR4nO1aybXDIAx0XRREPVTD6XdCMfkH44RFG2ADydPcEiyYkcYYsI+XQrExjtUEFAoKalDF1lCDKraGGlSxNdSgiq2hBlVsDTWoYmuoQRVbQw2q2Bpq0Inw9khg/Wo+34ABg3prXOgNDs5mwcGZd+X4btNKk3UOzvT6oGQ4huBMIczbSupDSchGoETVrZPKRIxYGjS/ydHegzPln1lkbMMZgspbvSQJCs4IUgkG0gZt0estzLP4/7EkJBcTooDGaWVCR4RmUG+z/J5ZL/IIj1dExn8gf8xUjvOlo/gZVKaXGt/bpGmtQaG2LQ1a95fXwVt8SspjiQfsXOU9FhU94kV6MxNSjUsNCjZtadB6EkgNytT6QyY4QzxaZyun7iqsc8kaVKCXTsQuBoVbdjRo5c9zYZz4k6z0aWZHFgXgAYu41nTJ4Cm5BuXtS1HhJonXO2RQJgNwEA5UFNIgKNPDDCuDFv6M27are8FYwO5UwIPoODIC6tyiHFocwjvCuEX9E+7iWb3jMyieASII4QKLkv4/n2Fp0PM4xJi0VMXZCDc1VneQhAcl4vTRoPLmh5NwBuX13vCIRzNABcFcRBMl2jCf4VE2030xBg3OGOerIz8BD3Jg7JRmuUFFeu9Yg2IZIIPAiyUrTbxlPsPCoNwMSbW/C1EfSvM8WINCjaMGHXvES/XeZVBE6bhBG7b28xnmBmWf4OhYWRUEjJrWoNbBW5zRNSgJ7qWLWO8da1AsA+zg1cX8WSfVNp/hkbVJZr6aRl17vqeGxY31n2HPX2BQ8hYO8fJdu/hGvaMGpTJQBtFJAEU1vVyaz/Cowvglf5HRIkjWFa88Pz8oThPAoMsJ0MH4PeegXXq7DSrIABiEJgES1fZ2fj7Djo9F2msN4IkT4HjrAvyYtwsiht2Ye1CPJ+G8uE3U3DJBI3Z9zXSDRR9Qfm15ampdfO/9mkk45INJiBcvN2gjw87P7dqXdAyPceXeHtYDs1Xv3fSVBsWS8Ll4tUFbGa76HrQEtLqjhv6s+qLy+KgspIf+70EX4KEkfDXDn/ii/kqbceElfJP1e9g/CV0Mf8Kgit+FGlSxNdSgiq2hBlVsjX9sY9kgdo3PogAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;,重新定义正域为&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFMAAAAkCAIAAAB695EuAAAB00lEQVRoge2Y27UDIQhFrYuCrIdqbMZicj/moSAPzc3ErKXnL6MjbFBkEl6rKsx2YJo2+Xra5Otpk6+nTb6efp48RcA8+lJGiMmZY5GnGAQpS9LJzaQyfIAk7ODJCII5Yukcrp/FdL5qh8zLeYqE47DAvOEPM8JNeE+4fx6jWgCLZGzZLW7DX8AlzwiChYZSTvH1NMXWJxe8eclyTFnQZA8heBueOsCZ+Hjl2DXQLJIxOnvdyderRs8IaoyM+Nnkgs/ADpe8MCE/j8NApfJP6ZUCNLDthUxyBk5PaHOamUE6dpYgd5OX13vOgx/OdtNessiPxAGUstmEoRe8PO1Jve6ua0ScJQbRILcjb0RcvAAGvO0gzwiAiRwpdeI4uW0/a2YJXUYUbkBvIzvkd0lTfWDeDJJ7gZeTTvPdll1h1bsLoVe+Eh6ypF8Qxs95bzh5wyLVNdYIEU/LTVy3qUpJlrsVZ3uotV0jEoqaINqz8rkpxsQmNe0fYBbqAr/Pa58uKz1+Wve5gfW8Sp6bLszp4bqk90NOA/e4qg0u9J//ZrcXmElOMq5dE+/Cu3GbSJ4ixAheMZnyff6s3kL6oGaRWx9Y39HP/xv1mDb5etrk62mTr6c/nE5I7YZQGGoAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;，边界域为&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAcCAIAAACWK8TTAAAB30lEQVRYhe1YUZbDIAjMuTgQ5+E0XsbDdD+SGIEBTXc36Xspf7U4zAgi7fJ6ni13E7jBvpqfYV/Nn2aFSerZTVWIS+YANBdevB0oVWhd0nTa8uoMQZYzCqrQ4rkr3O3rfo3LtjUJFeS5cE9wBVUECtuVdbELVYW0yo1bnoRjb+jnY2u6IwCs2R7UmsQOozARgTh9GE8EAIWqspKoQh1IUMuxaqy5sCZmT7aKFKfJxNbENFRe42mSDXYVCsGik4OatWRf2VVYqjsJ3XACyROZHtzGgxNLIjgBQppN/wG5khVJ6TI9FlV225Npjg4LcJw5GeADNOvjgf2rfTxQt9wPwk2QDXdajmO34Pi8ZudoWSp1e32D/gWTNc7PWHMVIin2VcCOc5pt/7KZNgndcLvcx8Gm2vZAc2ta7imEvlOaR5JfWl0bRlz/8nRQjlvvaOvZfVZdenzx5+6zYbsPV2oKc2EsNNCGx5EDrG+AQbvFc8egJAZ9ux8eYdvuHAzSUe545AyucGGSCnqkfZ97ZjuOZouFn3qfr7Ejt654BnPYlJ2dw66wrpzBhfm16gTgNs0qy9Hw8q7s/MTu0lyYmCm5jLvXNb+fr7C3xPyV3aI5+zF0gX32f0P/Y1/Nz7Anav4BBdfEmcOg3+gAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;，负域为&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAcCAIAAAB56a/tAAAB60lEQVRYhe2Y2ZnEIAiAqYuCqIdqaMZi3IdEBcUjuxN3vpnwOJHj54oZiF8m8N8B7JYH+NPlAf50eUtgIeRwSSMwkiydTMCBEQAAwLrKP4+lcSZUPw5MSxCBsTZnjJ3P9G8kp95KmmyFhZzohYoloTol5nHMKTJGhJpM+uLQdiNrQ+lrKzHAQojomMlWAmObkMAs2YBb7xiF5qE0uau8aNedFl5A1sCBWZrEGdNCxik57e9HrJLSlUm0hTgwdvMyylmM0QCfAFXz6AVieOvNsty3HZkO4REYD2hXrChg4eOgaZ6at7uqXsE7acclF86WMQLqJOlRPJR025qQ6iE6+nm0Xic4s0DHI1OdGniCclBNZGrrwcJK/aA1XEeLpZ8AB0Zk4Walegf7wABQ3sNmA51qquqTiNwKJ7XFDd01n7dUmBP3gQ/YBKzRCgDYAXZclUT5lez4z82eFbqBmp08n/R+4jSw91ozmm5q6x8PCnQ6pUHI9yXLUnvwLxeT1h88BgBQl8fqYCpevZyHi6i9izbuhZCDM/PmPaztJAvWto915T28SUpVm76aRjuTizetLaK62BmkvyGvaO8GNvX1olv96nEs/+Jr6XYRQiIczGA6dfv38B65TvJy2Qk8+srZJm/5F8+d8gB/uvwAaPuG9PA2Px0AAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;1.3概率粗糙集模型&lt;a href=&#34;data:image/png;base64,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&#34;&gt;3&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;概率粗糙集模型是变精度粗糙集模型的进一步泛化，通过引入两个参数&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;将正域、边界域和负域分别定义为 &lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUMAAAAqCAIAAACm3a52AAAFIUlEQVR4nO2b24G0KhCEjYtITgTGQzQkYzCcB0eFvtB4aWeWv+pt1YHmswuwdacMQdDf1/TtACAIekBwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBMHJEDSC4GQIGkFwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBA3q5DSHuJz6xRLDnJyi+eM6DzN385ymaZoGTUJRbjBViGmeBCnt1Rezi47T6yhSPD+Yfi0x0BCq+D7nymNz+vzuAuW2RIxHdEsMJRh2eL1YvhePxypJgElHdYXnfuX5aAxcDTXycju9xNmRqhPMVU2Uaa7GvzYvmoTmZtFpmos/P8z9Vj8Z1h5odaqKzPj1HdX9CBR5aOvBIrglhjrYz7123Uc0cTzAs3QyN576MxMXD4TQFPMwza7ToztMo+9myq085KluO0oQOm9jWW91x0WwShgOXqbTKaOW5hCCcN/KOITk1PA/phbM/ARP4mTtFAvLwMXzNue8xJj2BpQ5MM1+NP1htjsnvVOPynNYtX6wRhw3MIYND1pLDCpWA/l5pblOGzr/LjEmhoncSzE5fZcRe067ylNcfrudbOOqgNN0Y3tG2rSL/GDuajhZ8GCxBjSSqN4JrjPgGw915rPE6qHYINXTyknVRubrwSfV2JMMW8aFTHBclXsw3OV5ZU22cVXAaYHJeQut6BWYzZbpg9qOqD2z0XNvPNPp6V6o6z5KG9nrItUqYV39lP+q8EkCaiH5ObkDZr7HkzwM9zrZxEXLg28+Cyvyh5kbTl4X1lAUBZmte418HHWFaDuwFTa56il31JOoWO0q1o8tOLIlVEfml5hd09ktnqSy1elkE1fVG33eFGc+c669LX+YWXdyO50bGaSWEzpDvS6D1xJDiImWgOULH7ufrC1KrvLstmUUql1iQI4rTNe0eJ1n+Wx85jnZxEU6I+879eR0XaydYa7SnNzunL0TqU5sZ1gBQU3JR9QKea8iqJFX12qwTn/DQKtdNJfI4vvpulh4GvG4lq57psUbPLl7u5xs4+rIW6Vq/aXMzI8l56W+lSmsTlNeg6tbPf86at8Hhfk/Hp06yCoQe8Vtjv2cmS0j59qz4kOIcnvJHXgNZr7PU9xRT0xiUwYu5d4dM4CcuGQQd2DGhVXZXGHuUvYwfXMD/QBEqnORsq1uc0sH3jSHuAj1eKmwJ79gN2bIxmk1yZSWJnKbJitjaMBC6rEC4lswhfBu8Ty5Jpu4xFDoQeFdCn22vgcz85dFr8AULj3UHlJdKuAemhO5SHvJcuSm/t5ty7ijGX5jq1+XI9k66xmd+T65x8l1RwKB4gI2gVfrhyS21XGHmV149pBknSu4VFh14vGxkFb5d9EWTw4zM55vwBSPeqvCtQ+6tRoevyhnQOMTxwuyX+H/nH4XZjZ49jv5NVEj2zwlmJnz9Id5r+2Lqt//7QWy1rct5RZKXUfyXWKPf+D1gn4W5hMNvC22v7F4ijDpH58rXWF+y8nlN5/bLjyEmGhNY7uomPeKjZD6tusSsj+Xdqt+E2b+mzxrDDZPGSZrKG+X+MH80vammMmO+k25eagGneYwz4E+PrQqjP/U/yebMHPJ8w2YRoO/rHqwVnLKMHNj+O//f7KzOiqES0pb5Ud8sXC2xDiu+lisPAHT0G2Y3W08qy+WHJoTzcFCpHJpZhtZ1qz9oQiYPboDM3+L588VDyEIuiA4GYJGEJwMQSMIToagEQQnQ9AIgpMhaATByRA0gv4HcFPRS3/biycAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;值得一提的是，这些参数并非一定要考实验者手动选择，有时可以作为数据集的一种性质而导出，比如当我们只有两个X和~X两种结论时，我们可以通过使用成本矩阵中提供的信息对参数&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;进行求解。&lt;a href=&#34;data:image/png;base64,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&#34;&gt;1&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;1.4其他粗糙集模型&lt;/p&gt;&#xA;&lt;p&gt;除了上面提到的3种模型外，还有其他一些模型如模糊粗糙集模型、代数粗糙集模型(如粗糙群、粗糙环)&lt;a href=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHEAAAAaCAIAAAAPLyQeAAACbUlEQVRoge1Y27XEIAi0LguiHqqhGYvJ/VCjvLLGNZu9ezJ/+xBhGEAN24PVCHc78IN4OF2Ph9P1+FecEkRM7xhIGIFWeeNCcZowhhBCCNz9/etjKI8J5M8JYYaYhFFbnzMzmxgeS2eGgNl0dEpgENQvJZCsS8slC8wIgUrWEBYROm/McjxhDAGIQFqzOSWIMRpS3RcXe9JZpN2Aqdpt0x4MQGTrbZxk1d8+oWJpczhNiKSUyHoRQceYrOasUNuNjvdRLBVpwYksuSooNhJGYcritHAk6r8fEIxSOTlmC9yB1wFFd3M7+rFRx0ozZc9Flmc5+SxOCbMVVuCSUjeOCyjVRJUwCPIvWiuvYMwDb3tr7koVsc8Gp9VRtnNf3yxMuWkufOGHSMKZSraCrzHMU+qkyvyfCs8g+QWnrDvW+j+YT1XV/QrT2zkBG5ymVMsobzMz92oQp2rf6cJyf+N8ygbOfmDg88mnxtRpXTY38+3d9mCnjhKjOm2p87bRylWc9uztm4sDrhVky4Wtx/Eghta1CK1Y+Q3FK5rRmnFlsolpXSA4dVpy2948kckvc0FFQ+9DMSiXrNN2bBksA1z2vdgmrZnhM4cpNMJ2qQ7iL0Gx0SR41HuMC4C8zGqOx6aWKC6RwGpIVddhGxw+n/ZVIEPynL7pDSURJQKgsTvA6XsUPwio7nDFLaLDbe9SucvI7u3hHKuKUnUpWXrVlbhLpzlqAqCqVDUM1YpRJnpK1Sy6mtDtJk5r0Lw1Zs0eKXfk/dR9kCsb3/F+ehsSIn0m5qvxNZwmRDDOev8RX8JpbXsf6HbX40s4/Sk8nK7HH1sU7gL5/NBzAAAAAElFTkSuQmCC&#34;&gt;4&lt;/a&gt;等，这些模型都是原有Pawlak粗糙集模型的泛化，可以根据不同的需要进行选择。&lt;/p&gt;&#xA;&lt;p&gt;二、决策粗糙集&lt;/p&gt;&#xA;&lt;p&gt;决策粗糙集是根据一张决策信息表定义的粗糙集模型，一张决策信息表是一个四元组{U，AT∪D，V，f},其中：&lt;/p&gt;&#xA;&lt;p&gt;U={u1,u2,u3….} |U|=n&amp;lt;+∞&lt;/p&gt;&#xA;&lt;p&gt;AT∪D表示属性的集合，分为信息属性AT和决策属性D两个互不相交的子集&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过属性的不同取值，我们可以对U进行分类，而根据AT和D两组属性，我们可以在U上定义两个等价关系，R&lt;sub&gt;AT&lt;/sub&gt;与&lt;a name=&#34;OLE_LINK8&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK7&#34;&gt;&lt;/a&gt;R&lt;sub&gt;D&lt;/sub&gt;。通过根据这两组划分中的元素的相互关系，我们可以将他们间的元素联系起来，这样我们就得到了一系列的决策规则用于未知数据的预测。&lt;/p&gt;&#xA;&lt;p&gt;2.1完备信息系统&lt;/p&gt;&#xA;&lt;p&gt;完备信息系统是指信息系统中U中每个元素ui在AT∪D上的各个属性值确定已知，没有未知或丢失属性的情况发生，对于这种信息表，我们可以简单通过观察属性值是否相同来判断两个元素是否等价。&lt;/p&gt;&#xA;&lt;p&gt;2.1.1&lt;a name=&#34;OLE_LINK17&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK16&#34;&gt;&lt;/a&gt;不可分辨关系&lt;/p&gt;&#xA;&lt;p&gt;当信息系统中的属性都是简单的定性分类数据时，我们就可以简单的在U上定义两个等价关系，分别为：&lt;/p&gt;&#xA;&lt;p&gt; &lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过这两个等价关系，我们得到了U上的两个划分，将U/R&lt;sub&gt;AT&lt;/sub&gt; 中的元素记为pi&lt;a name=&#34;OLE_LINK11&#34;&gt;&lt;/a&gt;(i=1,2..|U/R&lt;sub&gt;AT&lt;/sub&gt;|),U/R&lt;sub&gt;D&lt;/sub&gt;中的元素记为qj(j=1,2..|U/R&lt;sub&gt;D&lt;/sub&gt;|)，如果有i、j满足集合pi属于集合qj说明当一个元素与等价集合pi中的元素在AT上属性值相等时，就一定有i在D上与qj的元素属性值相等，即可得出一条规则pi-&amp;gt;qj。&lt;/p&gt;&#xA;&lt;p&gt;根据这一思想，我们可以引出更为一般的决策规则。定义信息原子表达式&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJwAAAAiCAIAAAAlGicfAAAClElEQVRoge1ayZXDIAx1XRSkeqiGZijGczCYxRJIONjPjP5pJnG0fW2QbLtiOWxvG6D4PZTUBaGkLggldUEoqQtCSV0QSuqCUFIXhJxUB8b6CZbs+757a8BNkv2PICPVW7PNjbq3ZpuXNB04iM452Cg8YV2pPhjlraleoSAgdT6jz+pB1EbCHJx/emuyIM5sU4g9dQY56BK67xJSM0dn4wVajzIIDqaKrUPr7GNdpMymwyxmVLikPhznBzMoqANAq8DBMw0XtSnXLCGASWpz1MVmb6zlhCAOjPNBpNEg+vpasqHDGj2ZQeBwDx2IxHT94ttZFqq3RpBaPFKvraB45+xa7D2i7mqXwizzlKFltLZjuNCSpP2mpbX9YtuZ28PuuwE8UqkmhISeqb1ORKik5+8ztFwF8HBWACEVL7W2wJZfbDszOVJK75FavyqaP2UmXqxOTnG0XBoar/3WB5f6+ZGB2vSLb+c5DUb27Ruk1vu1LARphiGUZqSytMhGTpKUBGNiJQO1MJz0i29nsGfsCDU+U5HtLD3TvxoKIqkHo/SmlkKauE3mH8AcFA/U/FOEX1w7j8ZvBu/XxrffPI8dbMYEZyx6LMB7G1naWfdhapH0iesZHinKTp3iTvX84top2DkR3DinltdW4T9jfZ3i6SxSJ0UzZOFxUgv6od6syodavk0XL9aTjzxxUGt4p776drZOkKFZQWOLnnKjhPYewWXMSxeFA3jwhikohNTByBBJLvS5tGKcYm35rp7XIXHqRwpN6i902su/penG+8Kp9KjzCUbfuD+MnPZWuAnfp94Y8vp9ahthGhuAeCviHBIv/eXDl0EUmJL6ZRB7mpL6YVD7h5K6IJTUBaGkLggldUEoqQviD0AoRYNKApd8AAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;表示满足信息属性ai等于v的所有元素集合。决策原子表达式&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIkAAAAlCAIAAAD5mF0LAAACfUlEQVRoge1Z3dXsIAi0LguiHquxGYvJ96Ax/oGQ9e5yz2EeNwkzYRA06y6DVrhfCzCgMG/0wrzRC/NGL8wbvTBv9MK80QvzRi/MG73geRPBh4Rec8455yC+FpGCZzx9gOj/wt6bFPwuHSl4h5vHATPC50TV4R4fBn0voGQ2BT/8cm29YRhzJGM8qjNEORFtnJKu7y3ISUER0SugvYnAycUc9R227hwiijAvlFy433InBT+QRZjJKW9Yi+acNdeuFg4RzYmp0b/V24bqQBJNeEN2kLtB+hCZjebus/XexcJeUHKJmo5NbxkQa4iVw1EuktFLSMGvY+HeYO/QS5NV2/BS8zLpC4pNxOu9K4pBG+0opVwio5WwamYFuDfYOyzSx280Y8XAqu2X62yiOQwB7LV2VbZTLpDRhCKckXuz6JSiGdCXzPTkE49PNLURqqdFoBoXVfUb5QIZtXNTx8ZL7M0wjuXz85koq/d7LBAQof0aoZcNG65ygYyS2Y0z0nnT+xXB+3487w/4JSp2402wIxpjMrOCDHFWiW2U82VkEZ7IVNEj26eNnTKCcxCQPpu3N6OC/Cu+BPIlERExRBbc/X3LY+cL5QIZjErINkvPN/WLA8S7E9w0w0J7Nr/jTowsmGb/ghFhj1KNfv2pZh30jXKmjGtzNMm+AXgf0pHvAg3r4kgX2AGYZ91vQaD8ECHUpuFD2n/rFLizsiaFwE62rBD+NSTKDxGW9NUS5X2H5uRssoY5BOrNeowRKT+Ee7E0m/zP/7957pHup1tdinrZj3DvSkId2/a/p1ZEMG+0IlLnG8MvEcGZN3ph3uiFeaMX5o1emDd6Yd7ohXmjF398uo8Q2Re48gAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;表示满足决策属性di等于v的所有元素集合。&lt;/p&gt;&#xA;&lt;p&gt;现在对信息表达式进行定义，如果&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAIAAABWXBxEAAAAkklEQVQ4je3UzQ3AIAgFYOZ6AzkP07AMw9iD1SYFlf4cmkbOfj6ERMoPihb+EVYGWO/hvp3jgZ3ikR1gZVCrJHGsDAJrzVWGyz0saY+qPde7DCY6+eNke2+7bZZ8wVoc7nmUbGYlycTbN5cdAWVR/SV7ya35c4yXHLTKsFNzsROSszIi2LVR7JYkO75Pf0MLv4Y3qPIxo0q+Q44AAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;是信息表达式则&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIsAAAAmCAIAAAB7+f+YAAABsElEQVRoge2Zy6HCIBREqYuCqIdqaIZieItnPgYI3BtIRp1ZRj0MnpAQNYnBjnm6ANMIDaGHhtBDQ+ihIfTQEHpoCD00hB4aQs9lQ9Fb6yMCZDb2oZJXDVHQbOxFQxQ0HXvNEAXNx2oNRW/NGhfugwTXfOeQbiJavVRwpqygu6TGUPTWWB+XEyB6q/gedJDgjHNnjoZ0U9DKjipLRFRSbii4l/Nl+GW8+ZDmjIZ009EKpSp+hCVNOiy4ctaxN9o6/jpid3SQ3YTLcx/STU87lqouKxm2Zw3thnpO0GH+BUcPC0rvN53GBa4fKzRUXaEdN/A9TwzJX8qOtK8es0tuI1T3aPKSyjV08yah/K0cjj61Scg+5kLdohwrNPS6aVn7f+fa5EtOTymkey9bwa7vlV3ylDON3p6OIy2peh7KSrZaTYN0YPd8MR2gpMZQiS+e/hBIH1YPRyipMFTkS3sPgXRiF7b4wQiipOqJNecHV7iozoZ0YlNKAwXdXvLr/8GL3m1bJ9SclfwBQ3bID6hTc1by6w19fGgIPTSEHhpCDw2hh4bQQ0PooSH00BB6aAg9fx1epYKxOiUQAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;也都是信息表达式，同时所有信息原子表达式是信息表达式。&lt;/p&gt;&#xA;&lt;p&gt;同理定义决策表达式，用&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAfCAIAAAByEJoXAAAAlklEQVRIie3UyRGAIAwF0F8XBaWeVJNmKEYPjGExkBw84AyclOXxI4y4Pmo40IF2hYQAIHEur5mTPpchkAQTCdXZmdOzru22FaCDbCdzanJGErUrquPGeUNCE8eN00NNIHWijFEaiTqWImSVOX5sPWZ4h71OVIPNCTuRCa0cLT4ATbd0thkhx4lDThPC5D7s/Rs50F+gG9s7LIQF46mPAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;表示。&lt;/p&gt;&#xA;&lt;p&gt;用&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAAcCAIAAABOJ2DZAAAA+0lEQVRYhe3W7RGDIAwG4MyVgZgn07BMhrE/+DBRgiiejXe+P2tDnwTkCovvwL8BB/l8c3mvjwmR+EFKM6bPB8/0OeFZvgnevZ3tfEwINSFeWZMJrdIYAACqX/aSHm3rlI8JAYlLGRPOCKE5xhhWBBOW9eXHhi+G/I3SVeFeSh7Htr7NY0KjnepbMXXoFayiDsBQxBoSsvKs4QnfMG807eMUg8Gz9glE4X2bm2ZszL6OIT3v6fbzm341lm5r9dXOvD5uke9H6g2xeazP6brVeeMHLzB9/8UwceJORFwsB1E+fzzle4p35nf0/eyO9+L/pz7y+eby+ebi3fcDVcgo4aUgmNkAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;表示规则&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAIAAABWXBxEAAAAkklEQVQ4je3UzQ3AIAgFYOZ6AzkP07AMw9iD1SYFlf4cmkbOfj6ERMoPihb+EVYGWO/hvp3jgZ3ikR1gZVCrJHGsDAJrzVWGyz0saY+qPde7DCY6+eNke2+7bZZ8wVoc7nmUbGYlycTbN5cdAWVR/SV7ya35c4yXHLTKsFNzsROSszIi2LVR7JYkO75Pf0MLv4Y3qPIxo0q+Q44AAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;中的所有元素属于&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAfCAIAAAByEJoXAAAAlklEQVRIie3UyRGAIAwF0F8XBaWeVJNmKEYPjGExkBw84AyclOXxI4y4Pmo40IF2hYQAIHEur5mTPpchkAQTCdXZmdOzru22FaCDbCdzanJGErUrquPGeUNCE8eN00NNIHWijFEaiTqWImSVOX5sPWZ4h71OVIPNCTuRCa0cLT4ATbd0thkhx4lDThPC5D7s/Rs50F+gG9s7LIQF46mPAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;。即如果元素满足表达式&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAgCAIAAABCTrX+AAAAfElEQVQ4je3TsRHAIAgFUOb6AzkP07gMw5jCoEbBkM4itD7+IZ5UvhT9+gQtDLAEtYNt7WFTu3jSwqBWKW+0MAgsmiyM1avO6Q7TMbTZ0P2ozdzaFx3FVcfGmLN3FxxvKQwioO7PWXZ57DsnJ9HSAdx1BI+v847P/2nH6wv5pzEE+KJs/AAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;，则判断其满足表达式&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAeCAIAAACqmwlGAAAAfUlEQVQ4je2SyRXAIAgFf10WRD1WQzMUEw8YgkpicvC9HPTkMiOL4vg4sIUtLBCYACBl0aXkZHM9AnEXgUl3K19nzTbmvOTk4nrBn1y8vyWoIeTt+lZwAYzv8SAlYuNHui/a2oezieMIHs7185XwzI8CU5zKnTDj//691wgFBK4w0rbwGEAAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;。这样我们就定义了最一般的规则表达式。&lt;/p&gt;&#xA;&lt;p&gt;根据粗糙集的正域POS(X)，边界域BND(X)，和负域NEG(X)，我们可以从决策信息表的两个划分中定义以下两种规则&lt;/p&gt;&#xA;&lt;p&gt;1正规&lt;a name=&#34;OLE_LINK13&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK12&#34;&gt;&lt;/a&gt;则：如果&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAAAdCAIAAAAM4yQVAAACh0lEQVRoge2YXbrtEAyGOy4Dyngymkwmg3Eu0BKJ0rL7rJ5+V2tjo6/8sflPz2l7egP/tT76T+qj/6Q++k/qo/+kPvqZCBzy3CkZHZDZu4o+wabI2Eg5uBp0dAc4hLMZee8ZnbW9+xNbh7rS9gkKlgGi+ELZyOh2yvuA/c/QO5/SMvQn0y+kz+gEKHEcgaVu6qmVQBhO25WvqVpkugz+C+kXVru35FxlfxCjOzqqSRhhMqjFhh+lnvB2dOZBtwoASdH3T0O5yi0zdZO9oB83ttA0rbisZ67L56QuU9h+BMbo9K8d8VABv4zY5uGqfZHDGvus42NsBfKeIPSYRAZUhwIZeZqGNuTzwYBd5ijVUfTCP1pXuIAGJVWeM+GrxyziPoFpY1XMaXmiblH5KgZJtTDK1p/OX6HPzHHBsA+CGX7XSd8G2v/pmkWJjZgJN/UwolKdzo4/5k73q9cc+Of0CQDtu8EA/jZ8y/hLu6+XO5v1kgwvPZBr8LM4cDUReu8L+iHKpdycYt7ZBIpM05bbF5cqLdeKy9qCzKsUI3lTqjQEj2Qb3Y5h1jxaPdL3KFCNK5ND+wTKqerMByQGtZa6cS6i3he2k5ap7uhpe53G36z3f05MxARAdXoY1/hdNxlF77/9/V13tUJNokXIcQ3yJ9iAxvKgOvRn6cdvJwBiRLp9I2g9RUrFYJ/hN+JTGv3EG+dCpQ/PgnRwgluu0PO+nzg75Lx2sPLAM+/7fy5GpPpTibJnpbEKcXj1+GPkCfYt9BkR5D39iAxEKTvHe+z81feX2xHfewf9dBHJHZ8RAI5yaP7LdLH6tcL3HfRrMQJSFgUWwr+hN9KP5Uv2hrDqnnxXb6T/O/oH/MCpGEoCNbEAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;，则有：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX8AAAAuCAIAAABPg47WAAAFG0lEQVR4nO2c24HzKgyEU5crORVQR0qggFMHzVCM/weDzdXLRUJxMt/TbhIbjMaDkEleOwAASPCS7gAA4EeB+wAAZID7AABkgPsAAGSA+wAAZID7AABkgPsAAGSA+wAAZID7AABkgPuAfqzelCm9+tq0FegPeCZ97mP19vL8rTOjzg+/CmIFjyXUQUyoCqhlKUaRW395lqFjwH16+zN0kAD1W4q+9yvbYsDqraB0q7eo949WS2iG98GJP5l94nr7GDKjGdLDdOhJT8yXz8J9Yqzekonaq4c+BivbouUH3GffXTiuvhzRCfuWvnJMKsHQGBX866YclqmMccQYTw/3SYj04mHSzcq2SPkN98m7EtrREadyquNfNSqJL8dSJmuEHDb/+Tb3Kd8XHRQdoTCrUbCyLVLqC8dvcp88PJe1GFUJUZTQZmewWhGHlTnxcTA53LT7+MVCNCMkI75UT5PNVRyBxRLm28psoHrh5TrG4EAN5z4iaqlc+l+L3IJ1+Gyn6j3pcvpomnEiqdVlSMPdVv55v9+9p6XJfVyg6qJcOptNGUXNEQqr/mkm22qfkFzCb9RxyukEcW7ltVIt1SHuPTJYEN/pK3/P+QDPDVAeLepw703jKOY+tx4vkUu7kA8M+mPcpz2J949i6dQ4WfdZppaJMsuRw2xBaun722c+16scKVBJQfTh3qthCR1Hzn12o6qaodbTTRpNkGw+ZeVVGYjSJkBr3QHHm0ZNR2O27rNILbPmUz74ZtlVnzWYankFBTGEey+Px/v9/iD3qVylYO4z0OpTqs69M9q5F41CjbPPvBapZcJ9blYa+UaJ8A3/jtU6bvrmmse5yZ4Jw70XwvLOGDgrVd1H6WpdKjoomDXZanGVZ6FtFOOZmBlRRJva2ms3UZf9XD0u9b07KLN1nya1EEhl+FHNbZmjnPzEeU8+QuMVqBsqQ0wc7r3c+2HTOaFwn2OB6cvifrlZO8jHheoWLvVxPMpP2m3YqudwRPz9mESpMygz7tOhFgKpDN3z1ewmfD/dVFiqNSc7FRn0XlA7fbjrN5Wk+wTPAbL/qge5gWDaQVDNCI7x0zfl3LZixnEJs0Jqb+t+JZI9WC2P/jUkvuHkc51B+cN93PhMq4VIKj1P3OPA3DQbnzSv/F67goqRSQQwLqfE8lnC/bn7fXoPEvsygdVq25Qhedy8eP8Se2MtQemu96v/J9XylO+dDGCNsUYpk5eH+ul3ht6BTZNaMla7j1EvZUieAXZytknzyGeZ+ywyH46gTKpFTCpLOOKaLTyH6PSf3oHl+yrHYve5cvK0JmfOD/yd9Y5AueBb6D7LzCcKSiVh72ROLVWp7E4tDVJpyNdkvM1dlVHK+OxnalNQT7GzL9ys3yJb+Ps+/uBN26Rudw2EMT4ZddsWqDj7QnAv32z4IIe7rUpQSLx6XC3/qZpU9uvO5ZIKP17vcZHmGPPxbKjl9306w809933AbxtarZS6Vr/0X8Tb2yIDTs5qxMo1ZhuhWlikIoXV2iTDzb4gCJp2f6wNt7j7WK20CS6a51vA31m75OIqhdLUJeiI1PJt5qNU8oiQe0FwNS0UblH3cavV9DHHZwn+56g/JpYlUctXScVvSzrXPisWBFfTUuEWz30AAAn8C4LPAO4DwCfxSwsCuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQIZ/yYdDh3SayLIAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;2边界规则：如果&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGMAAAAmCAIAAABfzLIdAAACJ0lEQVRoge2Yy43FIAxFqYuCXI+roRmKySwgib/gaKSMJvJdEjCXgzG8V45UTOWvDfwbJamoklRUSSqqJBVVkooqSUWVpKJKUlElqaiSVFQfJdWgYn86qGOF5n59g1SDonV76lhHE1/c1Tw6m0GKxaNjLXrFbPz8TNugzaEe4rdyqgFd1rDIltNAtoxGYrxj5WzmSukoG5M7B7e1DPASKblZI2GIowa1VsM1Na2XpQJxtKaNu7Nz2hxWL5FqwDdT7m5HbIqEWAlfJg81hi0TSsToWF2mJm+L1Hl856Rj24ywtJKoY6Ai3h/12esI2BU/XpYdUCSrVlWGzQ24wHQ4gdycmhvsot/kuba3AtpwhGI0xP1lnb1rTIHmojS8RHjKPv7pG8tzYs4kiIlvkVnNaaG5jhJEQN1Ld3tIL/tuFvRSigdL1hY13+LmX04rt5UxOU+gUc3N+HewPamOtWKTN2jE8rGs6K65dTk04+gHAb2CWPJMlyTPHOtX+/ywIXV5Vo8Ns2+cVANAv0I+QLUDdXAmV8Kqaq4n5Mm5qlPM776gPahTw/1ZYORavGC2RdrvPLbsha6Cy9hGFTYend7dZ78uN+ln3H2iTs2lsAeCx1/9wDBzw69mpIPwdR9I+0eMU5Tle4o6OPtzVw/u9Y/9Qn7ydvH0t2/09/RrVl6Az5GKPdU9LTh/kNRx/Nv/p76hJBVVkooqSUWVpKJKUlElqaiSVFRJKqofoJjgr19ncNoAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;，则有：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYsAAAAqCAIAAADNteAjAAAE5ElEQVR4nO2c0YHjIAxEU5cLoo6UQAFXB81QjO/DxsGAHDASyJt5X3fZtbHRMAhB9rUCAIBWXrMfAAAASOBQAAC9wKEAAHqBQwEA9AKHAgDoBQ4FANALHAoAoBc4FABAL3AoAIBe4FCACW8X40qfvhbrJzwP+BMwOJS3yyvwXYvOHL/8KggaPJZYB2diVUAtM3GGd7Yoz0qscDlU63PeumgC9LDjf/qRbQng7VKQv7fL6emfqRYyNPsbH06a9cDpysWYeSFOI8F3V9EcGQ5VgbdLor2gSP7YjGyLl7/sUJ+nKOSD4aPkv+cro09nhFjGnuTvDYeqwxl6duR+iZFtsfLnHaoUms1bwqMFp0kfNVkMjQ+xM6ITnKRH/YpDlYdPLUVJBVExh35kW6zQi9QfcqjFWpNnQzUOJRhi2SRnXVdJC5RxqGQuKXT9eM31tEhISkRT/W1lVkG+dVyI7i6J9ORQXwQjoxbi7ekFVxYal7jRVojOs6E6h5KyKKpUxBn9ynLU+/1uvbNgDrXHgRbu6FnxvgAoSSVTKAudbdVPZvuwcWa7ZV+WSd6gYZVHC4ZfLWQvf7vocjgfW2WJdVU6lIScqM7jjn5dh+pyqGyGqbpIll1jrcF4jEN5aypfLQwmNoky1KFIwXCr5eYmeRqakKwen0Wb+adEaqpDlVoTiT7x5LErKXOo1RmyuwU0d5Gy9yazT1nlEb1QOkjp/X7B9kNnuqPBUIeiBMOslruneMpjPXrD83GjfTo0bu4qr9CaVPTzm7zfb+0ORbz63ByqteGnVMpbp8J4VdIdDIa9PEowih3qZFHpgchw/sCYiZXyi4yNN/pZiN4ZN24sWocylqyfnS6KZl/pPdGkGPuqa/dCmvFOM8sYqmlrpUZZk0V9nrj07M1BYahDUYLhVsvNnSc6hzqGOnli86tD3Zw8v0P0OHP0CR+8bUwHYg61rXBDiT+sd6mLgrq5hjnxmOQe8PXIHnnErret2hJw3B1hwCZRagxKp0NdCYZfLXcq5XloUvspf6kkzQxHyim0ly7zuKN/sZenzqHOe63UObTkor135E5VlIZPjUPVFVe2V+g11/q2rlc92ZZTufeTzfz89xqD8sWh9v7JH71CMDJqaThtcFHm/CQixLVrpLT6EOe/fF9dySwhEf2nnYdqvWjOFztiBQgVCqW4W0lpoSYozRsU5t9T1TIc75x3xrjVW9sb63YDaerkNFHmRIVDOfMyrn/Ds5V4mPfPASNMY2RbQkF5rFomsIU5q5DcolHgTZ0s+p0aDQ71yf+T93QuzaBZOyIe5/2zwECHGmZQp6AQq4FGVKilIvWb73/7GzpjnLfWHRuDdx/solSU0RB94a/8Tf/7UOHixYZvC0RdEnZIXMh093McHGQi7RzzzoyTtXRbRFBYyj/PVMt4wgtFRaOt/7tSqpq/D9US/QFzpda/semtMeaz/K4/Kw2kOMohI9ezdfyEWry1Lu964XXGqfX9H2Ojr9OhvDXWndZgf1Fyz+JTr+UpjPDxG2rx1pr0yP24zHFe9PU51L5cjkoPF0fTwSCS5ZYafkUt4fxWvMgalznOjL4+hwIAfOc3Mkc4FADP41cyx3WFQwEANAOHAgDoBQ4FANALHAoAoBc4FABAL3AoAIBe4FAAAL3AoQAAeoFDAQD08h9L/cDSZypaqwAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;根据这两种规则，我们就得到了从该信息系统中能得出的有效规则，通过这些规则，我们就可以通过任一元素在AT上的值，去估计它在D上的结论值。&lt;/p&gt;&#xA;&lt;p&gt;另外，有时我们的属性表中虽然有确定已知的属性值，但可能数据并非简单的定性分类数据，而是定量连续数据，对于这种属性，离散化处理使其变为定性分类数据是最为简单有效的方法。&lt;/p&gt;&#xA;&lt;p&gt;2.1.2定量属性—相似关系的引入&lt;a href=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=&#34;&gt;5&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;有时，我们并不能用简单的定性分类属性表示AT中的所有属性，因此，就引入了另外两种关系：相似关系与优势关系。&lt;/p&gt;&#xA;&lt;p&gt;当AT中的属性为量化数据时，我们可以简单改变原来属性值完全相等才属于同一类别的定义，对每一个数值定义一个范围的领域，当另一元素y的该属性值属于元素x的该属性的邻域中时，我们就说y与x相似，这样我们就在U上重新定义的一个二元相似关系。&lt;/p&gt;&#xA;&lt;p&gt;由于邻域可以任意的选择(一般要包括该值自己)，所以这一新的二元关系并不一定是等价关系了，这个关系将可能不再满足传递性与对称性。我们用xRy表示x相似于y。根据R对任一个x，我们可以定义两个集合，分别表示相似于x的元素集和x相似于的元素集。&lt;/p&gt;&#xA;&lt;p&gt; &lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWwAAAAlCAIAAADp3UT+AAAENklEQVR4nO2c28GDIAyFncuBmMMRnMZlHIb/oa2CJJBwE/3P99haTMLp4SLtZAEAoIDp7gAAAM8GJgIAKAImAgAoAiYCACgCJgIAKAImAgAoAiYCACgCJgIAKAImAgAoAiYCurGv8zRNZrs7DlAXmAjoyb7OMJG3ARMBPYGJvJC+JrKZed25N4v1tZmBJsv7avhUWzBU9ix8J0e1Ef2kkKEK9Cp5lJjIZ4kbQoe6r3MqiX2dp7iS4rG0qdElzfMm3hvXuFUq0VWSp8P3RBiqf9lZHNoKBNqwQ8ojTxv2ZfIonons6+xWaTNkejKVaC4Mg2j65WHrv68zKWz9UCOrpCDOzC+agvxQCRPRdPmQ8lBrw75MHuXLmWtcH9v0I92MPPQcnbQfgVkdcrPsjPmqpJLZcdYlM9Sv8r3rNNqwQ8pDrQ37MnnUN5GvUpxItf2ulJUNXLoBd5hIWElZmO1nIjVC/ZDhCcPJ4yYTGUce9U2E9JDfBc7qzmyxtc+87sfAJVgPOmONc4vfXakB8LyVaJlZx0TiscUrKS5dj83DZKcLuWxzPFMe1Uwknr5YHnxeQnksy5K6xKOyiRD9HgS+mSMzpsr6ldtm3Hs4dzhfCW+kXWRVmYlEYktVUlq63iaStzy3lq7q8+RRdSbCp5+suSAvmTzuMZGYVxNd/p1VrdxDPe14Gnb35abU40PdhLLicoaNLVXJI45I6TrZiCRUYTNUzzxLHpWXM1z6gpoL8uLk4RrHrTMRcgOLFkp0NPn1imS+yhTFW/3RIiEfm7VdzsRjS1XSBpdxNDcSYaiKZoRvWDuePOrviZDpS2qezOtoyfv0sizDmAi5c0MWZF/NzP+OImOooWdAk9kiRxO0DwVIWWdtrNKxpSp5NBwpXe5TUCWyUHXNODxLHmpt2IQ86PRlNU/kRchjCeDi4qi+sRpkR3T51yJZPy1d9HrNrNR616pdhAmW1UliOkzFlqrk55p06fpvrObaCG0Hj5OHVhs2Kg8ufWnNY3kx8sjzjoPah82s/S3ePNP0kz/SoAuRcTKR7sbEk3SlGMl9K7aB1Jo6jE1USUHpOphIOlRFQ/5nnikPnTYsLw8+fXnN+bwi8rjLRC7rRm9Hx11EujMod1f5/HxQm1oHAchtd/992Z4ImXHs6vTGnBObqJJGULpOB2YEna5o7jIZe6g8FNqwnDyY9I1R1pzLa9hzIhK0D1O1Yyk3841NKBuTNJE2sfU6KFIPpSf8F3mUNc7l1UYevX7FK5aKfpyxbG26/1RSce9GsWXM9W9H0+X/RR6N2m4jj35/BSCJP0siR+vhaYAbh+TkxmqL2PRbjmMg1Pb/kUcJfF6t5PHC/xM5FpMDzuobxlZyXmMEev2fyMjyKCGRV0t54J/NAABFwEQAAEXARAAARcBEAABFwEQAAEXARAAARcBEAABF/AHOhzOtNNe3kgAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这样我们就得到了两个U上的覆盖(由于这个关系将可能不再满足传递性与对称性，U上所有相似类也就不再一定会构成一个U的划分，而是构成一个覆盖。于是我们有覆盖：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAU0AAAArCAIAAABzSE1gAAAD1klEQVR4nO2b26GEIAxErcuCqMMSqIZmLMb9WB88EggoKjjn695djJBhJKI7LACA3hme7gAAoDrwOQD9A58D0D/wOQD9A58D0D/wOQD9A58D0D/wOQD9A58D0D/wOWiLWY/DMCjzdD/aAj4HzTHrET7PoyGfG1V8HTdq1DP3ZXTWzFrxR97PiRy8g0sGEFUMWlM04vNZj8eY/5VbCJ2TWY+pbM16HJjJcYP23nCOvjpfHP1r1uuHiHkKUoGgdR5N+Nxxuf2Zl5AwJQLh4w3vusazgs56DKalUQM3V99LIKJIQdcYa2va59A6QhM+JxPjJ+A/I9yUGCXPEa3+XdpTl7Lti+BjtvGbCUWUKEhC+hxax2jC596V/09wofsvCFZKxBf4I0AwU96oPZmO1xP2Oq0gybrwuwmA1nEq+Xwtt/4d3GovakXmcNtSC7o/S0ibbw2s8k+ZWJHvpzTUXhSKbh+5Cc3Wvt5yLtJu54SISQXz+vxlradpijeo4HPyAae4JiMxKlG3ExIEGTLKnr1U7oh7Ifoanw51NJSNOauWo9JxDRW02wl6nVJQzue1vt3nwcb4PvTyVYhOoLeQkAkKhByHYdSae/JCdJGr5VKhogfLTr1/QXxcxek1tNshREwpmBX8e1rb3r7b506f3EItrJQkJR8/oS1tRft0sU+tLgq1T4Xaw6WqWf7U+xeMAa72epZ2zlGFIqYUzOv6t7Sepuk5n7sDcCfHiSWBniZO6ontClKaWauRf20yS/t4qDVc1g4wOZNOPkMSU0m7HULElIJ5wT+k9RSQPOelPvfSbfTxd2RFEAZOrNdB8ggh11el2MVDfM+WDrV1QTxmJhL3COnyqr2ads4ZYs/VTjj9e1oL7b1z+Xq+DdaoYRzV8c+gDLnJI4JIDLOCeyuEO42c5YpaACR7sKJQdpek8lsbPvGjq+y3J7SzulhqRl/EtIJlvV8+ovVzPrfv1pSxblrsTBVMUC+/3r2QvQoFp/dmqDLO8em3agjtJaHIlMTu2ciRxUrO65+fp7RbZq3N2rDQitYLbSIF86JDa56b35Mp83nxLk0770hlUfkBepLoT0X4gwpFlMeH1ixN+PzcHp5Mfabha7V/8H04o0q0qH9xgtY8Tfj89B5N6kh+hrxQ+5z7wAps1XvJkbXf14XWHI34fFlOFX7lv0l+GbWL3xTbrrK9HZ9F/QFAa4pbfX5quxY8jb3L1IxbwLIsjfxeDQBwCvgcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHonx9yQYDNalfpcAAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有了关系R以后，我们认为一个元素x绝对属于X当且仅当x相似于的元素都属于X，同时，所有相似于X中某一元素x的元素都有可能属于X，于是可以定义U的任意子集X在关系R下上下近似为：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有了这个两个近似后&lt;a name=&#34;OLE_LINK25&#34;&gt;&lt;/a&gt;&lt;a name=&#34;OLE_LINK24&#34;&gt;&lt;/a&gt;，我们就可以像之前一样计算POS(X),BND(X),NRG(X)并简单的定义信息系统上的两种规则了。&lt;/p&gt;&#xA;&lt;p&gt;2.1.3优势关系与排序问题&lt;/p&gt;&#xA;&lt;p&gt;但是当我们决策属不再是简单的分类关系而是一中偏序关系时，我们就不能再像以前一样进行规则的推导了，这是，就要通过引入优势关系下的近似来进行处理。&lt;/p&gt;&#xA;&lt;p&gt;在优势关系中，在属性集AT上我们定义xDy表示x比y更好，一般来说xDy定义为：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQkAAAAiCAIAAADDFrtyAAAD3UlEQVR4nO1b3ZnjIAykLhekOlwC1dCMi9l7MI75kYTANnHum3m53QvIY6GRBGTdHwAAHNy3CQDASwFtAAAPaAMAeEAbAMAD2gAAHtAGAPCANgCAB7QBADygDQDgAW38t9j84pxzbvGbPCiQ+nG0Q+FeaqX9d/Kcp41AjkHzjR/B5hflwYHco8HAPPB4Hu+kAU9tfnGL3z7/SmNML6oZuYg385xaNza/5GscQ2FuJEYmykpMFWy6oIE+P25+SRxjSJspAjWdag44bXinkQqzeI5hqjYC1elvr6jz1SEVh6c7iPpxZ00460eZRoLvkEYuKx6JCjusckb3/Dbis7k8+zFTG4IvAg32VmIJNaQjpX2ZKI1Ajogly6URu9HW1LH40eJ092Z3cZvOswd3a+OIuPhGaVqU0sRROY6p53u1mlB9z2Co1pUBpnc5t4peWMxjRK+6AjkK/HsEGhJppnd5uuA7Ze20aYVhi0Iu8WzGiWXbsa5rg+NDdSNmhCL4pDyRdVX5IL2OG6C7qFRC1U+lnY1Q3kaT1OEc1iuWbkNCOx2r1vm1s5o+7TfHXeOpxomB59e0wVZYkXAWdIU/kg48wpqaatP857lLs6fV/q9WavM0VL0/oSdYtQSXaLk1VQ8dpTtqSjZWUIuqL/JU40Tgmerhe9pgWhqxS8jjN3utzftQD+7Mp+qUtFIUVaRcGfkgoXvHUpa9cvyFzYZxfzvWjirGu1LWDTzVOOGMr+v6Im04g5TrY6rTIXxOvrVu5Am8kkbKV+p9+mM4K0+c2cHNRiRkk2ZDG+IZHi/kbilf56nFSWV9rWAh+dB+g3y9PZK2VVXPHy+DlG7lpv1GtBXvnpR+Sjxp7hZHMYGLkWc3G60H1GunWB8+L73OU4sTzrpdEh88oI299zu4B6LAaUC69tsdQs27ruvnVMlQovK2I02egdyyLM5RqJu8rv7H1Gk2qoZ6ndCxWeaHMWtnmdaLyzzVOJGmfVMb+U5M6MWbKb2jo5DOiDp3JawvE/oUjt+kgGruN1JnpOde2X+WHuNeQf3ykVmndb5n164gULtbWWONxwWeuRH+w7feb1xHfTQFVGDvyfl8GdtBygPmm/fNDE+epMpTipPfvBc3YPI3Nn4UTGv3J1TLI7bYdq5HHXclY42K+gYZ5Di5j+dLtLG/0Oxv+f0kqn4kBgMbV6dHua+P2fcPdwScyFMnmfFsxcmNwvh7iTbUbh7QEfctwjcOFr+pBz7z/i5C4mkgefDU4+T2nuMV2gAewhGPROMX7Y/jtSShDQDgAW0AAA9oAwB4QBsAwAPaAAAe0AYA8PgHUlH3Du58GJsAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;这样，我们就可以对每个x定义两个集合分别表示比x更优的元素和x比其更优的元素。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUYAAAAqCAIAAABA9GUyAAADyUlEQVR4nO2b26GEIAxELefWYEHUYQlUQzMW4/1Y96EmISCIxDm/KwQyDC/dYQEAGGJo3QAAQElgaQBMAUsDYApYGgBTwNIAmAKWBsAUsDQApoClATAFLA2AKWBpAEwBSwNgirtYOng/t24DAAboxNLBjeLvsx9dKN2mJbhhGBLqnb27cGJKbd1NaCDls3Ssa+ngBoKNpLMf2d++T8R7PPuRKpzN7MfkROcMBUWKYqUvsXWylFQXGkj5PB2rr9KzH7c9W/u+az+3SusGQfqziqrS68qc3ZUpoglOP3BOcqqdbaR8oo7VLU019TWdb3rKWDq4pH4WM3XerJk5FJQp4mLmDNosTrWzjZRP1LG2pZmWBqfZlWTImjhwpMjpFeUNhdMpumiV7lHKJ+pY2dLc3KOavKgz1fvIshZ91fPzUKlz2G56f4f9Vk0FoodCpGw0RWKXr1uk+5TyuEwrpGQsLTc4lh85rl7HaZrkBypbmjshaMYB38u11tmPx7qpiPTVhXh/Edwx9rZqYt0RZne+rC5FbJephlahTymZ9MhSSqu0KEQ0P/Iw6MHS7JlfsxsRLgxewpI/Flm26D3frurg9mGEocCW1aaI7/I1pu5SSnbvLkspbryZBuvyI8UVdPy1cVtLs5cTqvOFdAfId//0OFBWPXt/eEhr6Z+y+hSJzq1u6/6kFFMiSymfpcmKlfmJDSGq7mmabmPpU6ev+Diga6CCJm+8o9s1WnTFhm33VEKK2C4XfHfH0qmUvK1FKeOWPh65lPkR4pI6TgfYdr2paGnmEk93A7hIk3RwznN3J4Xe75GD4X2fwUkuDQWyrD5FbJcv2Xb3KyWXHlFKeWomGqzPDxuX11Hp5A/1LE2Oy2HQTOorzJXn6wDy/vFwDKpy4/2tfHCO/aIxZul9WXWK+C5fcuPdsZTcHkCUkteRbnBCfri4so7tLc3ujhIV2m1F1g8ON+8QiI1ZxffSkS8X4tcqn7LKFEW7XPu9dOdS8umRpCT34nSDk/PDxO3nvfRZbvb12PGSexdetHSVxfTCr8fOcbOvxyQ5av5tg4vbz9djp0kZCYWW6IVO8Bz9ixA/FOJlcyl10riABlIyRonIUc3SQtxyOt7e0urOlvPzJ+p6YGK/hTiWOd55aMvmUegy8CoaSPm7o9XKUdrS8bgldezA0suyLA3/Lz3+ZRwdP63KLhsncrC/K+3+L11XDp5I3NI6dmJpAIAOWBoAU8DSAJgClgbAFLA0AKaApQEwBSwNgClgaQBMAUsDYApYGgBTwNIAmAKWBsAU/+jynOrCHTlSAAAAAElFTkSuQmCC&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;而处理决策集时，我们不再简单对每一类决策类求近似，而是求他们并集的近似：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;data:image/png;base64,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&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有了这四种近似后，我们可以将(1)(2)分为一组，(3)(4)分为一组，分别按照原有方法导出两种规则求解一定属于&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC0AAAArCAIAAABjIZbQAAABFklEQVRYhe3W3RWDIAwF4MzFQMyTaViGYeyDlNOQG0UB29OT+6gRPwL+0PYboW8DStwh4w4Zd8i4Q2bIkXPurk0x8EH1mIMDkR4+c4ipLduPmJrxdWkwmcPHrbQ0RSCftj9ShBPOHEi0phxUx5AjRQIxVzdFonoz0PcU24sr+tixgXYWW3O5IFiOOl4tRA3BDj2HMpaeiLrwpMIogg7JFzrUpc+Fkw0BBf37w2L0dUQ+L93nkQOtSrdjMyb8Hrr//WEx9LpMjHboh+ABhnYMbY55DuOTsbQXwAHuh19h6xz4dY7bkJkns65/5/aNMrtBd763J780TzlWMG44ljCuO/btMZ3yF//rE+MOGXfIuEPGHTLukHkBU2B8TaHjdcAAAAAASUVORK5CYII=&#34; alt=&#34;&#34;&gt;的元素规则和可能属于&lt;img src=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACsAAAApCAIAAAAj90ecAAABBklEQVRYhe3W0RHDIAgGYOZyIOZxGpZhmPQhOS/Cb6sX0lx7+GiJfgI1oe3pQU8DUpCCFKTgLwSqOh0rXOoo+oKgFiK/sNbCYsP2Gey4WAXD0FpOm3ijsDdH9IEwPKTWQl06jkkzZwXCBMawisJEbRuQZWH7cOOOBBtI3qEy9m7zkaCt1wJdEoDAu49VfE7dgx8iUJAX9OTOhTJzLlOfBBAw0wcjwFwW+v/C3O9OgGowLdjQIU9Lz9wHI4CvQtQwAt/gdwOM4FITRAgGV/1957cCsBO+jO4Q4MsYH11rjQQtvpn2hghNyvK78d3HxlcE4YBVQTxgUbC3QSzil7+VU5CCFPyb4AUdP3ozW1qttQAAAABJRU5ErkJggg==&#34; alt=&#34;&#34;&gt;的元素规则。&lt;/p&gt;&#xA;&lt;p&gt;2.1.4成对比较表法PCT&lt;a href=&#34;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAAAhCAIAAABP+zCnAAADOklEQVR4nO1aybXDIAx0XRREPVTD6XdCMfkH44RFG2ADydPcEiyYkcYYsI+XQrExjtUEFAoKalDF1lCDKraGGlSxNdSgiq2hBlVsDTWoYmuoQRVbQw2q2Bpq0Inw9khg/Wo+34ABg3prXOgNDs5mwcGZd+X4btNKk3UOzvT6oGQ4huBMIczbSupDSchGoETVrZPKRIxYGjS/ydHegzPln1lkbMMZgspbvSQJCs4IUgkG0gZt0estzLP4/7EkJBcTooDGaWVCR4RmUG+z/J5ZL/IIj1dExn8gf8xUjvOlo/gZVKaXGt/bpGmtQaG2LQ1a95fXwVt8SspjiQfsXOU9FhU94kV6MxNSjUsNCjZtadB6EkgNytT6QyY4QzxaZyun7iqsc8kaVKCXTsQuBoVbdjRo5c9zYZz4k6z0aWZHFgXgAYu41nTJ4Cm5BuXtS1HhJonXO2RQJgNwEA5UFNIgKNPDDCuDFv6M27are8FYwO5UwIPoODIC6tyiHFocwjvCuEX9E+7iWb3jMyieASII4QKLkv4/n2Fp0PM4xJi0VMXZCDc1VneQhAcl4vTRoPLmh5NwBuX13vCIRzNABcFcRBMl2jCf4VE2030xBg3OGOerIz8BD3Jg7JRmuUFFeu9Yg2IZIIPAiyUrTbxlPsPCoNwMSbW/C1EfSvM8WINCjaMGHXvES/XeZVBE6bhBG7b28xnmBmWf4OhYWRUEjJrWoNbBW5zRNSgJ7qWLWO8da1AsA+zg1cX8WSfVNp/hkbVJZr6aRl17vqeGxY31n2HPX2BQ8hYO8fJdu/hGvaMGpTJQBtFJAEU1vVyaz/Cowvglf5HRIkjWFa88Pz8oThPAoMsJ0MH4PeegXXq7DSrIABiEJgES1fZ2fj7Djo9F2msN4IkT4HjrAvyYtwsiht2Ye1CPJ+G8uE3U3DJBI3Z9zXSDRR9Qfm15ampdfO/9mkk45INJiBcvN2gjw87P7dqXdAyPceXeHtYDs1Xv3fSVBsWS8Ll4tUFbGa76HrQEtLqjhv6s+qLy+KgspIf+70EX4KEkfDXDn/ii/kqbceElfJP1e9g/CV0Mf8Kgit+FGlSxNdSgiq2hBlVsjX9sY9kgdo3PogAAAABJRU5ErkJggg==&#34;&gt;6&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;当我们拥有一张已经排序的信息表时，除了以上提到的方法以外，还有一种成对比较表法可以处理排序问题，导出规则对未知元素进行排序。&lt;/p&gt;&#xA;&lt;p&gt;该方法的核心是将原来定义在U上的信息表扩展为一个UXU上的信息表。&lt;/p&gt;&#xA;&lt;p&gt;新的信息表表示为{UXU，AT∪D，V，f}}&lt;/p&gt;&#xA;&lt;p&gt;UXU: |UXU|=n*n&lt;/p&gt;&#xA;&lt;p&gt;AT∪D中的属性与原有信息表中的属性一一对应，但是不再表示具体的属性值，对于AT中的属性a和元素(x,y)，新的信息表中a的值表示在原信息表中元素x比y在属性a上的优异程度。而对于D中的属性值，新的信息表中的属性d仅表示x优于y或y优于x。&lt;/p&gt;</description>
    </item>
    <item>
      <title>R语言系列—-区间估计</title>
      <link>https://sword865.github.io/archives/11/</link>
      <pubDate>Sat, 30 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/11/</guid>
      <description>&lt;p&gt;这一篇讲的是区间估计…..因为这不是一个关于统计学的系列，所以对文中出现的公式不会给予任何证明…..就是这样。&lt;/p&gt;&#xA;&lt;p&gt;就从一个最简单的正态分布的方差已知时，求均值的置信区间开始吧。&lt;/p&gt;&#xA;&lt;p&gt;书上的公式告诉我们这个区间是 $$\overline{x}\pm(\sigma/\sqrt{n})z_{(1-\sigma/2)}$$ ,其中Z&lt;sub&gt;p&lt;/sub&gt;表示的是正态分布N(0,1)下侧的p分位数。&lt;/p&gt;&#xA;&lt;p&gt;我们用R来实现求得这一结果的过程。下面设x里存储了给出的样本，sigma表示已知的方差，n表示样本的个数， alpha则是(1-置信水平)&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:r decode:true&#34;&gt;mean&amp;lt;-mean(x)&#xD;&#xA;ans&amp;lt;-c(mean-sigma*qnorm(1-alpha / 2)/sqrt(n) , mean+sigma*qnorm(1-alpha / 2)/sqrt(n))&#xD;&#xA;&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;这样,ans就存储了要求的置信区间。&lt;/p&gt;&#xA;&lt;p&gt;来解释一下吧，先用mean(x)求出样本的平均值，然后用qnorm(1-alpha / 2)求出Z&lt;sub&gt;1-a/2&lt;/sub&gt;，（还记得么？前缀q是分位数函数，）剩下的就是套公式的加减法了。&lt;/p&gt;&#xA;&lt;p&gt;这里的qnorm(1-alpha / 2)其实省略了很多参数，完整一些的写法是&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:r decode:true&#34;&gt;qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;第一个参数就不用解释了，第二,三个参数mean=0,sd=1，表示这是一个标准正态分布(不同于前面，这里增加了mean=和sd=，这种做法的好处是可以改变参数的顺序，但是结果是一样的)，最后一个参数lower.tail这个参数的意思就比较有意思了，官方解释如下：&lt;/p&gt;&#xA;&lt;p&gt;if TRUE (default), probabilities are $P[X &amp;lt;= x]$, otherwise, $P[X &amp;gt; x]$.&lt;/p&gt;&#xA;&lt;p&gt;明白了么?等于真的话，得出的就是X&amp;lt;=x的分位数，为假的话就是从X&amp;gt;x的方法寻找这个值。一般我们用默认的真就可以了。&lt;/p&gt;&#xA;&lt;p&gt;接下来我们把它整理成一个函数，方便使用&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:r decode:true&#34;&gt;z.test&amp;lt;-function(x,n,sigma,alpha){&#xD;&#xA;mean&amp;lt;-mean(x)&#xD;&#xA;ans&amp;lt;-c(&#xD;&#xA;  mean-sigma*qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)/sqrt(n),mean+sigma*qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)/sqrt(n))&#xD;&#xA;ans&#xD;&#xA;}&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;这样我们就可以直接使用z.test()完成对u的置信区间的计算。&lt;/p&gt;&#xA;&lt;p&gt;比如，有10个样本，分别是175,176,173,175,174,173,173,176,173,179。标准差为1.5，求均值95%的置信区间：&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:r decode:true  &#34;&gt;x&amp;lt;-c(175,176,173,175,174,173,173,176,173,179)&#xD;&#xA;z.test(x,10,1.5,0.05)&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;则返回置信区间：&lt;/p&gt;&#xA;&lt;p&gt;[1]173.7703 175.6297&lt;/p&gt;</description>
    </item>
    <item>
      <title>R语言系列—-数据描述</title>
      <link>https://sword865.github.io/archives/10/</link>
      <pubDate>Sat, 30 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/10/</guid>
      <description>&lt;p&gt;简单来说，R语言是一种主要用于统计分析、绘图的语言和操作环境。的源代码可自由下载使用，亦有已编译的执行档版本可以下载，可在多种平台下运行，包括UNIX（也包括FreeBSD和Linux）、Windows和MacOS。R主要是以命令行操作，同时有人开发了几种图形用户界面。&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;           为什么我会使用R语言呢？毕竟我们还有SPSS,SAS，S等其他工具。就我个人而言(其实对很多人也是这样)有两个原因&amp;#8212;-R的开源与其极高的自由度。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    R是开源的，是属于GNU系统的一个自由、免费、源代码开放的软件因此在使用它时我们不用担心使用的资格问题。（当然对人一般人来说其他软件也可以使用盗版…起码国内是这样）另外作为一种语言，R拥有极高的自由度&amp;#8212;-对于，很多新的统计学模型，也许SPSS等软件根本无法处理&amp;#8212;你只能使用系统提供的有限选项。但是在R语言中，你可以自己去实现它。这也是学术界对R如此关注的原因。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    敲了这么多废话，进入正题。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    这一篇的内容是数据描述，就冲R中内嵌的一些简单分布开始吧。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    R语言中提供了四类有关统计分布的函数（密度函数，累计分布函数，分位函数，随机数函数）。分别在代表该分布的R函数前加上相应前缀获得(d，p，q，r)。如正态分布的函数是norm，命令dnorm(0)就可以获得正态分布的密度函数在0处的值(0.3989)(默认为标准正态分布)。同理pnorm(0)是0.5就是正态分布的累计密度函数在0处的值。而qnorm(0.5)则得到的是0，即标准正态分布在0.5处的分位数是0（在来个比较常用的：qnorm(0.975)就是那个估计中经常用到的1.96了）。最后一个rnorm(n)则是按正态分布随机产生n个数据。上面正态分布的参数平均值和方差都是默认的0和１，你可以通过在函数里显示指定这些参数对其进行更改。如dnorm(0,1,2)则得出的是均值为1，标准差为2的正态分布在0处的概率值。要注意的是()内的顺序不能颠倒。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;           接下来我们用R来生成一个二项分布分布的图形吧。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;           binom是二项分布。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;pre class=&#34;lang:r decode:true &#34;&gt;n&amp;lt;-20&#xD;&#xA;p&amp;lt;-0.2&#xD;&#xA;k&amp;lt;-seq(0,n)&#xD;&#xA;plot(k,dbinom(k,n,p))&lt;/pre&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    R语言中用&lt;-给变量赋值，我们先让n=20，p=0.2然后用函数seq生成一个向量(1,2,3&amp;#8230;20)并将其赋于k。然后用polt函数画图。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;           在这里，我们用dbinom(k,n,p)生成了参数为n，p的二项分布在1….20处的概率值，然后以k的各个值为横坐标，dbinom(k,n,p)的各个值为纵坐标，绘图。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    然后我们来看一些R对数据性质的描述。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    &lt;strong&gt;绘制直方图：&lt;/strong&gt;hist(x),横轴表示变量取值，纵轴表示频率。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;pre class=&#34;lang:r decode:true&#34;&gt;x&amp;lt;-c(1,2,3,4,5)&#xD;&#xA;hist(x)&lt;/pre&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    (R语言中的向量前要求加c进行说明，故第一步是让x为一个值为(1,2,3,4,5)的向量，当然也可以看成一个值为1,2,3,4,5的样本)&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    我们来画二项分布的直方图吧&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;pre class=&#34;lang:r decode:true &#34;&gt;N&amp;lt;-10000&#xD;&#xA;n&amp;lt;-100&#xD;&#xA;p&amp;lt;-0.9&#xD;&#xA;x&amp;lt;-rbinom(x,n,p)&#xD;&#xA;hist(x)&lt;/pre&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    思考一下,上面的代码是怎样运作的?&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    &lt;strong&gt;绘制茎叶图&lt;/strong&gt;： stem(x)&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;pre class=&#34;lang:r decode:true&#34;&gt;x&amp;lt;-c(11,12,13,21,22,23)&#xD;&#xA;stem(x)&lt;/pre&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    结果如下：&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    The decimal point is 1 digit(s) to the right of the |&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;      1 | 123&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;      1 |&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    2 | 123&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    另外还有&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    &lt;strong&gt;盒图：&lt;/strong&gt;boxplot(x)&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    在各种图形之后，就是对数据的数值型描述了，包括&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    最大值max(x)，最小值min(x),中位数median(x)，五个分位数fivenum(x)，平均数mean(x),样本方差var(x)，样本标准差sd(x)，样本偏度系数skewness(x)，峰度系数kurtosis(x)等等。&#xD;&#xA;  &lt;/p&gt;&#xD;&#xA;  &lt;pre class=&#34;lang:r decode:true &#34;&gt;N&amp;lt;-10000&#xD;&#xA;n&amp;lt;-100&#xD;&#xA;p&amp;lt;-0.9&#xD;&#xA;x&amp;lt;-rbinom(x,n,p)&#xD;&#xA;max(x)&#xD;&#xA;min(x)&#xD;&#xA;median(x)&#xD;&#xA;fivenum(x)&#xD;&#xA;mean(x)&#xD;&#xA;var(x)&#xD;&#xA;sd(x)&#xD;&#xA;library(fBasics)&#xD;&#xA;skewness(x)&#xD;&#xA;kurtosis(x)&lt;/pre&gt;&#xD;&#xA;  &lt;p&gt;&#xD;&#xA;    就可以得到生成的随机数据的各种描述。&#xD;&#xA;  &lt;/p&gt;</description>
    </item>
    <item>
      <title>R语言系列—回归分析</title>
      <link>https://sword865.github.io/archives/12/</link>
      <pubDate>Sat, 30 Jun 2012 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/12/</guid>
      <description>&lt;p&gt;**         **一元线形回归模型：有变量x,y。假设有关系y=c+bx+e,其中c+bx 是y随x变化的部分，e是随机误差。&lt;/p&gt;&#xA;&lt;p&gt;可以很容易的用函数lm()求出回归参数b,c并作相应的假设检验，如：&lt;/p&gt;&#xA;&lt;pre class=&#34;lang:r decode:true &#34;&gt;x&amp;lt;-c(0.10, 0.11, 0.12, 0.13, 0.14, 0.15,0.16, 0.17, 0.18, 0.20, 0.21, 0.23)&#xD;&#xA;y&amp;lt;-c(42.0, 43.5, 45.0, 45.5, 45.0, 47.5,49.0, 53.0, 50.0, 55.0, 55.0, 60.0)&#xD;&#xA;lm.sol&amp;lt;-lm(y ~ 1+x)&#xD;&#xA;summary(lm.sol)&#xD;&#xA;&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;仅列出部分返回结果：&lt;/p&gt;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  Residuals:&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;    Min       1Q   Median    3Q     Max&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  -2.0431  -0.7056  0.1694  0.6633  2.2653&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  Coefficients:&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;              Estimate Std. Error      t value   Pr(&gt;|t|)&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  (Intercept)   28.493      1.580   18.04    5.88e-09 ***&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  x            130.835      9.683   13.51 9.50e-08 ***&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  在我们的输入中，关键是lm.sol&lt;-lm(y ~ 1+x)的调用，这里可以看到，lm使用了参数y~1+x,即表示我们使用的是模型y=c+bx+e (1表示常数项)&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  然后我们使用summary查看了lm返回的结果。在Residuals:中，我们可以看到的是一些关于残差的信息：最小最大值，4分位数等。Coefficients:中则是最为关键的对c和b的相关估计。其中Estimate是与b,c值的估计，Std. Error 则是回归参数b和c的标准差：sd(b), sd(c)。剩下的两个参数则是对回归参数的假设检验： t value是对b,c进行假设检验的t值，以及P-值(用来与显著性水平比较决定是否接受该阿假设检验)Pr(&gt;|t|)。最后我们还可以看到3个* 号，这表明x和y有非常显著的线性关系(*可以有0—3个，越多则线性关系越显著)。&#xD;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>简单讲一下使用MS3D为opengl建模</title>
      <link>https://sword865.github.io/archives/124/</link>
      <pubDate>Wed, 16 Mar 2011 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/124/</guid>
      <description>&lt;p&gt;做毕设的时候写的东西，贴上来吧…………&lt;/p&gt;&#xA;&lt;p&gt;由于在OPENGL只能通过程序语言绘制模型，远不能达到可见既可得的目的。因此，比起3DMAX、MAYA等可视化3D建模工具，OPENGL模型的建立就相当的困难，为了简化这一问题的处理，可以使用简单小巧的MS3D来完成可见即可得的绘制过程。&lt;/p&gt;&#xA;&lt;p&gt;MS3D的文件有着非常简单良好的文件结构，可从该文件中完美读取在可视工具中绘制的3D图形模型包含的点、线、面等各项基本结构的参数与位置，并在OPENGL根据读取结果即可进行绘制重现该模型。&lt;/p&gt;&#xA;&lt;p&gt;MS3D全名为MilkShape3D，是一款简单小巧的3D可视化图形建模工具，可以简单的使用各种点、线面等基本图形元素组合建立模型，并进行贴图，分组。进一步的，该工具还支持简单的骨骼动画制作，是一款非常好用的3D图形构建工具。&lt;/p&gt;&#xA;&lt;p&gt;[&lt;img class=&#34;alignnone  wp-image-125&#34; src=&#34;https://sword865.github.io/wp-content/uploads/2015/02/ms3d-300x164.jpg&#34; alt=&#34;ms3d&#34; width=&#34;428&#34; height=&#34;234&#34; /&gt;][1]&lt;/p&gt;&#xA;&lt;p&gt;在建立了MS3D中完成模型建立后可保存为.ms3d的文件格式，通过对该文件格式进行分析，就可以了解文件结构，以在程序中通过读取该文件重现所见模型。&lt;/p&gt;&#xA;&lt;p&gt;该文件依次包括6段信息，除第一段文件头外，其它每段的开始位置都记录了该段中元素的数目，可用于计算该段的具体大小。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;文件头:大小固定为14字节。前10个字节为固定的标志 MS3D000000&amp;lt;-其中后6个字节就是字符0（即值为48）后4个字节为该模型格式的版本号，这4个字节为一个有符号整数，目前该版本号的值为3或4，两种版本的格式细节不同。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;点数据：紧接着文件头的就是模型的顶点数据部分，顶点部分的头两个字节为一个无符号整数，表示有多少个顶点。之后便是一个接一个的顶点的具体数据，包括可见性，x,y,z的坐标和绑定骨骼的ID编号(未绑定骨骼则为-1)。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多边形数据: 紧接着顶点数据的是多边形数据（三角形），多边形部分头两个字节是一个无符号整数，表示有多少个三角形。之后便是一个接一个的三角形数据。主要记录了每个三角形结构，包括顶点索引，顶点法线（用于光照计算），纹理坐标和组信息。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;组信息：即网格信息，出于灵活性的考虑，模型的一个个三角形被按照网格或是组来划分。网格部分头两个字节是一个无符号整数，表示有得多少个网格。之后便是一个接一个的网格数据，每个网格结构的大小可能不同（因为他们拥有的三角形数不同）。主要包括网格的名字（字符串），三角形数量、三角形索引和材质索引（无材质则为-1）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;材质信息：贴图、颜色等材质部分。头两个字节是一个无符号整数，表示有多少个材质。之后便是一个接一个的材质信息。包括材质名、环境光、漫射光、高光、自发光、发光值、透明度、贴图文件名、透明贴图文件名。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;骨骼信息： 动画、动作等。该结构是MS3D中的动态结构，仅当建立动态动画时存在，包括一种名为关键帧的结构，记录时间与对应的坐标系变换。骨骼信息，一开始是两个字节的无符号整数，表示一共有多少个骨骼，之后便是一个个的骨骼，骨骼的大小不是固定的。主要包括了骨骼名字，父骨骼名字，初始旋转与初始平移、以及之后的各个旋转与平移关键帧。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;在分析了解了MS3D的文件格式后，就可以通过编写程序读取MS3D文件并根据该文件建立模型了，对应于MS3D的不同分段，可以依次建立6种结构体分别对应每段内容：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;MS3DHeader     /\*包含ms3d文件的版本信息\*&#xD;&#xA;MS3DVertex     /\*顶点信息\*/&#xD;&#xA;MS3DMaterial   /\*材质(纹理贴图等)信息\*/&#xD;&#xA;MS3DTriangle   /\*绘制三角形信息\*/&#xD;&#xA;MS3DJoint      /\*节点(骨骼)信息\*/&#xD;&#xA;MS3DKeyframe   /\*关键窗口\*/&#xD;&#xA;//an example for vertex&#xD;&#xA;struct MS3DVertex&#xD;&#xA;{&#xD;&#xA;  unsigned char m_ucFlags;   //编辑器用标志&#xD;&#xA;  CVector3 m_vVert;        //x,y,z的坐标&#xD;&#xA;  char m_cBone;        //Bone ID （-1 ,没有骨头）&#xD;&#xA;  unsigned char m_mcUnused;      //保留，未使用&#xD;&#xA;};&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;(1)第一个成员表示了该顶点在编辑器中的状态（引擎中不是必须）其各个值的含义如下：&lt;/p&gt;&#xA;&lt;p&gt;0：顶点可见，未选中状态&lt;/p&gt;&#xA;&lt;p&gt;1：顶点可见，选中状态&lt;/p&gt;&#xA;&lt;p&gt;2：顶点不可见，未选中状态&lt;/p&gt;&#xA;&lt;p&gt;3：顶点不可见，选中状态&lt;/p&gt;&#xA;&lt;p&gt;(2)第二个成员为顶点的坐标，CVector3为三个float型组成，总共12字节&lt;/p&gt;&#xA;&lt;p&gt;(3)第三个成员为该顶点所绑定的骨骼的ID号，如果该值为-1 则代表没有绑定任何骨骼（静态）&lt;/p&gt;&#xA;&lt;p&gt;(4)第四个成员不包含任何信息，直接略过。&lt;/p&gt;&#xA;&lt;p&gt;将MS3D各段内容分别导入对应的结构体，将其读入内存。&lt;/p&gt;&#xA;&lt;p&gt;多边形（三角形）结构读取示范：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;//内存空间分配&#xD;&#xA;// pPtr为文件读取偏移指针&#xD;&#xA;int nTriangles = *( word* )pPtr;&#xD;&#xA;m_numTriangles = nTriangles;&#xD;&#xA;m_pTriangles = new Triangle[nTriangles];&#xD;&#xA;pPtr += sizeof( word );&#xD;&#xA;//读取每个三角型&#xD;&#xA;for ( i = 0; i &amp;amp;lt; nTriangles; i++ )&#xD;&#xA;{&#xD;&#xA;  MS3DTriangle *pTriangle = ( MS3DTriangle* )pPtr;&#xD;&#xA;  int vertexIndices[3] = { pTriangle-&amp;amp;gt;m_vertexIndices[0], pTriangle-&amp;amp;gt;m_vertexIndices[1], pTriangle-&amp;amp;gt;m_vertexIndices[2] };&#xD;&#xA;  float t[3] = { 1.0f-pTriangle-&amp;amp;gt;m_t[0], 1.0f-pTriangle-&amp;amp;gt;m_t[1], 1.0f-pTriangle-&amp;amp;gt;m_t[2] };&#xD;&#xA;  //数据读取&#xD;&#xA;  memcpy( m_pTriangles[i].m_vertexNormals, pTriangle-&amp;amp;gt;m_vertexNormals, sizeof( float )*3*3 );&#xD;&#xA;  memcpy( m_pTriangles[i].m_s, pTriangle-&amp;amp;gt;m_s, sizeof( float )*3 );&#xD;&#xA;  memcpy( m_pTriangles[i].m_t, t, sizeof( float )*3 );&#xD;&#xA;  memcpy( m_pTriangles[i].m_vertexIndices, vertexIndices, sizeof( int )*3 );&#xD;&#xA;  //文件读取指针前进&#xD;&#xA;  pPtr += sizeof( MS3DTriangle );&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;要注意得是，因为MS3D使用窗口坐标系而OpenGL使用笛卡儿坐标系，所以需要反转每个顶点Y方向的纹理坐标&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结9—优化</title>
      <link>https://sword865.github.io/archives/13/</link>
      <pubDate>Wed, 30 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/13/</guid>
      <description>&lt;p&gt;不同于之前的分类和聚类算法，优化的目的是尝试找到一个使成本函数输出最小化的值。这里主要包括两个算法：模拟退火算法和遗传算法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;成本函数&lt;/strong&gt;:&lt;br&gt;&#xA;接受一个经推测的题解，并返回一个数值结果，该值越大代表成本越高（题解表现越差），该值越小就表示题解越好。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;模拟退火算法：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;优化算法的目标可以看为寻找x使函数f(x)最小。&lt;/p&gt;&#xA;&lt;p&gt;但是严格的最小值往往是很难达到的，我们不得不把眼光投入到寻找一个尽可能好的次优解去。&lt;/p&gt;&#xA;&lt;p&gt;最简单的方法被称为随机法，即成千上万次的对x进行猜测，然后把这些x中使f(x)最小的一个作为答案。虽然这样很简单，但是效果很差。于是出现了爬山法。&lt;/p&gt;&#xA;&lt;p&gt;爬山法从一个随机解出发，然后不断向该解附近的使f(x)的值更小的x移动，直到当前x附近的解都比x差为止。为了使效果更好，我们可以从多个随机解出发重复着一个过程，将最好的一个作为答案。很容易就能认识到，这样找到的解是一个极值点，是一个局部最小值。&lt;/p&gt;&#xA;&lt;p&gt;爬山法虽然好，但是在其寻找最优解的过程中，前进的方向是固定的（使f(x)更小的方向），但是有时向其他方法前进也是必要的，因为f(x)可能先增大在变小成为最优的。&lt;/p&gt;&#xA;&lt;p&gt;于是就有了模拟退火法。&lt;/p&gt;&#xA;&lt;p&gt;该算法这源于固体的退火过程，即先将温度加到很高(大量原子被激发)，再缓慢降温(即退火)，则能使达到能量最低点。如果急速降温(即为淬火)则不能达到最低点。&lt;/p&gt;&#xA;&lt;p&gt;模拟退火法同样是从一个随机解出发。但是它在寻找最优解时并不一定是向更好的x移动，也有一定的概率向更差的x移动，这个概率开始较大，但是会随时间而渐渐变小，直到稳定。一般该概率可以定义为：p=e ^ (-  (highcost – lowcost ) / temperature )，其中temperature是随时间增大而变小的温度，开始温度很高时p -&amp;gt; 1，后来会渐渐变小使p-&amp;gt;0。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;遗传算法：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;遗传算法的思想来自生物的遗传和变异，算法以种群为单位（一个种群为一组既多个解），其算法的运行过程如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;随机生成一组初始解（初始种群）。&lt;/li&gt;&#xA;&lt;li&gt;计算种群中各个解的成本，然后进行排序。&lt;/li&gt;&#xA;&lt;li&gt;我们将种群中靠前（成本低）的解保留下来，删除其他解，这一过程称为精英选拔。&lt;/li&gt;&#xA;&lt;li&gt;对已有解进行微小的改变，将改变后的结果作为新的元素加入种群，这一过程称为变异。&lt;/li&gt;&#xA;&lt;li&gt;选择一些优秀的解两两组合，然后将他们按某种方式进行结合（如求平均），将得到的结果作为新的元素加入种群，这一过程称为交叉（配对）。&lt;/li&gt;&#xA;&lt;li&gt;不断重复2—5步，直到达到指定迭代次数或成本函数连续数代都没有更好的改善。&lt;/li&gt;&#xA;&lt;li&gt;得到一组解，该组解为算法输出。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;该系列结束，恩，也许以后学了更多，有了更好的了解后会回来改一改，谁知道呢？&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结8—非负矩阵因式分解</title>
      <link>https://sword865.github.io/archives/14/</link>
      <pubDate>Fri, 25 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/14/</guid>
      <description>&lt;p&gt;&lt;strong&gt;数学基础:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;线性代数的矩阵乘法运算。&lt;/p&gt;&#xA;&lt;p&gt;   非负矩阵分解是一种特征提取的算法，它尝试从数据集中寻找新的数据行，将这些新找到的数据行加以组合，就可以重新构造出数据集。&lt;/p&gt;&#xA;&lt;p&gt;   算法要求输入多个样本数据，每个样本数据都是一个m维数值向量，首先把我们的数据集用矩阵的形式写出来，每一列是一个数据，而每一行是这些数据对应维度的数值。于是我们就有了一个大小为m*n的输入矩阵。而算法的目标就是将这个矩阵分解为另外两个非负矩阵的积。&lt;/p&gt;&#xA;&lt;div&gt;$$M_{m,n}=A_{m,r}B_{r,n}$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;   我们将分解矩阵后新得出的一个维度称为特征，那么在前一个m*r的矩阵中，第i行第j列的值就代表属性i对第j种特征的贡献值，而后一个矩阵的第i行第j列则代表第i种特征对第j个样本的贡献值。这样我们就找出了输入样本的r种特征。&lt;/p&gt;&#xA;&lt;p&gt;   r的大小应该依照需要进行选择，比如如果是希望找到某些共性特征，则就要选择较小的r。当我们确定了一个较为合适的r值后，就要想办法确定后面两个矩阵具体的值了。&lt;/p&gt;&#xA;&lt;p&gt;   书中给出的算法大致如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;定义一个函数计算用来两个矩阵的差异程度（每个对应元素相减后平方的和）&lt;/li&gt;&#xA;&lt;li&gt;随机生成2个矩阵(m&lt;em&gt;r维和r&lt;/em&gt;n维)记为A（权重矩阵）,B（特征矩阵）&lt;/li&gt;&#xA;&lt;li&gt;计算A&lt;em&gt;B与输入的m&lt;/em&gt;n的数据矩阵的差异，足够小则停止，否则继续&lt;/li&gt;&#xA;&lt;li&gt;按一定规则调整A，B的值后转3.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;对于调整的方法，可以用模拟退火（下一篇文章中会提到）等多种算法，书里使用的是乘法更新法则，该法则我没有认真去看….感兴趣的可以去看论文….英文的…&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf&#34;&gt;http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;算法如下：&lt;/p&gt;&#xA;&lt;p&gt;hn 转置后的权重矩阵和数据矩阵相乘的结果&lt;/p&gt;&#xA;&lt;p&gt;hd 转置后的权重矩阵和原权重矩阵相乘再乘特征矩阵的结果&lt;/p&gt;&#xA;&lt;p&gt;wn数据矩阵与转置后的特征矩阵相乘的结果&lt;/p&gt;&#xA;&lt;p&gt;wd权重矩阵与特征矩阵相乘，再与转置后的特诊矩阵相乘得到的矩阵&lt;/p&gt;&#xA;&lt;p&gt;为了更新特征矩阵和权重矩阵，我们先把上面所有矩阵变为数组．然后把特征矩阵中每一个值与hn中对应值相乘，并除以hd中对应的值．类似的，我们再将权重矩阵中每一个值与wn中的对应值相乘，并除以wd中对应的值．&lt;/p&gt;&#xA;&lt;p&gt;最近的算法都很好理解的样子…不过写起来还是挺麻烦的….还有最后一篇优化了，内容挺多，包括模拟退火和遗传算法….恩&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;embed id=&#34;lingoes_plugin_object&#34; width=&#34;0&#34; height=&#34;0&#34; type=&#34;application/lingoes-npruntime-capture-word-plugin&#34; hidden=&#34;true&#34; /&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>算法总结7—多维缩放</title>
      <link>https://sword865.github.io/archives/15/</link>
      <pubDate>Sun, 20 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/15/</guid>
      <description>&lt;p&gt;一直没有时间写…..唉&lt;/p&gt;&#xA;&lt;p&gt;这个东西好像是属于数据可视化？反正就是把多维的数据降到低维空间但是仍然尽可能的保持原来数据之间的距离关系(就是在原来维度下离的远的点仍然离得远，接近的点仍然接近) 。最常见的应该就是降到2维以方便打印和屏幕输出。&lt;/p&gt;&#xA;&lt;p&gt;算法的输入是所有数据在高维情况下两两之间的距离（记i与j的距离为Dij）。现在以降到2维为例说明这个算法。&lt;/p&gt;&#xA;&lt;p&gt;首先我们把所有数据点随机绘制在一张二维图像上，然后计算它们两两之间的距离dij，然后我们计算出它与高维距离Dij的误差，根据这些误差，我们将每对数据点按比例移近或移远，然后重新计算所有dij，不断重复到我们没法减少误差为止。&lt;/p&gt;&#xA;&lt;p&gt;还是来具体说明一下吧，假设有n个点&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;输入每一对点之间的距离Dij。&lt;/li&gt;&#xA;&lt;li&gt;随机在2维平面生成n个点，点i坐标记为x[i]、y[i]，计算它们两之间的距离，记为dij.&lt;/li&gt;&#xA;&lt;li&gt;对所有i 和j计算：eij=(dij-Dij) / Dij，每个点用一个二维的值grad[k]来表示它要移动的距离的比例因子(初始为0,0)。在计算出每个eij后，计算 ((x[i]-x[j]) / dij)* eij，然后把它加到grad[i][x]上，同样把((y[i]-y[j]) / dij)* eij加到grad[i][y]上。&lt;/li&gt;&#xA;&lt;li&gt;把所有eij的绝对值相加，为总误差，与前一次的总误差比较(初始化为无穷大)，大于前一次的话就停止。否则把它作为上一次总误差，继续。&lt;/li&gt;&#xA;&lt;li&gt;对每个点，新的坐标为x[i] -= rate * grad[i][x]  y[i] -= rate*grad[i][y]，其中rate是开始时自己定义的一个常数参数，该参数影响了点的移动速度。重新计算各个dij，回到3。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;伪码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;for m = 1 to 1000{&#xD;&#xA;  for i=1 to n&#xD;&#xA;    for  j = 1 to n&#xD;&#xA;      dij=sqrt((x[i] – x[j])^2+(y[i]-y[j])^2)&#xD;&#xA;  for i=1 to n&#xD;&#xA;    gradi=0&#xD;&#xA;  totale=0&#xD;&#xA;  for i= 1 to n&#xD;&#xA;    for j= 1 to n{&#xD;&#xA;       if(j==i) continue&#xD;&#xA;         eij=(dij-Dij) / Dij&#xD;&#xA;         grad[i][0]+= ((x[i] - x[j]) / dij)* eij&#xD;&#xA;         grad[i][1]+=((y[i] - y[j]) / dij)* eij&#xD;&#xA;         totale+=abs(eij)&#xD;&#xA;       }&#xD;&#xA;  if (laste &amp;amp;lt; totale) break;&#xD;&#xA;  laste=totale&#xD;&#xA;  for i=1 to n{&#xD;&#xA;    x[i] -= rate * grad[i][x]&#xD;&#xA;    y[i] - = rate* grad[i][y]&#xD;&#xA;  }&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt; &lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结5&amp;6—-k-最近邻与聚类</title>
      <link>https://sword865.github.io/archives/16/</link>
      <pubDate>Mon, 14 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/16/</guid>
      <description>&lt;p&gt;因为这两个算法比较简单，又有些相似，所以这里放在一起。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;K-最近邻：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;k-最近邻也是一种用来进行预测的算法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;工作原理：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;接受一个用以进行数值预测的新数据项，然后将它与一组已经赋过值的数据项进行比较。算法会从中找出与待预测数据最为接近的k项，并这k项其求均值以得到最终的结果。&lt;/p&gt;&#xA;&lt;p&gt;总计来说这是一个很简单的算法，只要我们做好距离的定义并选择一个适合的k值，我们就可以很容易的实现它。&lt;/p&gt;&#xA;&lt;p&gt;由于我们计算2组数据的距离的通常方法是将他们中对应的每一项目的差值的绝对值(或平方)相加，所以就会出现不同数据范围不同导致的误差。比如每组数据有2个分量，一个取值为0—10,另一个是0—-999999，那么第二的值就会几乎完全决定我们最后的结果。所以我们要对每一组数据进行缩放。&lt;/p&gt;&#xA;&lt;p&gt;对数据的缩放取决于具体的应用，我们可以通过交叉验证尝试多组缩放因子然后比较它们的优劣。交叉验证的做法是先数据的一部分去除，然后用剩余数据去推测这组数据，我们就可以根据预测的结果对缩放因子进行评估。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;能利用复杂函数进行数值预测，又简单易懂，并且我们可以很容易的在算法中实现查看用哪些近邻进行预测。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;每次进行预测，它都会使用所有样本，这会导致效率的低下。&lt;/p&gt;&#xA;&lt;p&gt;寻找缩放因子是一项很乏味的工作.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;聚类：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;聚类算法可以用于任何具有一个或多个数值属性的数据集合，通过这些数值属性，我们将其所有数据映射到一个n维空间中，并定义该空间中的距离，然后我们可以通过各个数据间的距离对其实现聚类。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;分级聚类:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;分级聚类的算法是不断找出所有数据中距离最小的两个数据A、B，然后将它们合并成一个新的节点，该节点在n维空间中的坐标是原来两数据点的均值，通过不断进行这一操作，我们最终可以得到一个树形的层级结构。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;K-均值聚类:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;不同于分级聚类，K-均值聚类的目的是将数据拆成K个不同的群组，其具体算法如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在n维空间中随机生成K个中心点&lt;/li&gt;&#xA;&lt;li&gt;将每个数据项分配给与其距离最近的中心点。&lt;/li&gt;&#xA;&lt;li&gt;将中心点位置移动到所有分配给它的数据项的中心。如果中心点位置没有改变，则结束算法，否则回到第二步。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;具体选择哪种聚类算法取决于要处理的问题，当要将数据拆分到不同的群组时，k均值聚类往往是很有价值的，而如果我们更想了解哪些群组间更为接近，分级聚类更好。当然，我们也可以同时使用２种算法得到更加详细的信息。&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;embed id=&#34;lingoes_plugin_object&#34; width=&#34;0&#34; height=&#34;0&#34; type=&#34;application/lingoes-npruntime-capture-word-plugin&#34; hidden=&#34;true&#34; /&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>统计,逻辑与智能</title>
      <link>https://sword865.github.io/archives/17/</link>
      <pubDate>Thu, 10 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/17/</guid>
      <description>&lt;p&gt;      今天上了开学的第一节统计学，开了很久的小差，想了不少东西。&lt;/p&gt;&#xA;&lt;p&gt;      以前虽然自学过概率论与数理统计，但是也只是了解了一些公式与原理，一直对于统计学的一些应用不甚理解(或者说不能接受)，尤其是基于统计的机器学习，一直不能接受它作为一种实现的人工智能的手段。因为我心中的人工智能是绝对理性，严谨，逻辑的。虽然我可以接受统计学的理论，却不能把它作为一种严谨的逻辑。&lt;/p&gt;&#xA;&lt;p&gt;　 但是，今天突然想到了感性，是的，人是理性的，但是人的思维中也充满了感性的，当然，这是早已熟知的事实。&lt;/p&gt;&#xA;&lt;p&gt;　 先给感性下一个定义吧。&lt;/p&gt;&#xA;&lt;p&gt;　 感性：作用于人的感觉器官而产生的感觉，知觉和表象等直观认识，相对与‘理性’”&lt;/p&gt;&#xA;&lt;p&gt;　 是的，感性一种直观的认识，那么这种认识从哪里来呢？过去的经验。人们的感性是在经验的基础上建立的，是一种仅仅由经验得出而没有任何逻辑背景的判断。&lt;/p&gt;&#xA;&lt;p&gt;　 统计学不也是这样么？将大量的样本作为过去的经验，仅仅由这些经验而不带任何逻辑推断的去快速做出一种“感性”的判断。只是这种感性比人的感性更加严谨，不会受到类似“小概率事件经常发生”这种错觉的影响，但也可以算是一种理性的感性了。&lt;/p&gt;&#xA;&lt;p&gt;      对应的，我又想起了逻辑学，如果统计是根据经验快速简单的做出判断的话，那么逻辑学就是通过严谨的逻辑推理去寻找正确的答案，这个过程会很繁琐，但是它使绝对严谨理性的，比我们的大脑更加严谨，理性——那何不把它看成一种是理性的理性呢？&lt;/p&gt;&#xA;&lt;p&gt;     但是仅仅有统计与逻辑，我们无法建立一个系统，因此也许还需要一个驱动吧？在完成一个任务、解决一个问题时，这个驱动不断的让感性提供可能解，然后让理性验证它——突然我发现，这不就是“启发式搜索”所作的事情么？&lt;/p&gt;&#xA;&lt;p&gt;     以前翻过一些人工智能的书，总是觉的虽然那些方法可以达到目的，但是却没有触及到智能的本质，因此总是有些失望的，可是现在，我释然了。什么是智能的本质？好像是在《与众不同的心理学》这本书上，我看到过类似问题(也许问得是别的什么，不过差不多)。书里说，这是不可验证的，如果我们甚至不能解释，验证它，我们为什么可以凭借自己的主观推断去确定一个机器是否拥有智能？我们凭什么可以认为，这些机器，当他们把现在这些技术发挥到一定程度后就不可以拥有智能？也许我们自己的自我认知也只是一种数学的算法对自身产生的作用呢？（是不是有谁说过，这个宇宙，连同我们的存在，都只是一种错觉？记不清了…..不过看来这句话还是很有意思的。）&lt;/p&gt;&#xA;&lt;p&gt;　 想到了这些之后，我对“人工智能最难的是处理常识”第一次有了很深的认同，以前总是不能充分认识常识的作用，但是如果直觉，经验在智能中占了如此重要的一部分，那么我们就必须去处理常识――其中的困难自然不用多说了。&lt;/p&gt;&#xA;&lt;p&gt;     最后，把我上课时写在书上的话记录下来吧：&lt;/p&gt;&#xA;&lt;p&gt;     统计学—以理性研究感性，我们的直觉从过去的经验去推导未来，这种推断不能解释结果的原因。（因为它在历史上倾向于如此，所以它很可能如此。）统计学将这种感性理性化，并出除了一些直觉上的错误（如：小概率事件经常发生），但其根本上还是一种感性的判断，因此解释这种感性推断背后的原因，事物呈现这种状态的原因，就是人的工作了。所以统计学也可以用来在没有线索时，作为一种“事后诸葛亮”式的推断的第一步（即先找出最可能答案，在设法解释它，不过这种方法具有不可证伪性，所以不是科学严谨的――毕竟是直觉么）。同时，统计的机器学习可以就可用来模拟人的直觉学习了（而且是一种没有错误的直觉）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结4—支持向量机</title>
      <link>https://sword865.github.io/archives/18/</link>
      <pubDate>Tue, 08 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/18/</guid>
      <description>&lt;p&gt;支持向量机……复杂的东西，书里讲得也不怎么详细，起码具体算法没有说……所以又去查了些资料……&lt;/p&gt;&#xA;&lt;p&gt;支持向量机是用来对数据进行分类的。&lt;/p&gt;&#xA;&lt;p&gt;首先从最简单的情况开始吧：&lt;/p&gt;&#xA;&lt;p&gt;如果有一条直线，我们把它看成一条数轴，上面有一些样本点，其中坐标大于某个值的点都属于一类，坐标小于某个值的点都属于一类，那么我们就可以用这个值来做分分界点，它点把直线上的点分为了两类。因为样本点是有限可数的。所以这个分类点的取法不唯一。选好后，随便给我们一个点，我们就可以根据这个随机给出的点是在分界点的左侧还是右侧来判断这个点的类别。&lt;/p&gt;&#xA;&lt;p&gt;同样，一个平面上有很多样本点，这些点也分为2类，如果我们在平面上可以找到这样一条直线满足这两类样本点分别分布在直线的两侧，那么我们就可以用这个平面作分界面，来对之后随机给出的点进行分类。&lt;/p&gt;&#xA;&lt;p&gt;仍然用同样的方法，我们可以用一个平面给分布在一个3维立体空间中的点分类。&lt;/p&gt;&#xA;&lt;p&gt;总结起来就是说：在n维空间中有很多样本点，如果我们能找到一个n-1维的超平面，这个平面恰好把空间中的样本点分在它的两侧，那么我们就可以用这个n-1维的超平面来对之后随机给出点分类。&lt;/p&gt;&#xA;&lt;p&gt;这种方法有两个问题：&lt;/p&gt;&#xA;&lt;p&gt;1）  因为那个n-1维的超平面选法往往是不唯一的，我们要选哪一个?&lt;/p&gt;&#xA;&lt;p&gt;2）  更多情况下，我们找不到这样一个n-1维超平面，你可以想象更多情况下，我们要分类的数据是“混合”在一起的，很难简单的用一个点，一条线，或者一个更高纬度的线性分类器把它分开。&lt;/p&gt;&#xA;&lt;p&gt;接下来我们就要来解决这个问题。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;最优超平面的确定:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;如果选择合适的分界超平面呢？直观的来说，我们因该选择一个距离两组数据“最远”的超平面。首先每个点都和这个超平面有一个距离（该距离可以通过把n维空间放入一个n维坐标系后用代数的方法计算出来，具体计算过程此处就不说了。不过1维２维３维的情况你应该能自己算出来吧～～～，理解就好）我们选择的超平面要让所有这些距离中最小的一个值最大。&lt;/p&gt;&#xA;&lt;p&gt;我们在n维空间空建立一个n维坐标系&lt;/p&gt;&#xA;&lt;p&gt;在这个n维坐标系中，每个n-1维超平面都可一个用一个方程表示出来，这里设为。&lt;/p&gt;&#xA;&lt;div&gt;$$H(x)=a_{0}+\sum_{i=1}^{n}(a_{i}*x_{i})$$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;我们用一个变量Y表示一个点相对超平面的关系，在一侧为1.另一侧为-1.&lt;/p&gt;&#xA;&lt;p&gt;可以证明:（证明过程略）&lt;/p&gt;&#xA;&lt;p&gt;该平面在满足下面的约束时：&lt;/p&gt;&#xA;&lt;div&gt;$Y_{i}H_(x_{i})\geq 1$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;极小化函数&lt;/p&gt;&#xA;&lt;div&gt;$\frac{1}{2}\sum_{j=1}^{n}(a_{j}^{2})$&lt;/div&gt;&#xD;&#xA;&lt;p&gt;这是一个二次规划问题，我们对它求解就可以得到最优平面。&lt;/p&gt;&#xA;&lt;p&gt;有时我们找不到这样一个超平面，这时，我们可以把超平面的约束条件放的宽松一点，也就是在超平面附近允许两种分类的点的重叠，可以同过把改为（e&amp;gt;0）来实现这一目的。&lt;/p&gt;&#xA;&lt;p&gt;（具体证明与求解参考《统计学完全教程》 科学出版社 P290的支持向量机一节）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;第二个问题的解决—核方法&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;很多时候，我们是找不到一个简单的超平面对样本进行划分的，这个时候，我们可以通过坐标变换，把样本点映射到一个可以线形划分的空间中。&lt;/p&gt;&#xA;&lt;p&gt;这个映射可以是同维度的，即映射前后样本空间的纬度相同，比如：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://pic002.cnblogs.com/images/2012/52809/2012063021394557.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;就可以通过一个简单的&lt;strong&gt;求平方&lt;/strong&gt;运算，把数据从线性不可划分变为线性可分—我们可以很容易的找到一条直线把后者的样本点分成两个部分。&lt;/p&gt;&#xA;&lt;p&gt;但是很多时候，问题没有这么简单，我们就需要用另外一种映射，即把样本点映射到更高纬度的空间去。&lt;/p&gt;&#xA;&lt;p&gt;比如上面的左图还可以做这么一种变换：&lt;/p&gt;&#xA;&lt;p&gt;$$z_1=x_1x_1, z_2=\sqrt{2}x_1x_2, z_3=x_2x_2$$&lt;/p&gt;&#xA;&lt;p&gt;这样我们就可以在新的样本空间中很简单的找到一个平面把这些点分开了．仔细分析，你可以发现，这个平面其实是左图中的一个椭圆的经过上述变换后得到的．&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;较高维空间的线性分类器对应于原空间的一个非线性分类器．&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;这就是&lt;strong&gt;核方法&lt;/strong&gt;的核心。&lt;/p&gt;&#xA;&lt;p&gt;通过找到一个合适的映射，我们就可以前面的问题(2)了&lt;/p&gt;&#xA;&lt;p&gt;这种映射称为核函数，核函数的选择是很有技巧的，它也有一些常见的模型，很多时候我们只要选择合适的模型并计算适当的参数就可以了。具体方法这里不说了，有兴趣的可以参见《&lt;a href=&#34;http://download.csdn.net/source/1353188&#34;&gt;RBF核函数的支持向量机参数选择&lt;/a&gt;》一文。&lt;/p&gt;&#xA;&lt;p&gt;找到核函数后，我们就完全解决上述问题了。&lt;/p&gt;&#xA;&lt;p&gt;（其实这里还有一些简化计算的技巧，这些技巧与其它更具体的东西还是可以去看《统计学完全教程》 科学出版社，真是一本非常强大的书。）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;优点:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;可以很快的判断一个样本的种类。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;缺点:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;由于对每个数据集的最佳核变换及相应参数都不一样，所以对每个数据集都要重新学习确定函数与参数。&lt;/p&gt;&#xA;&lt;p&gt;一般而言，支持向量机更适合包含大量数据的问题，而其他方法如决策树，更适合小规模的数据集。&lt;/p&gt;&#xA;&lt;p&gt;支持向量机也是一种黑盒技术，由于存在像高维空间的判断，我们很难解释分类的具体标准与原因。&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;embed id=&#34;lingoes_plugin_object&#34; width=&#34;0&#34; height=&#34;0&#34; type=&#34;application/lingoes-npruntime-capture-word-plugin&#34; hidden=&#34;true&#34; /&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;p style=&#34;margin:0;padding:0;height:1px;overflow:hidden;&#34;&gt;&#xD;&#xA;  &lt;a href=&#34;http://www.wumii.com/widget/relatedItems&#34; style=&#34;border:0;&#34;&gt;&lt;img src=&#34;http://static.wumii.cn/images/pixel.png&#34; alt=&#34;无觅相关文章插件，快速提升流量&#34; style=&#34;border:0;padding:0;margin:0;&#34; /&gt;&lt;/a&gt;&#xD;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结3—神经网络</title>
      <link>https://sword865.github.io/archives/19/</link>
      <pubDate>Mon, 07 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/19/</guid>
      <description>&lt;p&gt;&lt;strong&gt;生物神经网络：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;    &lt;/strong&gt; 在生物的神经网络中的基本单位是神经元，神经元与神经元之间是由突触的相互联系来传递信息的，在静止息状态时，神经元的膜的内外电压保持一种稳定状态（膜内电压低于膜外电压），当神经元受到刺激后，在被刺激的部分周围，这种平衡状态会被打破，电压改变，与没有受到刺激的部分形成电流传递信息，电流的强弱取决于受刺激部位电压的改变量。&lt;/p&gt;&#xA;&lt;p&gt;     前一个神经元的轴突末梢作用于下一个神经元的胞体、树突或轴突等处组成突触。不同的轴突末梢可以释放不同的化学物质对下一个神经元产生不同的影响。也就是说会使下一个神经元的受刺激部分产生不同的电压，也就导致了不同程度的电流，最终也就传递了完全不同的信息。&lt;/p&gt;&#xA;&lt;p&gt;     一个神经元可以通过轴突作用于成千上万的神经元，也可以通过树突从成千上万的神经元接受信息。当多个神经元同时对一个神经元产生作用时，结果这些神经元的作用强度共同决定。&lt;/p&gt;&#xA;&lt;p&gt;     神经系统按功能可大致分为传入神经（感觉神经）、中间神经（脑：延脑、脑桥、小脑、中脑、间脑、大脑脊髓）与传出神经（运动神经）三类。&lt;/p&gt;&#xA;&lt;p&gt;     感受神经的作用是接受外界信息（输入），中间神经则起到了信息传递与计算分析的作用，最用，传出神经会负责对外界信息作出相应的反应（输出）。&lt;/p&gt;&#xA;&lt;p&gt;     模仿这一过程，我们就可以建立人工神经网络。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;人工神经网络：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;     人工神经网络的基本单位是人工神经元（以下简称神经元）。一个神经元可以有多个输入，每个输入有一个相应权值。&lt;/p&gt;&#xA;&lt;p&gt;图示如下：&lt;/p&gt;&#xA;&lt;img class=&#34;alignnone  wp-image-125&#34; src=&#34;http://upload.wikimedia.org/wikipedia/commons/9/97/Ncell.png&#34; alt=&#34;nn&#34; /&gt;&#xD;&#xA;&lt;pre&gt;&lt;code&gt;a1~an为神经元的输入值&#xD;&#xA;w1~wn为神经元各个的输入所拥有的权值&#xD;&#xA;b为偏移量&#xD;&#xA;sum对各个输入与其权值的积求和(含偏移量)。&#xD;&#xA;f为传递函数，接受sum的输出，通过一个函数变换，输出t&#xD;&#xA;t为神经元输出&#xD;&#xA;数学表示 t=f(WA&#39;+b)&#xD;&#xA;W为权向量&#xD;&#xA;A为输入向量，A&#39;为A向量的转置&#xD;&#xA;b为偏移量&#xD;&#xA;f为传递函数&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;在人工神经网络中，神经元之间相互连接，在连接点将前者的输出作为后者的输出，形成错综复杂的网状结构，进行信息的传递与计算。&lt;/p&gt;&#xA;&lt;p&gt;我们这里要介绍的是其中比较简单的一种模型，称为“多层感知机（MLP）”网络。&lt;/p&gt;&#xA;&lt;p&gt;为了简化模型，我们假设偏移量b=0.&lt;/p&gt;&#xA;&lt;p&gt;多层感知机网络由3部分组成：&lt;/p&gt;&#xA;&lt;p&gt;输入层：功能类似感受神经，每个节点接受外界的直接输入。这里的模型中，每个节点接受单一输入，权值为1。&lt;/p&gt;&#xA;&lt;p&gt;输出层：功能类似运动神经，该层输出就是神经网络的输出。&lt;/p&gt;&#xA;&lt;p&gt;隐藏层：是输入层和输出层之间的多层神经网络，可以有1或多层。&lt;/p&gt;&#xA;&lt;p&gt;因此，MLP网络中至少有3个层次。&lt;/p&gt;&#xA;&lt;img class=&#34;alignnone  wp-image-125&#34; src=&#34;https://sword865.github.io/images/_posts/2012063021381464.jpg&#34; alt=&#34;mlp&#34; /&gt;&#xD;&#xA;&lt;p&gt;这些层次中，每层的每个神经元的输出都会作为下一层的每个神经元的输入，因此当我们对输入层进行输入后，该信息会一层层传递下去，最终从输出层输出。&lt;/p&gt;&#xA;&lt;p&gt;神经网络建立后，我们需要设法确定每个神经元的各个输入的权重w，并选择合适的函数f对输入进行变换，只有完成以上工作后，我们才能使用神经网络完成相应的工作。&lt;/p&gt;&#xA;&lt;p&gt;我们一般会选择过关于源点对称的S形函数作为函数f，该种函数特点是:输入接近0时，函数对输入的变化有敏感的反应，这一敏感度将随输入绝对值的增大而下降，最终趋于0。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;权重的获取：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;选择合适的函数后，我们就要去确定各权重w了，权重的选择取决于我们想要神经网络完成的任务，我们首先会给每个输入一个初始化的默认值，该值可任意选取。&lt;/p&gt;&#xA;&lt;p&gt;完成初始化后，我们就要开始训练神经网络了，即给神经网络大量的已知的正确的输入及其对应的输出，神经网络会将自己得到到的输出与正确输出向比较，然后根据某一算法调整自身的权重，使自身输出更接近正确答案。&lt;/p&gt;&#xA;&lt;p&gt;我们这里要介绍的调整算法称为&lt;strong&gt;反向传播法&lt;/strong&gt;，因为该算法是沿网络反向调整权值的。&lt;/p&gt;&#xA;&lt;p&gt;这一算法中，我们会分析输出与正确答案，并将将输出向正确答案推进，为了了解如何推进，我们需要一个函数来计算函数f的斜率，设该函数为g。根据该函数，我们可以计算sum因改变的值。&lt;/p&gt;&#xA;&lt;p&gt;整个算法如下：&lt;/p&gt;&#xA;&lt;p&gt;从后向前对输出层和所有隐含层：&lt;/p&gt;&#xA;&lt;p&gt;1）  计算节点当前输出与期望结果的差值d。(期望结果t – 实际输出 y)&lt;/p&gt;&#xA;&lt;p&gt;对输出层: t在输入训练数据时一同输入。&lt;/p&gt;&#xA;&lt;p&gt;对隐含层: t = sum ( 前一层的每个节点的差值di * 这两个节点间连线的权值 )&lt;/p&gt;&#xA;&lt;p&gt;2）  利用函数g确定函数f在节点输出值y处的改变速率v。v=g(y)&lt;/p&gt;&#xA;&lt;p&gt;3）  改变每个输入链接的权值，其改变量与链接的当前输入强度与学习速率rate（自己定义的属于(0,1)的常量）成正比。&lt;/p&gt;&#xA;&lt;p&gt;（每个wi的改变量为（v&lt;em&gt;d&lt;/em&gt;rate*输入ai））&lt;/p&gt;&#xA;&lt;p&gt;这样一层层的从后向前反推，最终完成对一个训练样本的学习。&lt;/p&gt;&#xA;&lt;p&gt;当对所有样本完成训练后，我们就可以使用这个神经网络了。&lt;/p&gt;&#xA;&lt;p&gt;比如，我们想用神经网络模拟一个数学函数，我们先向网络提供大量的正确的输入输出进行训练，然后就可以用神经网络作模拟这个函数进行计算了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结2—决策树分类器</title>
      <link>https://sword865.github.io/archives/20/</link>
      <pubDate>Sun, 06 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/20/</guid>
      <description>&lt;p&gt;&lt;strong&gt;数学基础：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;树：树是一种数据结构，它是由n（n&amp;gt;=1）个有限结点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：&lt;/p&gt;&#xA;&lt;p&gt;每个结点有零个或多个子结点；&lt;/p&gt;&#xA;&lt;p&gt;每一个子结点只有一个父结点；&lt;/p&gt;&#xA;&lt;p&gt;没有前驱的结点为根结点；&lt;/p&gt;&#xA;&lt;p&gt;除了根结点外，每个子结点可以分为m个不相交的子树；&lt;/p&gt;&#xA;&lt;p&gt;没有子节点的节点称为叶节点。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;决策树分类器原理：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;决策树是一颗树，要分类的样本从树根进入，在树的每个节点通过对样本的某种属性的判断选择不同的路径逐步下降到底,得出其所属类别。&lt;/p&gt;&#xA;&lt;p&gt;例图:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://pic002.cnblogs.com/images/2012/52809/2012063021362216.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;为了建立一棵决策树,我们首先应向程序输入大量训练数据(包含所属类别的数据)，程序将根据训练数据按某一算法自动生成决策树。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;决策树生成算法:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;   为了构造决策树，算法首先创建一个根节点，然后通过分析训练数据，逐步选出适合的变量对数据进行拆分(即逐步构造上图中的非叶子节点。)&lt;/p&gt;&#xA;&lt;p&gt;   为了选择适合的变量对数据进行拆分，我们需要一个方法来评估一种拆分方案的好坏，&lt;strong&gt;其评估方法包括：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;基尼不纯度：&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;定义：基尼不存度是指来自集合的某种结果随机应用于集合中某一数据的预期误差。（如果集合中所有结果属于同一类，则误差为0）&lt;/p&gt;&#xA;&lt;p&gt;使用：利用这一思想，我们可以将集合中每种类别的数据出现的次数除以数据总数计算相应概率，再将这些概率的乘积相加（所有概率两两相乘后在相加），这样就会得到某一数据被随机分配到错误结果的总概率。&lt;/p&gt;&#xA;&lt;p&gt;伪代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;imp=0&#xD;&#xA;for k1 in kinds&#xD;&#xA;    p1=count(k1) / total&#xD;&#xA;    for k2 in counts&#xD;&#xA;        if (k1==k2)continue&#xD;&#xA;        p2=count(k2) / total&#xD;&#xA;        imp+=p1*p2&#xD;&#xA;ans=imp&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &amp;nbsp;&amp;nbsp; (p1*p2是一个p1类别的数据被当作p2的概率)&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;**熵：**在信息论中，熵代表的是集合的无序程度—–基本上就相当于我们在此处所说的集合的混杂程度。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;熵的值是遍历所有结果后得到的pi*log2(pi)的和的绝对值&lt;/p&gt;&#xA;&lt;p&gt;伪代码：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ent=0.0&#xD;&#xA;for k in kinds&#xD;&#xA;    p=count(k) / total&#xD;&#xA;    ent=ent – p*log2(p)     // 因为0&amp;lt;p&amp;lt;=1，所以必有log2(p)&amp;lt;=0&#xD;&#xA;ans=ent&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;有了上述评估方法后，我们就可以不断尝试各种拆分方法，然后选出最好的拆分方法构造树中的节点了。我们将计算拆分前的熵（基尼不存度）值，与拆分后的熵（基尼不存度）的值的加权平均，将其差值作为&lt;strong&gt;信息增益&lt;/strong&gt;。最终对能得到最大信息增益的属性进行拆分。然后再分别对拆分后得集合选择属性进行拆分，直到最大信息增益为非正时停止拆分，这时决策树就构建完毕了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;优化：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;为了防止决策树变的过度拟合（过度针对训练数据），我们可以在信息增益小于某个值后就停止拆分。但是我们可能遇到这样的数据―――某次拆分信息增益很小，但下一次就会很大。为了防止这一状况，我们可以在用先前的方法构造整棵树后，在尝试消除多余的节点。这个过程就是&lt;strong&gt;剪枝&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;剪枝的过程就是对具有相同父节点的节点进行检查，判断将其合并后，信息增益是否会小于某个指定发值。若是，则合并这些节点。合并后节点包括所有可能的结果值。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;在处理数值型数据时，熵和基尼不存度并不是一个好的选择，因为有些数值相差很近，有些相差很远，不能简单用是否为同一类别进行判断。所以我们可以用方差代替它们。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;决策树对缺失数据的处理：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;当我们要判断类别的样本缺少某些决策树作判断时必须的数据时，我们可以选择同时走两个分支，不过我们不是平均统计各分支的结果值，而是进行加权统计。为了达到这一目标，决策树中每个节点都有一个值为１的权重，即观测数据对于数据向是否属于某个特定分类的概率具有１００％的影响，而如果走多个分支，我们将给每个分支一个权重，其值等于所有位于该分支的其他数据所占的比重。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;决策树最大的优势是它可以轻易对一个受训模型给予解释。（解释分类原理）&lt;/p&gt;&#xA;&lt;p&gt;决策树可以同时接受分类型和数值型数据。&lt;/p&gt;&#xA;&lt;p&gt;比起贝叶斯分类器（参考**[&amp;lt;集体智慧编程&amp;gt;算法总结1—贝叶斯分类器][2]**）决策树可以更好的处理变量间的相互影响。&lt;/p&gt;</description>
    </item>
    <item>
      <title>算法总结1—贝叶斯分类器</title>
      <link>https://sword865.github.io/archives/21/</link>
      <pubDate>Sat, 05 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/21/</guid>
      <description>&lt;p&gt; 这几天以很快的速度翻完了&amp;lt;集体智慧编程&amp;gt;,因为只是对里面的算法感兴趣,对那些web2.0的应用没什么感觉,所以很多地方都是一扫而过,现在按最后一章的顺序来对所有相关的算法作一个详细的复习….&lt;/p&gt;&#xA;&lt;p&gt;这个是第一篇……贝叶斯分类器&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;数学基础：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;条件概率&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;定义：设A, B是两个事件，且P(A)&amp;gt;0 称P(B∣A)=P(AB)/P(A)为在条件 A下发生的条件事件B发生的条件概率。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;乘法公式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设P(A)&amp;gt;0，则有P(AB)=P(B∣A)P(A)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;全概率公式和贝叶斯公式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;定义: 设S为试验E的样本空间，B1, B2, …Bn为E的一组事件，若BiBj=Ф, i≠j, i, j=1, 2, …,n; B1∪B2∪…∪Bn=S则称B1, B2, …, Bn为样本空间的一个划分。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设试验E的样本空间为，A为E的事件，B1, B2, …,Bn为的一个划分，且P(Bi)&amp;gt;0(i=1, 2, …n)，则P(A)=P(A∣B1)P(B1)+P(A∣B2)+ …+P(A∣Bn)P(Bn)称为全概率公式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设试验E的样本空间为S，A为E的事件，B1, B2, …,Bn为的一个划分，则P(Bi∣A)=P(A∣Bi)P(Bi)/∑P(B｜Aj)P(Aj)=P(B｜Ai)P(Ai)/P(B)称为贝叶斯公式。&lt;/p&gt;&#xA;&lt;p&gt;说明：i，j均为下标，求和均是1到n&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;贝叶斯分类器原理：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过某些特征对不同的内容进行分类。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;特征的定义&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;任何可以用来判断内容中具备或缺失的东西。如要对文档进行分类时，所谓的内容就是文档，特征就是文档中的单词(当然你也可以选择其他合理的东西)&lt;/p&gt;&#xA;&lt;p&gt;当向贝叶斯分类器输入一个要进行分类的样本后，分类器会先对该样本进行分析，确定其特征，然后将根据这些特征时，计算样本属于各分类的概率。&lt;/p&gt;&#xA;&lt;p&gt;朴素贝叶斯分类器的具体工作步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;学习：向分类器输入一系列的训练数据，注意这些数据是包括其所属类别的，分类器将对训练数据进行分析，计算出&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;1.各个特征在各个分类中出现的概率(=某分类中具有该特征的数据数目/该分类数目)如先计算出各个单词在各种分类的文档出现的概率。&lt;/p&gt;&#xA;&lt;p&gt;将该概率作为某分类下某特征出现的条件概率P(feature|category)&lt;/p&gt;&#xA;&lt;p&gt;2.任选一个样本属于某分类的概率(=某分类文章数 / 文章总数)&lt;/p&gt;&#xA;&lt;p&gt;记该概率为p(category)&lt;/p&gt;&#xA;&lt;p&gt;在朴素的贝叶斯分类器中，我们假设将要组合的各个概率相互独立(当然，很多时候并非如此。我们有时会发现，当样本拥有某一特征时，则它就更可能拥有另一项特征。)&lt;/p&gt;&#xA;&lt;p&gt;2)分类计算：在向分类器提供大量学习数据后，我们就可以用它对新的样本进行分类了。&lt;/p&gt;&#xA;&lt;p&gt;首先对样本进行分析，找出其具有的各种特征，利用这些特征，我们来计算各个分类中出现该样本的概率p(sample | category)。为了完成这一计算，我们只要简单将该分类下在该文档中出现过的特征出现的条件概率相乘即可。即∏P(feature | category) 这里的feature是该样本拥有的所有特征。&lt;/p&gt;&#xA;&lt;p&gt;但是，我们实际要计算的是P (category | sample),即给定样本属于某分类的条件概率。&lt;/p&gt;&#xA;&lt;p&gt;这里，就用到了贝叶斯定理：P(A | B)=P(B | A)P(A) / P(B)&lt;/p&gt;&#xA;&lt;p&gt;这里就是：P(category | sample)= P(sample | category)P(category) / P(sample)&lt;/p&gt;</description>
    </item>
    <item>
      <title>读《你的灯亮这么》—走出问题的乌托邦</title>
      <link>https://sword865.github.io/archives/22/</link>
      <pubDate>Tue, 25 Aug 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/22/</guid>
      <description>&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  军训期间闲着无聊时,决定读一些&amp;ldquo;杂书&amp;rdquo;，其中有一本叫《你的灯亮着么?》的小册子，刚读完不久，趁着今晚休息的时间作以记录。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &lt;strong&gt;1)&lt;/strong&gt;&lt;strong&gt;动手解决问题前，好好想想问题的来源。2)如何从各个角度看待问题，找到其真正所在。3)为什么不要把人们的解决方法误以为是问题的定义，更不要把某个问题的解决方法误认为是问题的定义，特别是整个解决方法是你自己所使用的。4)永远不要肯定你已经有了一个正确的定义，即使是在问题好像已经解决之后。5)每一种解决方法都会带来新的问题。6)问题最难处理的部分恰恰是去意识到它们的存在。7)在理解问题前，至少要做好准别接受三种可能的出错情况。8)或许还可以改变问题的表述来获得不同的解决方法。9)当你沉迷于寻找问题的定义和解决方法时，不要忘记随时都回头看看，看看自己是不是已经迷路了&amp;hellip;。10)当别人能很好的解决自己的问题时，千万不要越俎代庖。11)如果某人能够解决这个问题，但是他们并不会遇到这一问题时，那么你首先要做的就是让他们也感受一下问题。12)不管看上去如何，人们很少知道他们要什么，直到你给了他们所需要东西。13)甚至，事实上，并没有多少人真的希望他们的问题被解决。&lt;/strong&gt;&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  以上摘自书中序言。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  解决问题前，我们自然要先明确问题，比如问题的对象，问题的内容等等，虽然问题本身并不会有一个通俗简单的定义。但是书中的一种说法确实让人耳目一新&amp;#8212;-&amp;ldquo;&lt;strong&gt;问题就是你所期望的东西和你体验的东西之间的差别&lt;/strong&gt;&amp;rdquo;。对问题的定义是非常重要的―――同样是具有风险的，很多人在问题的定义中徘徊，因为他们不愿承担定义失误的风险。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  作为一个问题的解决者，为了定义一个问题（当然，它并不唯一），我们可以利用经典的分治算法把一个问题变为一系列的问题。为了实现这一转变，我们需要去回答另外一些问题&amp;#8212;比如&amp;ldquo;谁有问题&amp;rdquo;&amp;ldquo;问题的本质是什么&amp;rdquo;&amp;ldquo;问题是谁引起的&amp;rdquo;等等。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  当我们做出了一个比较适合的定义后，我们就可以着手去解决它。由于&amp;ldquo;问题就是你所期望的东西和你体验的东西之间的差别&amp;rdquo;，我们可以从两个方面入手&amp;#8212;-&lt;strong&gt;要么改变期望，要么改变体验&lt;/strong&gt;。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  要改变体验，有很多种方法，书中举例说&amp;ldquo;很多人觉得等待电梯的时间太久&amp;rdquo;―――&amp;ldquo;那么我们的期望的就是更加快速有效的乘坐电梯，体验则是漫长的等待&amp;rdquo;，而解决方法是―――&amp;ldquo;在等待电梯的拐角放上一面镜子&amp;rdquo;――――&amp;ldquo;对着镜子整理衣着减少了人们体验到的时间&amp;rdquo;。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  你从例子中体验到了什么?我悟到的是&amp;ldquo;&lt;strong&gt;体验!=(不等于)现实&lt;/strong&gt;&amp;rdquo;，我们可以在不对现实做出任何改变的同时，用某种手段改变人们的体验。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  但是在解决这一问题后是什么呢?&amp;#8212;-新的问题&amp;#8212;有人在镜子上乱涂乱画！我们的问题解决者不得不继续想办法去解决它。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &lt;strong&gt;如果你想找到一个问题的解决方法，试试&amp;ldquo;让情况变得更糟&amp;rdquo;&lt;/strong&gt;。基于这个原则，问题解决者把在镜子上涂画变成了一种娱乐的活动&amp;#8212;效果是一样的，人们不会觉得电梯来得太慢了&amp;#8212;他们甚至觉得来得太快了，不是么？&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  在结束这一章时，书中继续了那个很有趣的电梯的故事&amp;#8212;&amp;ldquo;在他们讨论解决问题时，曾经用说笑的口气提出过偷取隔壁大楼电梯使用时间的方法，但是被否决了。后来问题解决者发现隔壁大楼是一座百货商场，而且商场最近生意还不怎么样&amp;#8212;他们巴不得有人去偷取他们的电梯时间呢！&amp;rdquo;文中的结论是&amp;ldquo;对那些没有幽默感的人，帮他们解决问题简直就是自寻烦恼&amp;rdquo;（因为他对这个说笑口气提出的解决方案给予了严肃的批评），我觉得，这告诉我们，&lt;strong&gt;很多方案，我们并不能只从印象和表面去判断他是否可行&amp;#8212;-因为那并不可靠。&lt;/strong&gt;&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  然后是一个新的故事&amp;#8212;-在这里不对那个故事进行复述了，我觉得这个故事中最重要的结论是&amp;ldquo;&lt;strong&gt;不要把他们的解决方法误认为是问题的定义&lt;/strong&gt;&amp;rdquo;即是说，我们要自己去了解问题，而不要从别人那里&amp;#8212;尤其是他们的解决方案那里得到问题的答案。很多时候我们试图从别人那里去得到问题的定义，但是那永远是局部的，这和我们在做题做不出时，会去重读题目一样&amp;#8212;最原始的资料，虽然最难以使用，但却又是最为有效的。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  另外一个结论是：&lt;strong&gt;如果你太轻易地解决了他们的问题，他们永远都不会相信你真的解决了他们的问题。&lt;/strong&gt;&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  人总是过于自信的，这使他们不愿承认自己错误的估计了一个问题的难度。这使得我们有时为了解决一个问题，会浪费比解决问题更多的时间去说服哪些人&amp;#8212;&amp;#8211;为了避免这一点，我们必须在适当的时候承认自己的愚昧和无知。当然，倒过来想，绝大多数问题可以是简单的，只是我们用错了方法，走错了方向。仅此而已。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  在下一个故事中，再次强调了以下的事实：&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &lt;strong&gt;每一种解决问题的方法都会到来新的问题。我们永远都不能消灭问题。问题、解决问题的方法和新的问题编织成一条无穷无尽的锁链。在解决一个问题的时候，要找出至少三个可能出现的新问题，否则说明我们对于当前问题的理解还不够透彻。&lt;/strong&gt;&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  另外：&lt;strong&gt;问题最难以处理的部分恰恰是去意识到它们的存在。&lt;/strong&gt;如果我们能够意识到问题的存在，那么很多问题是很容易解决的。一个典型的例子是交通限速与交通事故的关系。当能源危机使美国限速减低到55英里时，交通事故大量减少。但是在这以前呢？我们常把原因归因与酒后驾车等问题,根本没有人意识到他们习以为常的交通限速根本就不合理！这是因为我们思维中的惯性的存在。因此，换一个身份进行思考，（孩子，外国人等等）也许你会对问题有一个全新的解读。因为很多我们习以为常的东西其实并不合理，或者说并不完美。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  这也就代入了&amp;ldquo;问题的表述&amp;rdquo;的问题，不同的问题表述可以给我们不同的解决方案，同样会带来不同的新的问题。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &amp;nbsp;只要我们记得对自己提问：&amp;ldquo;&lt;strong&gt;我们要怎样改变问题的表述才能获得不同的解决方法？&lt;/strong&gt;&amp;rdquo;也许我们就能得到不同表述与答案。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  一个简单的例子是一个简单的圆。我们可以问&amp;ldquo;这个物体是什么?&amp;rdquo;，也可以问&amp;ldquo;这个常见的物体什么?&amp;rdquo;&amp;ldquo;这个不常见的物体是什么?&amp;rdquo;你的答案一定会大不一样吧。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  这里我又想到了一个加鸡蛋的故事：&amp;ldquo;您要加鸡蛋么？&amp;rdquo;&amp;ldquo;您要加一个还是两个鸡蛋？&amp;rdquo;这样提问的两家商店可以有着完全不同的营业额。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  提问的内容与方法确实可以制约到人的思维，进而控制了我们的答案。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p&gt;这其实是一种文字游戏。&lt;/p&gt;&#xA;&lt;p&gt;有时我们可以利用它，有时我们却要减少文字引起的不确定性，因此，一旦你用文字来表述一个问题，请仔细推敲这些文字以使这种表述在每个人的头脑中都是一个意思。&lt;/p&gt;&#xA;&lt;p&gt;    另外，由于问题中存在的种种陷阱**：**&lt;strong&gt;当你在寻找问题定义的道路上疲倦地游荡时，不要忘记随时都回头看看，看看你是不是已经迷路了。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  又是新的故事。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  如果一些人产生了问题，你最好不要随便的插干涉它&amp;#8212;&amp;ldquo;&lt;strong&gt;当别人能够很好地解决自己问题的时候，千万不要越俎代庖。&lt;/strong&gt;&amp;rdquo;因为外力的入侵或许会使问题产生一些我们事先没有想到的变化&amp;#8212;-比如引入新的变量，改变问题的性质等等。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  如果这是他们的麻烦，就让它成为他们的麻烦吧。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &amp;nbsp;&amp;nbsp; &amp;nbsp;但是当你无法解决你所解决的问题而需要寻求帮助时，你也许会发现有人可以轻易的解决它。你要如何寻找帮助呢?威逼和利诱都不是最好的选择&amp;#8212;-&lt;strong&gt;你只需要让他也感受到这一问题的存在。&lt;/strong&gt;（当然，这不是永远有效的，因为也许那个人根本就不在乎，或者他会认为你是在给他捣乱！）&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  如果你用尽方法都行不通的话，&lt;strong&gt;为什么不试试指责你自己呢&lt;/strong&gt;？人们倾向于在别人身上寻找问题，确不会降低自己的期望。还记得我们对问题的定义么&amp;ldquo;问题其实就是你期望的东西和你体验的东西之间的差别&amp;rdquo;除了改变体验外，降低期望同样是一种方法&amp;#8212;-虽然你并不喜欢。但是事实是，很多问题的根源在你自己身上。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  不得不提的是书中最经典的一个例子:在一个隧道的入口处有一个照牌&amp;ldquo;警告：前有隧道请打开车头灯&amp;rdquo;，那么隧道的出口呢？&amp;ldquo;请关灯？&amp;rdquo;如果是晚上呢？也许我们可以用非常麻烦的语法分析各种情况写出一个完美的招牌，但是谁会去读它？最简单的方法是&amp;ldquo;如果这是他的问题，把问题留给他好了&amp;rdquo;&amp;#8212;简单的在牌子上写上&amp;ldquo;&lt;strong&gt;你的灯亮这么&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;&amp;rdquo;&amp;#8212;我们没有必要为所有人解决一个对每个人都很简单，组合起来确又非常复杂的问题，不是么？&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  最后，书中讨论了一个很奇怪的问题&amp;ldquo;我们真的想解决问题么？&amp;rdquo;虽然很奇怪，但是这种情况确实经常出现。也许你只是在享受问题解决过程的乐趣，也许你解决问题是为了否定它,谁知道呢?&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  最后的最后，是书中的最后说明的一句话：&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p&gt;  &lt;strong&gt; ****“首先，对自己要真诚。”&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;  &lt;/strong&gt; &lt;strong&gt;“&lt;strong&gt;&lt;strong&gt;This above all&lt;/strong&gt;&lt;/strong&gt;，&lt;/strong&gt; &lt;strong&gt;to thine own self be true&lt;/strong&gt;**。”**&lt;/p&gt;&#xA;&lt;p&gt;    在解决和定义一个问题前：“道德是最为重要的”&lt;/p&gt;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &amp;nbsp;&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  &amp;nbsp;&amp;nbsp;&amp;nbsp; 虽然文章已经结束了，我还是想把书中一个很有趣的问题及解决与大家分享，这来自书的序篇。&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  序篇&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  问题：没有人会阅读序言&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  解决方法：把序言称为第一章&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  解决方法带来的新问题：第一章是单调沉闷的&#xD;&#xA;&lt;/p&gt;&#xD;&#xA;&lt;p align=&#34;left&#34;&gt;&#xD;&#xA;  再次解决：把第一章扔了，再把第二章称为第一章&#xD;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ACM暑假集训总结</title>
      <link>https://sword865.github.io/archives/23/</link>
      <pubDate>Wed, 19 Aug 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/23/</guid>
      <description>&lt;p&gt;ACM的暑假集训结束了，趁着军训还没开始，对整个暑假接触到的东西作了一个总结，因为刚参加ACM不久，所以内容大都比较基础吧，文章中提到了些参考资料，如果需要的话，请留下邮箱。&lt;/p&gt;&#xA;&lt;p&gt;目录&lt;br&gt;&#xA;1)数据结构&lt;br&gt;&#xA; 1.并查集&lt;br&gt;&#xA; 2.高精度数&lt;br&gt;&#xA; 3.线段树&lt;br&gt;&#xA; 4.字典树&amp;lt;未完成&amp;gt;&lt;br&gt;&#xA;2)常用算法&lt;br&gt;&#xA; 1.递推&lt;br&gt;&#xA; 2.动态规划&lt;br&gt;&#xA; 3.贪心&lt;br&gt;&#xA; 4.搜索&lt;br&gt;&#xA;3)图论部分&#xA; 1.2-SAT问题&lt;br&gt;&#xA; 2.差分约束系统&lt;br&gt;&#xA; 3.二分图&lt;br&gt;&#xA; 4.最短路(SPFA,Dijkstra)&lt;br&gt;&#xA; 5.欧拉回路&amp;lt;未完成&amp;gt;&lt;br&gt;&#xA; 6.最优比率生成树&lt;br&gt;&#xA; 7.关键路径&lt;br&gt;&#xA; 8.网络流(流的算法/应用)&lt;br&gt;&#xA;     最大流算法(3种)&lt;br&gt;&#xA;     最小费用最大流算法&lt;br&gt;&#xA;     图的连通性（最小点割集）&amp;lt;未完成&amp;gt;&lt;br&gt;&#xA;     混合欧拉回路&lt;br&gt;&#xA; 9.其他图论相关问题算法:&lt;br&gt;&#xA;     K短路  &lt;br&gt;&#xA;     图的单向连通（包括2次DFS缩点） &lt;br&gt;&#xA;4)其他 &lt;br&gt;&#xA; 1.计算几何&lt;br&gt;&#xA; 2.数学(数论,组合数学,数值计算) &lt;br&gt;&#xA;5)附录&lt;br&gt;&#xA; 1.A*算法&lt;br&gt;&#xA; 2.位运算之格雷码：&lt;br&gt;&#xA; 3.线性同余方程&lt;/p&gt;&#xA;&lt;h2 id=&#34;一数据结构&#34;&gt;一．数据结构：&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1并查集&#34;&gt;1.并查集.&lt;/h3&gt;&#xA;&lt;p&gt;用于实现合并与查找两种操作的数据结构.&lt;br&gt;&#xA;实现方法:线形数组,有根树.&lt;br&gt;&#xA;优化:&lt;br&gt;&#xA;把深度小的树合并到深度大的树,深度相等时任选一棵树,既max(h1,h2), if h1&amp;lt;&amp;gt;h2. / h1+1, if h1=h2.&lt;br&gt;&#xA;合并操作时的路径压缩.&lt;br&gt;&#xA;并查集的偏移向量:&lt;br&gt;&#xA;并查集的偏移向量属于并查集的变形，只要适用于集合数目较少，或是固定的并查集类型。 &lt;br&gt;&#xA;增加一个offset字段,表示元素相对根的偏移量.&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;在find函数中计算偏移量&#xD;&#xA;int findset ( int x )&#xD;&#xA;{&#xD;&#xA;    int t ;&#xD;&#xA;    if ( father [ x ] == x ) return x ;&#xD;&#xA;    else t = findset( father [ x ] ) ;&#xD;&#xA;    offset [ x ] = ( offset [ x ] + offset [ father [ x ] ] ) % DEPTH ;//DEPTH表示几个状态量&#xD;&#xA;    //如果1182中，DEPTH=3；&#xD;&#xA;    father [ x ] = t ;&#xD;&#xA;    return t ; &#xD;&#xA;}//使用函数递归调用查找父亲在处理上优于循环。&#xD;&#xA;union函数中计算偏移量&#xD;&#xA;void union(int x,int y,int d){&#xD;&#xA;    int fx , fy ;&#xD;&#xA;    fx = find ( x ) ;&#xD;&#xA;    fy = find ( y ) ;&#xD;&#xA;    if ( fx == fy ) return ;&#xD;&#xA;    father [ fx ] = fy ;&#xD;&#xA;    offset [ fx ] = (offset [ y ] - offset[x]+d+3)% 3 ;&#xD;&#xA;} &#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h3 id=&#34;2高精度数&#34;&gt;2.高精度数&lt;/h3&gt;&#xA;&lt;p&gt;大数的加减乘除&lt;br&gt;&#xA;小数的高精度计算参考pku1001&lt;/p&gt;</description>
    </item>
    <item>
      <title>有重复组合数</title>
      <link>https://sword865.github.io/archives/24/</link>
      <pubDate>Thu, 02 Apr 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/24/</guid>
      <description>&lt;p&gt;从n个元素中有重复地取r个，不计顺序，则不同的取法有多少种？&lt;br&gt;&#xA;这个问题的答案被称为有重复组合数。结果很简洁，是C(n+r-1,r)。(注：这表示从n+r-1个数中取出r个数的组合数)&lt;br&gt;&#xA;【证明1】&lt;br&gt;&#xA;我们先把原命题具体化。假设这n个元素就是1&lt;del&gt;n这n个数:       &lt;br&gt;&#xA;对于每一种选出来的组合a1，a2，a3，&amp;hellip; ，am，我们要求：a1&amp;lt;=a2&amp;lt;=a3&amp;lt;=&amp;hellip;&amp;lt;=ar，那么最终的目的就是找出这样的a(i)组数。&lt;br&gt;&#xA;这里我们构造b1=a1，b2= a2+1，&amp;hellip; ，b(i)= a(i)+(i-1)，&amp;hellip; ，b(r)= a(r)+(r-1)&lt;br&gt;&#xA;于是b(i)和a(i)一一对应，即所求a(i)组数对应于b(i)组数&lt;br&gt;&#xA;又因为 b1 &amp;lt; b2 &amp;lt; b3 &amp;lt; &amp;hellip; &amp;lt; br 且b(i)取值于1&lt;/del&gt; n+(r-1)&lt;br&gt;&#xA;亦即原命题等价于从1~ n+r-1中取得r个不重复排列数&lt;br&gt;&#xA;来源：&lt;a href=&#34;http://zhidao.baidu.com/question/16706714.html&#34;&gt;http://zhidao.baidu.com/question/16706714.html&lt;/a&gt;&lt;br&gt;&#xA;【证明2】&lt;br&gt;&#xA;将n个元素看做n个盒子,r看作r个无区别的球,则相当于:&lt;br&gt;&#xA;把r个同样的球放入n个顺次排列的盒子,求不计放球顺序的放法种数&lt;br&gt;&#xA;用0表示盒子,1表示球&lt;br&gt;&#xA;我们把这n个0和r个1写在一行上。&lt;br&gt;&#xA;由于球必须放在盒子中,规定某个0之前,到上一个0为止的1的个数,表示该盒子中装的球数&lt;br&gt;&#xA;注意到最后一个数必须是0&lt;br&gt;&#xA;所以相当于从前面n+r-1个位置中挑出r个位置放1，其余n-1个位置放0&lt;br&gt;&#xA;来源：&lt;a href=&#34;http://pengzhe0302.spaces.live.com/blog/cns!529d86ea9ec40ca2!113.entry&#34;&gt;http://pengzhe0302.spaces.live.com/blog/cns!529d86ea9ec40ca2!113.entry&lt;/a&gt;&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;embed id=&#34;lingoes_plugin_object&#34; width=&#34;0&#34; height=&#34;0&#34; type=&#34;application/lingoes-npruntime-capture-word-plugin&#34; hidden=&#34;true&#34; /&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>编译原理虎书java版本–Chapter 2-3</title>
      <link>https://sword865.github.io/archives/25/</link>
      <pubDate>Sat, 14 Mar 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/25/</guid>
      <description>&lt;p&gt;文件：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;options {&#xD;&#xA;    JAVA_UNICODE_ESCAPE = true;&#xD;&#xA;}&#xD;&#xA;PARSER_BEGIN(MiniJavaParser)&#xD;&#xA;public class MiniJavaParser {}&#xD;&#xA;PARSER_END(MiniJavaParser)&#xD;&#xA;// Insert a specification of a lexical analysis here.&#xD;&#xA;TOKEN :&#xD;&#xA;{&#xD;&#xA;    &amp;lt; LPAREN: &amp;quot;(&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; RPAREN: &amp;quot;)&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; LSQPAREN: &amp;quot;[&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; RSQPAREN: &amp;quot;]&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; LBRACE: &amp;quot;{&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; RBRACE: &amp;quot;}&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; DOT: &amp;quot;.&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; ASSIGN: &amp;quot;=&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; LT: &amp;quot;&amp;lt;&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; PLUS: &amp;quot;+&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; MINUS: &amp;quot;-&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; AND : &amp;quot;&amp;amp;&amp;amp;&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; NOT : &amp;quot;!&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; SEMICOLON: &amp;quot;;&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; PUBLIC: &amp;quot;public&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; RETURN: &amp;quot;return&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; BOOLEAN: &amp;quot;boolean&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; CLASS: &amp;quot;class&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; INTERFACE: &amp;quot;interface&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; ELSE: &amp;quot;else&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; EXTENDS: &amp;quot;extends&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; FALSE: &amp;quot;false&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; IF: &amp;quot;if&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; WHILE: &amp;quot;while&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; INTEGER: &amp;quot;int&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; LENGTH: &amp;quot;length&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; MAIN: &amp;quot;main&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; NEW: &amp;quot;new&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; STATIC: &amp;quot;static&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; STRING: &amp;quot;String&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; THIS: &amp;quot;this&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; TRUE: &amp;quot;true&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; PRINT: &amp;quot;System.out.println&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; VOID: &amp;quot;void&amp;quot; &amp;gt;&#xD;&#xA;    }&#xD;&#xA;    TOKEN : /* LITERALS */&#xD;&#xA;    {&#xD;&#xA;        &amp;lt; INTEGER_LITERAL: ( [&amp;quot;1&amp;quot;-&amp;quot;9&amp;quot;] ([&amp;quot;0&amp;quot;-&amp;quot;9&amp;quot;])* | &amp;quot;0&amp;quot; ) &amp;gt;&#xD;&#xA;    }&#xD;&#xA;    TOKEN : /* IDENTIFIERS */&#xD;&#xA;    {&#xD;&#xA;        &amp;lt; IDENTIFIER: (|)* &amp;gt;&#xD;&#xA;        |&#xD;&#xA;        &amp;lt; #LETTER:&#xD;&#xA;        [&#xD;&#xA;        &amp;quot;u0024&amp;quot;,&#xD;&#xA;        &amp;quot;u0041&amp;quot;-&amp;quot;u005a&amp;quot;,&#xD;&#xA;        &amp;quot;u005f&amp;quot;,&#xD;&#xA;        &amp;quot;u0061&amp;quot;-&amp;quot;u007a&amp;quot;,&#xD;&#xA;        &amp;quot;u00c0&amp;quot;-&amp;quot;u00d6&amp;quot;,&#xD;&#xA;        &amp;quot;u00d8&amp;quot;-&amp;quot;u00f6&amp;quot;,&#xD;&#xA;        &amp;quot;u00f8&amp;quot;-&amp;quot;u00ff&amp;quot;,&#xD;&#xA;        &amp;quot;u0100&amp;quot;-&amp;quot;u1fff&amp;quot;,&#xD;&#xA;        &amp;quot;u3040&amp;quot;-&amp;quot;u318f&amp;quot;,&#xD;&#xA;        &amp;quot;u3300&amp;quot;-&amp;quot;u337f&amp;quot;,&#xD;&#xA;        &amp;quot;u3400&amp;quot;-&amp;quot;u3d2d&amp;quot;,&#xD;&#xA;        &amp;quot;u4e00&amp;quot;-&amp;quot;u9fff&amp;quot;,&#xD;&#xA;        &amp;quot;uf900&amp;quot;-&amp;quot;ufaff&amp;quot;&#xD;&#xA;        ]&#xD;&#xA;        |&#xD;&#xA;        &amp;lt; #DIGIT:&#xD;&#xA;        [&#xD;&#xA;        &amp;quot;u0030&amp;quot;-&amp;quot;u0039&amp;quot;,&#xD;&#xA;        &amp;quot;u0660&amp;quot;-&amp;quot;u0669&amp;quot;,&#xD;&#xA;        &amp;quot;u06f0&amp;quot;-&amp;quot;u06f9&amp;quot;,&#xD;&#xA;        &amp;quot;u0966&amp;quot;-&amp;quot;u096f&amp;quot;,&#xD;&#xA;        &amp;quot;u09e6&amp;quot;-&amp;quot;u09ef&amp;quot;,&#xD;&#xA;        &amp;quot;u0a66&amp;quot;-&amp;quot;u0a6f&amp;quot;,&#xD;&#xA;        &amp;quot;u0ae6&amp;quot;-&amp;quot;u0aef&amp;quot;,&#xD;&#xA;        &amp;quot;u0b66&amp;quot;-&amp;quot;u0b6f&amp;quot;,&#xD;&#xA;        &amp;quot;u0be7&amp;quot;-&amp;quot;u0bef&amp;quot;,&#xD;&#xA;        &amp;quot;u0c66&amp;quot;-&amp;quot;u0c6f&amp;quot;,&#xD;&#xA;        &amp;quot;u0ce6&amp;quot;-&amp;quot;u0cef&amp;quot;,&#xD;&#xA;        &amp;quot;u0d66&amp;quot;-&amp;quot;u0d6f&amp;quot;,&#xD;&#xA;        &amp;quot;u0e50&amp;quot;-&amp;quot;u0e59&amp;quot;,&#xD;&#xA;        &amp;quot;u0ed0&amp;quot;-&amp;quot;u0ed9&amp;quot;,&#xD;&#xA;        &amp;quot;u1040&amp;quot;-&amp;quot;u1049&amp;quot;&#xD;&#xA;        ]&#xD;&#xA;    }&#xD;&#xA;    SKIP :&#xD;&#xA;    {&#xD;&#xA;        &amp;lt; &amp;quot; &amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; &amp;quot;t&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; &amp;quot;n&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; &amp;quot;r&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt; &amp;quot;//&amp;quot; (~[&amp;quot;n&amp;quot;])* &amp;quot;n&amp;quot; &amp;gt;&#xD;&#xA;        | &amp;lt;&amp;quot;/*&amp;quot; (~[&amp;quot;*&amp;quot;])* &amp;quot;*&amp;quot; (~[&amp;quot;/&amp;quot;] (~[&amp;quot;*&amp;quot;])* &amp;quot;*&amp;quot;)* &amp;quot;/&amp;quot;&amp;gt;&#xD;&#xA;    }&#xD;&#xA;    // The following is a simple grammar that will allow you&#xD;&#xA;    // to test the generated lexer.&#xD;&#xA;    void Program() :&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        MainClass() (ClassDecl())*&#xD;&#xA;    }&#xD;&#xA;    void MainClass() :&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        &amp;quot;class&amp;quot; &amp;quot;{&amp;quot; &amp;quot;public&amp;quot; &amp;quot;static&amp;quot; &amp;quot;void&amp;quot; &amp;quot;main&amp;quot; &amp;quot;(&amp;quot; &amp;quot;String&amp;quot; &amp;quot;[&amp;quot; &amp;quot;]&amp;quot; &amp;quot;{&amp;quot; Statement() &amp;quot;}&amp;quot; &amp;quot;}&amp;quot;&#xD;&#xA;    }&#xD;&#xA;    void ext() :&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        (&amp;quot;extends&amp;quot;  )?&#xD;&#xA;    }&#xD;&#xA;    void ClassDecl() :&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        &amp;quot;class&amp;quot; ext()  &amp;quot;{&amp;quot; (VarDecl())* (MethodDecl())* &amp;quot;}&amp;quot;&#xD;&#xA;    }&#xD;&#xA;    void VarDecl():&#xD;&#xA;    {}&#xD;&#xA;    { Type() &amp;quot;;&amp;quot;}&#xD;&#xA;    void MethodDecl():&#xD;&#xA;    {}&#xD;&#xA;    {&amp;quot;public&amp;quot; Type()&#xD;&#xA;        &amp;quot;(&amp;quot; FormaList() &amp;quot;)&amp;quot;&#xD;&#xA;        &amp;quot;{&amp;quot; ( LOOKAHEAD(2) VarDecl() )* (Statement())*  &amp;quot;return&amp;quot; Exp() &amp;quot;;&amp;quot; &amp;quot;}&amp;quot;&#xD;&#xA;    }&#xD;&#xA;    void FormaList():&#xD;&#xA;    {}&#xD;&#xA;    {(Type()  &amp;quot;FormalRest()&amp;quot;)?}&#xD;&#xA;    void FormaRest():&#xD;&#xA;    {}&#xD;&#xA;    {&amp;quot;,&amp;quot; Type() }&#xD;&#xA;    void Type():&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        |&amp;quot;boolean&amp;quot;&#xD;&#xA;        |LOOKAHEAD(2)&#xD;&#xA;        &amp;quot;int&amp;quot;&#xD;&#xA;        |&amp;quot;int&amp;quot; &amp;quot;[&amp;quot; &amp;quot;]&amp;quot;&#xD;&#xA;    }&#xD;&#xA;    void Statement():&#xD;&#xA;    {}&#xD;&#xA;    {&amp;quot;{&amp;quot; (Statement())* &amp;quot;}&amp;quot;&#xD;&#xA;    |&amp;quot;while&amp;quot; &amp;quot;(&amp;quot; Exp() &amp;quot;)&amp;quot; Statement()&#xD;&#xA;    |&amp;quot;System.out.println&amp;quot;  &amp;quot;(&amp;quot; Exp() &amp;quot;)&amp;quot;&#xD;&#xA;    | instat1() &amp;quot;=&amp;quot; Exp() &amp;quot;;&amp;quot;&#xD;&#xA;    |&amp;quot;if&amp;quot; &amp;quot;(&amp;quot; Exp() &amp;quot;)&amp;quot; Statement() inif()&#xD;&#xA;}&#xD;&#xA;void inif():&#xD;&#xA;{}&#xD;&#xA;{(LOOKAHEAD(2) &amp;quot;else&amp;quot; Statement())?}&#xD;&#xA;void instat1():&#xD;&#xA;{}&#xD;&#xA;{(&amp;quot;[&amp;quot; Exp() &amp;quot;]&amp;quot;)?}&#xD;&#xA;void Exp():&#xD;&#xA;{}&#xD;&#xA;{Expa() (LOOKAHEAD(2) (Expb()))?&#xD;&#xA;}&#xD;&#xA;void Expa():&#xD;&#xA;{}&#xD;&#xA;{&amp;quot;true&amp;quot;&#xD;&#xA;    |&amp;quot;false&amp;quot;&#xD;&#xA;    |&#xD;&#xA;    |&amp;quot;this&amp;quot;&#xD;&#xA;    |&amp;quot;!&amp;quot; Exp()&#xD;&#xA;    |&amp;quot;(&amp;quot; Exp() &amp;quot;)&amp;quot;&#xD;&#xA;    |LOOKAHEAD(2)&#xD;&#xA;    &amp;quot;new&amp;quot; &amp;quot;int&amp;quot; &amp;quot;[&amp;quot; Exp() &amp;quot;]&amp;quot;&#xD;&#xA;    |&amp;quot;new&amp;quot; &amp;quot;(&amp;quot; &amp;quot;)&amp;quot;&#xD;&#xA;}&#xD;&#xA;void Expb():&#xD;&#xA;{}&#xD;&#xA;{&#xD;&#xA;    op() Exp()&#xD;&#xA;    |&amp;quot;[&amp;quot; Exp() &amp;quot;]&amp;quot;Exp()&#xD;&#xA;    |LOOKAHEAD(2)&#xD;&#xA;    &amp;quot;.&amp;quot; &amp;quot;length&amp;quot;&#xD;&#xA;    |&amp;quot;.&amp;quot;&#xD;&#xA;}&#xD;&#xA;void op():&#xD;&#xA;{}&#xD;&#xA;{&amp;quot;&amp;amp;&amp;amp;&amp;quot;&#xD;&#xA;    |&amp;quot;&amp;lt;&amp;quot;&#xD;&#xA;    |&amp;quot;+&amp;quot;&#xD;&#xA;    |&amp;quot;-&amp;quot;&#xD;&#xA;    |&amp;quot;*&amp;quot;}&#xD;&#xA;    void ExpList():&#xD;&#xA;    {}&#xD;&#xA;    {(Exp()  (ExpRest())*)?}&#xD;&#xA;    void ExpRest():&#xD;&#xA;    {}&#xD;&#xA;    {&amp;quot;,&amp;quot; Exp()}&#xD;&#xA;    void Goal() :&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        ( MiniJavaToken() )*&#xD;&#xA;    }&#xD;&#xA;    void MiniJavaToken():&#xD;&#xA;    {}&#xD;&#xA;    {&#xD;&#xA;        &amp;quot;class&amp;quot;  |  | &amp;quot;{&amp;quot; | &amp;quot;public&amp;quot; | &amp;quot;static&amp;quot; | &amp;quot;void&amp;quot; |&#xD;&#xA;            &amp;quot;main&amp;quot; | &amp;quot;(&amp;quot; | &amp;quot;String&amp;quot;  | &amp;quot;[&amp;quot; | &amp;quot;]&amp;quot; | &amp;quot;)&amp;quot; | &amp;quot;}&amp;quot; | &amp;quot;extends&amp;quot; | &amp;quot;;&amp;quot;&#xD;&#xA;            | &amp;quot;return&amp;quot; | &amp;quot;,&amp;quot; | &amp;quot;int&amp;quot; | &amp;quot;boolean&amp;quot; | &amp;quot;=&amp;quot; | &amp;quot;if&amp;quot; | &amp;quot;else&amp;quot; | &amp;quot;while&amp;quot;&#xD;&#xA;            | &amp;quot;System.out.println&amp;quot; | &amp;quot;&amp;amp;&amp;amp;&amp;quot; | &amp;quot;&amp;lt;&amp;quot; | &amp;quot;+&amp;quot; | &amp;quot;-&amp;quot; | &amp;quot;*&amp;quot; | &amp;quot;.&amp;quot; |&#xD;&#xA;            &amp;quot;length&amp;quot; | | &amp;quot;true&amp;quot; | &amp;quot;false&amp;quot; | &amp;quot;this&amp;quot; | &amp;quot;new&amp;quot; |&#xD;&#xA;            &amp;quot;!&amp;quot;&#xD;&#xA;    }&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>KMP算法复杂度分析</title>
      <link>https://sword865.github.io/archives/26/</link>
      <pubDate>Wed, 11 Mar 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/26/</guid>
      <description>&lt;p&gt;KMP算法也算接触很久了，今天却突然发现不知道那个的复杂度是怎么来的&lt;br&gt;&#xA;于是想啊想，查啊查，总结如下&lt;br&gt;&#xA;设代码为&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;s=0;  &#xD;&#xA;for(i=1;i&amp;lt;=m,i++){  &#xD;&#xA;    while(s&amp;gt;0&amp;amp;&amp;amp;a[i]!=b[s+1])s=next(s)  &#xD;&#xA;    if(a[i]==b[s+1])s++;  &#xD;&#xA;    if(s==n) return (i-n)&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;分析的关键是那个while循环循环会让s减少&lt;br&gt;&#xA;而s又只会在第五行增加，于是j最多增加m次，&lt;br&gt;&#xA;在然后我们就知道j最多减少m次(因为不能为负)&lt;br&gt;&#xA;平摊到每个for上就是一次&lt;br&gt;&#xA;所以复杂度就是O(m)了&lt;br&gt;&#xA;不过也有书上说是O(m+n)&lt;br&gt;&#xA;这个就不是很明白了&amp;hellip;&#xA;想想在说&amp;hellip;&lt;/p&gt;&#xA;&lt;div&gt;&#xD;&#xA;  &lt;embed type=&#34;application/lingoes-npruntime-capture-word-plugin&#34; width=&#34;0&#34; height=&#34;0&#34; id=&#34;lingoes_plugin_object&#34; hidden=&#34;true&#34; /&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>终于还是开了个blog。。。</title>
      <link>https://sword865.github.io/archives/27/</link>
      <pubDate>Sun, 08 Mar 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/27/</guid>
      <description>&lt;p&gt;RT&lt;br&gt;&#xA;以后常来看看吧&lt;/p&gt;</description>
    </item>
    <item>
      <title>编译原理虎书java版本–Chapter 1</title>
      <link>https://sword865.github.io/archives/28/</link>
      <pubDate>Sun, 08 Mar 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/28/</guid>
      <description>&lt;p&gt;Count.java&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;public class  Count&#xD;&#xA;{&#xD;&#xA;    int resolveStm(Stm stm){&#xD;&#xA;        int temp1=0,temp2=0;&#xD;&#xA;        if(stm.kind==1){&#xD;&#xA;            temp1=resolveStm(((CompoundStm)stm).stm1);&#xD;&#xA;            temp2=resolveStm(((CompoundStm)stm).stm2);&#xD;&#xA;            return temp1&amp;gt;temp2? temp1:temp2;&#xD;&#xA;        }else if(stm.kind==2){&#xD;&#xA;            return resolveExp(((AssignStm)stm).exp);&#xD;&#xA;        }else if (stm.kind==3){&#xD;&#xA;            return countExpInExpList(((PrintStm)stm).exps);&#xD;&#xA;        }else{&#xD;&#xA;            return 0;&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;    int countExpInExpList(ExpList expList){&#xD;&#xA;        if(expList.kind==1){&#xD;&#xA;            return 1;&#xD;&#xA;        }else if(expList.kind==2){&#xD;&#xA;            return 1+countExpInExpList(((PairExpList)expList).tail);&#xD;&#xA;        }else{&#xD;&#xA;            return 0;&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;    int resolveExp(Exp exp){&#xD;&#xA;        int temp1,temp2;&#xD;&#xA;        if(exp.kind==1){&#xD;&#xA;            return 0;&#xD;&#xA;        }else if(exp.kind==2){&#xD;&#xA;            return 0;&#xD;&#xA;        }else if(exp.kind==3){&#xD;&#xA;            temp1 = resolveExp(((OpExp)exp).left);&#xD;&#xA;            temp2 = resolveExp(((OpExp)exp).right);&#xD;&#xA;            return temp1&amp;gt;temp2?temp1:temp2;&#xD;&#xA;        }else if(exp.kind==4){&#xD;&#xA;            temp1=resolveStm(((EseqExp)exp).stm);&#xD;&#xA;            temp2=resolveExp(((EseqExp)exp).exp);&#xD;&#xA;            return temp1&amp;gt;temp2?temp1:temp2;&#xD;&#xA;        }else{&#xD;&#xA;            return 0;&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;    int resolveExpList(ExpList expList){&#xD;&#xA;        int temp1,temp2;&#xD;&#xA;        if(expList.kind==2){&#xD;&#xA;            temp1 = resolveExp(((PairExpList)expList).head);&#xD;&#xA;            temp2 = resolveExpList(((PairExpList)expList).tail);&#xD;&#xA;            return temp1&amp;gt;temp2?temp1:temp2;&#xD;&#xA;        }else if(expList.kind==1){&#xD;&#xA;            return resolveExp(((LastExpList)expList).last);&#xD;&#xA;        }else{&#xD;&#xA;            return 0;&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;}&#xD;&#xA;Interp.java&#xD;&#xA;public class  Interp&#xD;&#xA;{&#xD;&#xA;    void startinterpStm(Stm stm){&#xD;&#xA;        Table t=new Table(null,0,null);&#xD;&#xA;        interpStm(stm,t);&#xD;&#xA;    }&#xD;&#xA;    Table interpStm(Stm stm,Table t){&#xD;&#xA;        if(stm.kind==1){&#xD;&#xA;            Table t1=interpStm(((CompoundStm)stm).stm1,t);&#xD;&#xA;            Table t2=interpStm(((CompoundStm)stm).stm2,t1);&#xD;&#xA;            return t2;&#xD;&#xA;        }else if(stm.kind==2){&#xD;&#xA;            IntAndTable it1 = interExp(((AssignStm)stm).exp,t);&#xD;&#xA;            Table t1=update(it1.t,((AssignStm)stm).id,it1.i);&#xD;&#xA;            return t1;&#xD;&#xA;        }else if(stm.kind==3){&#xD;&#xA;            printExplist(((PrintStm)stm).exps,t);&#xD;&#xA;            return t;&#xD;&#xA;        }else{&#xD;&#xA;            return t;&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;    IntAndTable interExp(Exp exp,Table t){&#xD;&#xA;        if(exp.kind==1){&#xD;&#xA;            int temp=lookup(t,((IdExp)exp).id);&#xD;&#xA;            return new IntAndTable(temp,t);&#xD;&#xA;        }else if(exp.kind==2){&#xD;&#xA;            return new IntAndTable(((NumExp)exp).num,t);&#xD;&#xA;        }else if(exp.kind==3){&#xD;&#xA;            IntAndTable it1= interExp(((OpExp)exp).left,t);&#xD;&#xA;            IntAndTable it2= interExp(((OpExp)exp).right,it1.t);&#xD;&#xA;            int x1,x2,result;&#xD;&#xA;            x1=it1.i;&#xD;&#xA;            x2=it2.i;&#xD;&#xA;            if(((OpExp)exp).oper==1){&#xD;&#xA;                result=x1+x2;&#xD;&#xA;            }else if(((OpExp)exp).oper==2){&#xD;&#xA;                result=x1-x2;&#xD;&#xA;            }else if(((OpExp)exp).oper==3){&#xD;&#xA;                result=x1*x2;&#xD;&#xA;            }else if(((OpExp)exp).oper==4){&#xD;&#xA;                result=x1/x2;&#xD;&#xA;            }else{&#xD;&#xA;                result=0;&#xD;&#xA;            }&#xD;&#xA;            return new IntAndTable(result,t);&#xD;&#xA;        }else if(exp.kind==4){&#xD;&#xA;            Table t1=interpStm(((EseqExp)exp).stm,t);&#xD;&#xA;            IntAndTable t3= interExp(((EseqExp)exp).exp,t1);&#xD;&#xA;            return t3;&#xD;&#xA;        }else{&#xD;&#xA;            return new IntAndTable(0,t);&#xD;&#xA;        }&#xD;&#xA;    }&#xD;&#xA;    Table update(Table t1,String i,int v){&#xD;&#xA;        Table t2=new Table(i,v,t1);&#xD;&#xA;        return t2;&#xD;&#xA;    }&#xD;&#xA;    int lookup(Table t,String key){&#xD;&#xA;        if(key.compareTo(t.id)==0){&#xD;&#xA;            return t.value;&#xD;&#xA;        }else return lookup(t.tail,key);&#xD;&#xA;    }&#xD;&#xA;    void printExplist(ExpList exps,Table t){&#xD;&#xA;        if(exps.kind==1){&#xD;&#xA;            IntAndTable temp=interExp(((LastExpList)exps).last,t);&#xD;&#xA;            System.out.println(temp.i);&#xD;&#xA;        }else if(exps.kind==2){&#xD;&#xA;            IntAndTable temp=interExp(((PairExpList)exps).head,t);&#xD;&#xA;            System.out.print(temp.i+&amp;quot;&amp;quot;);&#xD;&#xA;            printExplist(((PairExpList)exps).tail,t);&#xD;&#xA;        }else return;&#xD;&#xA;    }&#xD;&#xA;// IntAndTable interExpList(ExpList explist,Table t){&#xD;&#xA;// }&#xD;&#xA;}&#xD;&#xA;class Table&#xD;&#xA;{&#xD;&#xA;    String id;&#xD;&#xA;    int value;&#xD;&#xA;    Table tail;&#xD;&#xA;    Table(String i,int v,Table t){id=i;value=v;tail=t;}&#xD;&#xA;}&#xD;&#xA;class IntAndTable&#xD;&#xA;{&#xD;&#xA;    int i;&#xD;&#xA;    Table t;&#xD;&#xA;    IntAndTable(int ii,Table tt){i=ii;t=tt;};&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
