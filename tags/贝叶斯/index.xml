<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>贝叶斯 on 悟剑阁</title>
    <link>https://sword865.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/</link>
    <description>Recent content in 贝叶斯 on 悟剑阁</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2015. All rights reserved.</copyright>
    <lastBuildDate>Sat, 05 Sep 2009 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://sword865.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>算法总结1—贝叶斯分类器</title>
      <link>https://sword865.github.io/archives/21/</link>
      <pubDate>Sat, 05 Sep 2009 00:00:00 +0000</pubDate>
      <guid>https://sword865.github.io/archives/21/</guid>
      <description>&lt;p&gt; 这几天以很快的速度翻完了&amp;lt;集体智慧编程&amp;gt;,因为只是对里面的算法感兴趣,对那些web2.0的应用没什么感觉,所以很多地方都是一扫而过,现在按最后一章的顺序来对所有相关的算法作一个详细的复习….&lt;/p&gt;&#xA;&lt;p&gt;这个是第一篇……贝叶斯分类器&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;数学基础：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;条件概率&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;定义：设A, B是两个事件，且P(A)&amp;gt;0 称P(B∣A)=P(AB)/P(A)为在条件 A下发生的条件事件B发生的条件概率。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;乘法公式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设P(A)&amp;gt;0，则有P(AB)=P(B∣A)P(A)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;全概率公式和贝叶斯公式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;定义: 设S为试验E的样本空间，B1, B2, …Bn为E的一组事件，若BiBj=Ф, i≠j, i, j=1, 2, …,n; B1∪B2∪…∪Bn=S则称B1, B2, …, Bn为样本空间的一个划分。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设试验E的样本空间为，A为E的事件，B1, B2, …,Bn为的一个划分，且P(Bi)&amp;gt;0(i=1, 2, …n)，则P(A)=P(A∣B1)P(B1)+P(A∣B2)+ …+P(A∣Bn)P(Bn)称为全概率公式。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;设试验E的样本空间为S，A为E的事件，B1, B2, …,Bn为的一个划分，则P(Bi∣A)=P(A∣Bi)P(Bi)/∑P(B｜Aj)P(Aj)=P(B｜Ai)P(Ai)/P(B)称为贝叶斯公式。&lt;/p&gt;&#xA;&lt;p&gt;说明：i，j均为下标，求和均是1到n&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;贝叶斯分类器原理：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过某些特征对不同的内容进行分类。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;特征的定义&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;任何可以用来判断内容中具备或缺失的东西。如要对文档进行分类时，所谓的内容就是文档，特征就是文档中的单词(当然你也可以选择其他合理的东西)&lt;/p&gt;&#xA;&lt;p&gt;当向贝叶斯分类器输入一个要进行分类的样本后，分类器会先对该样本进行分析，确定其特征，然后将根据这些特征时，计算样本属于各分类的概率。&lt;/p&gt;&#xA;&lt;p&gt;朴素贝叶斯分类器的具体工作步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;学习：向分类器输入一系列的训练数据，注意这些数据是包括其所属类别的，分类器将对训练数据进行分析，计算出&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;1.各个特征在各个分类中出现的概率(=某分类中具有该特征的数据数目/该分类数目)如先计算出各个单词在各种分类的文档出现的概率。&lt;/p&gt;&#xA;&lt;p&gt;将该概率作为某分类下某特征出现的条件概率P(feature|category)&lt;/p&gt;&#xA;&lt;p&gt;2.任选一个样本属于某分类的概率(=某分类文章数 / 文章总数)&lt;/p&gt;&#xA;&lt;p&gt;记该概率为p(category)&lt;/p&gt;&#xA;&lt;p&gt;在朴素的贝叶斯分类器中，我们假设将要组合的各个概率相互独立(当然，很多时候并非如此。我们有时会发现，当样本拥有某一特征时，则它就更可能拥有另一项特征。)&lt;/p&gt;&#xA;&lt;p&gt;2)分类计算：在向分类器提供大量学习数据后，我们就可以用它对新的样本进行分类了。&lt;/p&gt;&#xA;&lt;p&gt;首先对样本进行分析，找出其具有的各种特征，利用这些特征，我们来计算各个分类中出现该样本的概率p(sample | category)。为了完成这一计算，我们只要简单将该分类下在该文档中出现过的特征出现的条件概率相乘即可。即∏P(feature | category) 这里的feature是该样本拥有的所有特征。&lt;/p&gt;&#xA;&lt;p&gt;但是，我们实际要计算的是P (category | sample),即给定样本属于某分类的条件概率。&lt;/p&gt;&#xA;&lt;p&gt;这里，就用到了贝叶斯定理：P(A | B)=P(B | A)P(A) / P(B)&lt;/p&gt;&#xA;&lt;p&gt;这里就是：P(category | sample)= P(sample | category)P(category) / P(sample)&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
