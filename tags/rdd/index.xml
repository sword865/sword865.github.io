<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RDD on 悟剑阁</title>
    <link>https://sword865.github.io/tags/rdd/</link>
    <description>Recent content in RDD on 悟剑阁</description>
    <generator>Hugo</generator>
    <language>zh-CN</language>
    <copyright>Copyright (c) 2015. All rights reserved.</copyright>
    <lastBuildDate>Sun, 12 Mar 2017 15:49:45 +0800</lastBuildDate>
    <atom:link href="https://sword865.github.io/tags/rdd/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>比较一下spark2的DataFrame和RDD</title>
      <link>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</link>
      <pubDate>Sun, 12 Mar 2017 15:49:45 +0800</pubDate>
      <guid>https://sword865.github.io/posts/2017/2017-01-19-%E6%AF%94%E8%BE%83%E4%B8%80%E4%B8%8Bspark2%E7%9A%84dataframe%E5%92%8Crdd/</guid>
      <description>&lt;p&gt;前段时间把spark集群升级到2.x，使用起来感觉相对1.x的版本最大的改动就是DataFrame正式开始替代RDD成为主流，包括我们最常用到的mllib的官方文档也提到：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;In the Spark 2.x releases, MLlib will add features to the DataFrames-based API to reach feature parity with the RDD-based API.&#xD;&#xA;After reaching feature parity (roughly estimated for Spark 2.2), the RDD-based API will be deprecated.&#xD;&#xA;The RDD-based API is expected to be removed in Spark 3.0.&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h4 id=&#34;rdd的结构&#34;&gt;RDD的结构&lt;/h4&gt;&#xA;&lt;p&gt;RDD可以看成是一个分布式的无序列表，这个列表内的元素是一个object，RDD并不关心每个object的内部结构。因此所有操作都必须对这个object进行，不利于算子的复用。&lt;/p&gt;&#xA;&lt;p&gt;比起DataFrame，RDD更方便我们对数据做一些底层的操作，也可以用于unstructured的数据。&lt;/p&gt;&#xA;&lt;h4 id=&#34;dataframe的结构&#34;&gt;DataFrame的结构&lt;/h4&gt;&#xA;&lt;p&gt;DataFrame不同于RDD，框架会去了解object中的数据是什么样的结构，这样每个算子就可以单独实现在某个列上，复用起来就更加简单。&lt;/p&gt;&#xA;&lt;p&gt;因为DataFrame比RDD多个更多的限制，对内部的元素也有了更多的了解，可以使用SQL语句进行操作，因此也就可以在对DataFrame进行操作时使用Spark SQL的Catalyst优化器进行优化。&lt;/p&gt;&#xA;&lt;p&gt;Catalyst一个易于扩展的查询优化器，同时支持基于规则(rule-based)和基于代价(cost-based)的优化方法，我们可以基于相关API自己定义优化规则。&lt;/p&gt;&#xA;&lt;p&gt;最后，Spark的Tungsten目前还只支持DataFrame API, 因此在使用RDD时不能享受到Tungsten带来的效率优化。（Tungsten做的优化概括起来说就是由Spark自己来管理内存而不是使用JVM，这样可以避免JVM GC带来的性能损失）&lt;/p&gt;&#xA;&lt;h4 id=&#34;dataset数据结构&#34;&gt;DataSet数据结构&lt;/h4&gt;&#xA;&lt;p&gt;前面提到DataFrame每一个record对应了一个Row。而Dataset的定义更加宽松，每一个record对应了一个任意的类型。实际上，从源码中可以看到，DataFrame就是Dataset的一种特例。&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;package object sql {&#xD;&#xA;    ...&#xD;&#xA;    type DataFrame = Dataset[Row]&#xD;&#xA;}&#xD;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;DataSet和DataFrame可以通过df.as和ds.toDF方法方便的进行转化。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
